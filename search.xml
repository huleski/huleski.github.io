<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java线程池实现原理]]></title>
    <url>%2F2019%2F03%2F16%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Java中的ThreadPoolExecutor类java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法：123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值：1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService AbstractExecutorService的实现：12345678910111213141516171819202122232425262728public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 ExecutorService接口的实现：123456789101112131415161718192021public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而ExecutorService又是继承了Executor接口 Executor接口的实现：123public interface Executor &#123; void execute(Runnable command);&#125; ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor之间的关系 Executor是一个顶层接口，在它里面只声明到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法：1234execute()submit()shutdown()shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果 shutdown()和shutdownNow()是用来关闭线程池的。 线程池实现原理1. 线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态：12345volatile int runState;static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2. 任务的执行 ThreadPoolExecutor类中其他的一些比较重要成员变量：12345678910111213141516171819private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可：123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下：1if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行1addIfUnderCorePoolSize(command) 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断：1if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行：1ddIfUnderMaximumPoolSize(command) 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面：1if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断：1if (runState != RUNNING || poolSize == 0) 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行：1ensureQueuedTaskHandled(command) 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize：123456789101112131415private boolean addIfUnderCorePoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); //创建线程去执行firstTask任务 &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true;&#125; 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心线程池大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行1t = addThread(firstTask); 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现：123456789101112private Thread addThread(Runnable firstTask) &#123; Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); //创建一个线程，执行任务 if (t != null) &#123; w.thread = t; //将创建的线程的引用赋值为w的成员变量 workers.add(w); int nt = ++poolSize; //当前线程数加1 if (nt &gt; largestPoolSize) largestPoolSize = nt; &#125; return t;&#125; 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private final class Worker implements Runnable &#123; private final ReentrantLock runLock = new ReentrantLock(); private Runnable firstTask; volatile long completedTasks; Thread thread; Worker(Runnable firstTask) &#123; this.firstTask = firstTask; &#125; boolean isActive() &#123; return runLock.isLocked(); &#125; void interruptIfIdle() &#123; final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) &#123; try &#123; if (thread != Thread.currentThread()) thread.interrupt(); &#125; finally &#123; runLock.unlock(); &#125; &#125; &#125; void interruptNow() &#123; thread.interrupt(); &#125; private void runTask(Runnable task) &#123; final ReentrantLock runLock = this.runLock; runLock.lock(); try &#123; if (runState &lt; STOP &amp;&amp; Thread.interrupted() &amp;&amp; runState &gt;= STOP) boolean ran = false; beforeExecute(thread, task); //beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据 //自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 try &#123; task.run(); ran = true; afterExecute(task, null); ++completedTasks; &#125; catch (RuntimeException ex) &#123; if (!ran) afterExecute(task, ex); throw ex; &#125; &#125; finally &#123; runLock.unlock(); &#125; &#125; public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); //当任务队列中没有任务时，进行清理工作 &#125; &#125;&#125; 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样：1Thread t = new Thread(w); 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了：123456789101112public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125;&#125; 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现：123456789101112131415161718192021222324252627Runnable getTask() &#123; for (;;) &#123; try &#123; int state = runState; if (state &gt; SHUTDOWN) return null; Runnable r; if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) //如果线程数大于核心池大小或者允许为核心池线程设置空闲时间， //则通过poll取任务，若等待一定的时间取不到任务，则返回null r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); if (r != null) return r; if (workerCanExit()) &#123; //如果没取到任务，即r为null，则判断当前的worker是否可以退出 if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); //中断处于空闲状态的worker return null; &#125; // Else retry &#125; catch (InterruptedException ie) &#123; // On interruption, re-check runState &#125; &#125;&#125; 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现：12345678910111213141516private boolean workerCanExit() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean canExit; //如果runState大于等于STOP，或者任务缓存队列为空了 //或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1 try &#123; canExit = runState &gt;= STOP || workQueue.isEmpty() || (allowCoreThreadTimeOut &amp;&amp; poolSize &gt; Math.max(1, corePoolSize)); &#125; finally &#123; mainLock.unlock(); &#125; return canExit;&#125; 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现：12345678910void interruptIdleWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) //实际上调用的是worker的interruptIfIdle()方法 w.interruptIfIdle(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中：123456789101112void interruptIfIdle() &#123; final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) &#123; //注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的 //如果成功获取了锁，说明当前worker处于空闲状态 try &#123; if (thread != Thread.currentThread()) thread.interrupt(); &#125; finally &#123; runLock.unlock(); &#125; &#125;&#125; 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的：123456789101112131415private boolean addIfUnderMaximumPoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true;&#125; 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3. 线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现：12345678910public boolean prestartCoreThread() &#123; return addIfUnderCorePoolSize(null); //注意传进去的参数是null&#125; public int prestartAllCoreThreads() &#123; int n = 0; while (addIfUnderCorePoolSize(null))//注意传进去的参数是null ++n; return n;&#125; 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的1r = workQueue.take(); 即等待任务队列中有任务。 4. 任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5. 任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 6. 线程池的关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7. 线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 如何合理配置线程池的大小一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1 如果是IO密集型任务，参考值可以设置为2*NCPU 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 原文链接]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java四个线程池的实现]]></title>
    <url>%2F2019%2F03%2F11%2Fjava%E5%9B%9B%E4%B8%AA%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[太久没有关注线程池, 现在复习一下 Java通过Executors提供四种线程池，分别为：1234newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。示例代码如下：123456789101112131415161718192021import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors;public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(index); &#125; &#125;); &#125; &#125; &#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下：1234567891011121314151617181920import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors;public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; fixedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors() newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：1234567891011121314import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println(&quot;delay 3 seconds&quot;); &#125; &#125;, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟3秒执行。 定期执行示例代码如下：1234567891011121314import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; System.out.println(&quot;delay 1 seconds, and excute every 3 seconds&quot;); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟1秒后每3秒执行一次。 newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下：123456789101112131415161718192021import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 结果依次输出，相当于顺序执行各个任务。 可以使用JDK自带的监控工具来监控我们创建的线程数量，运行一个不终止的线程，创建指定量的线程，来观察： 工具目录：C:\Program Files\Java\jdk1.8.0_171\bin\jconsole.exe 运行程序做稍微修改：12345678910111213141516171819202122232425262728import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; while(true) &#123; System.out.println(index); Thread.sleep(10 * 1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 可以查看线程数的变化]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何向开源项目提交无法解答的问题]]></title>
    <url>%2F2019%2F03%2F06%2F%E5%A6%82%E4%BD%95%E5%90%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BA%A4%E6%97%A0%E6%B3%95%E8%A7%A3%E7%AD%94%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[作为一名互联网开发者，总会使用和参与过一些开源项目。开源社区里，有些你来我往，有些则石沉大海。人们提问的方式有许多迷人和实用的共通之处。有人专门把它们提炼出来，希望能帮助到那些像他们一样充满了好奇心、且愿意付诸行动去惹恼开源项目维护者的人们。 以下是『如何提出无法解答的问题』的十三个小技巧： 1.惜字如金『言多必失，不如闷声发大财』 压缩问题的字节数，不要让对方觉得你啰嗦。用最简单的字词描述你的问题，提炼关键字，简化掉冗长的过程和繁琐的细节。 正确示范: 样式编译报错 错误示范： 在我的项目里引入了 xxx.css，编译时出错了，报错信息如下：Module build failed: SyntaxError: Unexpected token我是这么引用的：import ‘xxx.css’;balalalala ….. 2.缓兵之计『和他成为长期笔友』 如果维护者答复你了，通常他们会索要进一步的信息。记住不要着急回复，那样显得你像个工作狂（时时刻刻泡在电脑边，可怜巴巴的等待回复）。你还有其他生活，喝杯咖啡，聊个微信，隔上十天半个月再回复。相信我，他们很快会失去耐心而关掉这个问题，或者因为一时关不了而心情郁闷。 正确示范： 你：使用 Button 时发现控制台报错，提示如下。维护者（两天内）：我没有重现出你的例子，可以提供一份可重现的示例么？维护者（三天后）：@你维护者（一周后）：ping~你（两周后）：哎呀抱歉，没有及时回复，我的代码在这里。 错误示范： 你：使用 Button 时发现控制台报错，提示如下。维护者（两天内）：我没有重现出你的例子，可以提供一份可重现的示例么？你（两天内）：可能我的情况有些不同，这里是重现代码。 3.夹带私货『我哪有时间排查，这绝对是你的锅』 在一个中型或者大型项目中引入开源模块容易遇到奇怪的问题。几十个文件上百个业务模块，项目工期又紧张，一一排查太辛苦了，还是另请高明吧，赶紧打个包发给对方。 正确示范： 我的数据库项目出现了一个前端组件问题，这里是我的代码，有人能帮我看看么。附件：db-service-app.rar (434MB) 错误示范： 我的项目里出现了一个前端组件问题，我简化了一下代码，发现是 xxx 组件和 yyy 组件同时使用时出现的，这里有个简单的重现例子。附件：component-xxx-yyy-bug.zip (12KB) 4.卖个关子『欲知后事如何，且听下回分解』 总是留个后手，不要一次性把话说完，让你的问题充满神秘感，充分调动起读者的好奇心。 正确示范： 你：我的代码出错了，不知道该怎么办？你：我这里有一个问题，有人能帮我解决么？你：在吗？ 错误示范： 你：我使用了刚刚发布的 xxx 最新版本，控制台出现如下错误…我是这么调用的…我的代码仓库在这里… 5.弄乱格式『怕他轻易看懂我的问题，我必须要做点什么』 从来，永远不要格式化问题。你又不是美工，美化格式不是你的特长。你的精力要用在项目开发中，也没有时间去学习什么格式化语法。至于对方能不能看明白，你才不需要关心。 正确示范： 123456789101112131415161718192021222324252627282930313233343536373839404142 renderBatchButton() &#123;return(&lt;Dropdown overlay=&#123;this.renderExportMenu(&quot;2&quot;)&#125;&gt;导出出库单);&#125;renderExportMenu(category) &#123;let exportFile=(&#123;key&#125;)=&gt;&#123;console.log(key)&#125;let items=[];if(this.props.global.template_list)&#123;items=this.props.global.template_list.map((item)=&gt;&#123;if(category===item.category)&#123;return (&lt;Menu.Item key=&#123;item.id&#125;&gt;&#123;item.name&#125;&lt;/Menu.Item&gt;);&#125;&#125;);&#125; 错误示范： 1234567891011121314151617import React from &apos;react&apos;;import ReactDOM from &apos;react-dom&apos;;import &#123; Menu, Icon &#125; from &apos;antd&apos;;class Demo extends React.Component &#123; state = &#123; collapsed: false, &#125;; toggle = () =&gt; &#123; this.setState(&#123; collapsed: !this.state.collapsed, &#125;); &#125; render() &#123; return &lt;Menu&gt;...&lt;/Menu&gt;; &#125;&#125; 6.遗漏关键信息『诶？我忘了说我没插电源了么？』 项目代码一开始总是跑的好好的，你做了某个操作、或改动了某些代码、或者在一个特殊的环境下，问题出现了。 这个区别往往是问题的关键，把它留在心里就好，不要轻易说出来。 正确示范： 你：我的代码出错了。维护者：我尝试了各种方式都没有重现出来，麻烦提供下重现？你（很久以后）：哦！我是在 chrome 35 中出现的这个问题。 错误示范： 你：我的代码在 chrome 35 出错了。维护者：好的，我也重现了，我看看怎么修复。 7.提供错误的信息『在错误的信息上解决问题才能体现你牛逼嘛！哈哈哈』 有时候需要做一些误导，有意或者无意，总之制造困难是你的强项。 正确示范： 你：我的代码出错了。维护者：你使用了什么版本？你：0.8.4（实际上本地是 0.8.3）维护者：你确定么，0.8.4 应该已经修复过这个问题。我再看看… 错误示范： 你：我的代码在 0.8.3 版本里出错了。维护者：0.8.4 应该已经修复过这个问题，升级到新版即可解决。 8.尽情宣泄情绪『你们把我项目搞挂了，狗屎！』 开源项目导致了你的项目出现 BUG，导致了你周六晚上还要加班，导致了男/女友抱怨你不理他/她，这必须要有人负责。你的工作和生活被他们毁了，也别让他们好过。 正确示范： 这个项目烂透了，用起来全是坑，文档也太简略了，这样做开源真是呵呵了 错误示范： 这个项目有很多细节问题，文档也不完善，请问有改进的计划么？我收集了以下具体问题，希望持续完善。 9.构思宏伟蓝图『我要造一台汽车，该怎么做？』 尝试问一个具有宏大目标的问题，只有那些祖母般慈祥的维护者才会尝试回答你（这简直不可能发生）。而且由于你表现出了在所有技术细节上的毫无准备以及极端无知，对方的回答也没办法让你满意。 正确示范： 请问怎么打包发布？ 错误示范： 我要开发一个前端单页项目，后端是 php，架构是前后端完全分离的方式。我尝试使用 xxx 进行打包构建时遇到一个问题…（省略五十字）请问这时我应该做什么？ 10.自由发挥『八股文的时代早就过去了！』 很多开源项目的维护者都是傲慢、迂腐、喜欢设定各种规矩的怪胎。例如他们常常会提供奇怪的问题模板，让你在一个又臭又长的表单里填空。一旦你不按他们说的来，他们就会视你为捣乱分子，把你批判一番。你哪里受得了这些拘束，想怎么写就怎么写，让他们和他们的模板都见鬼去吧！ 正确示范： 浮层没有关闭，代码如下，求解决 错误示范： 1234567891011121314151617xxx 组件浮层没有关闭- 使用版本：1.0.0- 浏览器：Chrome 56.0987- 操作系统：Windows 10## 你做了什么？我引入了组件 xxx，代码如下，我点击组件后打开浮层，做了如下操作。## 你期待的是什么？浮层应该关闭。## 实际上的情况是？浮层短暂关闭后又再次弹出。[GIF截图]## 可重现的在线演示http://demo.com/demo.html 11.重复提问『重要的事要说三遍』 在不同的地方重复你提过的问题，加深对方的印象，颠覆对方的想象！ 正确示范： 问题一：发请求时报错：405 Method not allowd。问题二：您好，我这里出现了 405 Method not allowd 的问题。问题三：请求 405 错误，请问我该怎么办？问题 n：… 错误示范： 问题一：发请求时报错：405 Method not allowd你：+1 我也出现了这个问题。 12.出其不意『到全世界提问，到他们想不到的地方提问』 即使你知道有官方渠道，也推荐用其他方式向维护者提问：微博、Twitter、知乎私信、知乎评论区、Email、微信、个人博客、蚂蚁森林、朋友圈、他对 TFboys 微博的转发，今日头条娱乐版的评论区……到一切你能找到他的地方去提问。 正确示范： 未关注人私信：你好，我们项目用的是你们的框架，我想问下可以让 xxx 组件获取到焦点吗？因为要做键盘切换 错误示范： 官方渠道：你好，我们项目用的是你们的框架，我想问下可以让 xxx 组件获取到焦点吗？因为要做键盘切换 13.上纲上线『接连便是难懂的话，什么”KPI”，”绩效”，”弃坑”之类，引得众人都哄笑起来』 把你的问题拔高一个层次，站在道德高地进行指责，一旦讨论涉及到政治，他们便百口莫辩。 正确示范： 原来大公司团队也就这样啊，都不好好测试的么？就这玩意还好意思拿出来，就是个 KPI 产物，晋升完就不管了。 错误示范： 这个项目虽然是大公司的产品，在以下方面比起竞品还有劣势，个人不建议使用。 总结总而言之，开源项目的维护者在尝试解答和解决问题时，总是希望能亲眼看到问题发生，不要让他们得逞。另外，他们大多对未关闭的问题有强迫症，尽量多制造一些这样的问题。 原文链接]]></content>
      <categories>
        <category>开源</category>
      </categories>
      <tags>
        <tag>提问</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10-你需要提供管理员权限才能删除此文件]]></title>
    <url>%2F2019%2F03%2F02%2Fwin10-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8F%90%E4%BE%9B%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%89%8D%E8%83%BD%E5%88%A0%E9%99%A4%E6%AD%A4%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[新买的电脑配置环境, 在系统盘新建/修改/删除文件的时候会弹框提示: 你需要提供管理员权限才能新建/修改/删除此文件 去网上搜索解决方法, 清一色的复制粘贴: 去修改文件夹权限! 这个智障答案是最多的, 难道我每操作一个文件就去修改一次文件夹权限?甚至还有用命令行操作、添加脚本的, 我的妈啊, 就一个权限问题还得把操作系统学一遍不成? 解决方法 按WIN+R，打开运行对话框 输入gpedit.msc，打开组策略 一步步地选择: 计算机配置-&gt;Windows 设置-&gt;安全设置-&gt;本地策略-&gt;安全选项 找到右侧的用户账户控制：以管理员批准模式运行所有管理员这个项，默认设置是启用的，把它设成禁用。 重启电脑 完成! 试试新建/修改/删除文件看是否还会出现权限提示]]></content>
      <categories>
        <category>win10</category>
      </categories>
      <tags>
        <tag>win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2019%2F02%2F27%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[日志文件 日志文件 说明 /var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一 /var/log/secure 与安全相关的日志信息 /var/log/maillog 与邮件相关的日志信息 /var/log/cron 与定时任务相关的日志信息 /var/log/spooler 与UUCP和news设备相关的日志信息 /var/log/boot.log 守护进程启动和停止相关的日志消息 系统 命令 说明 uname -a 查看内核/操作系统/CPU信息 cat /etc/issue 登陆信息显示数据 cat /etc/redhat-release 查看操作系统版本 cat /proc/cpuinfo 查看CPU信息 hostname 查看计算机名 lspci -tv 列出所有PCI设备 lsusb -tv 列出所有USB设备 lsmod 列出加载的内核模块 env 查看环境变量 资源 命令 说明 free -m 查看内存使用量和交换区使用量 df -h 查看各分区使用情况 du -sh &lt;目录名&gt; 查看指定目录的大小 grep MemTotal /proc/meminfo 查看内存总量 grep MemFree /proc/meminfo 查看空闲内存量 uptime 查看系统运行时间、用户数、负载 cat /proc/loadavg 查看系统负载 磁盘和分区 命令 说明 fdisk -l # 查看所有分区 swapon -s # 查看所有交换分区 fdisk /dev/vdb # 对磁盘/dev/edb进行分区 mount /dev/vdb1 /data # 将磁盘分区/dev/vdb1挂载到/data下 echo /dev/vdb1 /data ext4 defaults 0 0 &gt;&gt; /etc/fstab 启动时自动挂载分区 网络 命令 说明 ifconfig 查看所有网络接口的属性 iptables -L 查看防火墙设置 route -n 查看路由表 netstat -lntp 查看所有监听端口 netstat -antp 查看所有已经建立的连接 netstat -s 查看网络统计信息 进程 命令 说明 ps -ef 查看所有进程 top 实时显示进程状态 用户 命令 说明 w 查看活动用户 id &lt;用户名&gt; 查看指定用户信息 last 查看用户登录日志 cut -d: -f1 /etc/passwd 查看系统所有用户 cut -d: -f1 /etc/group 查看系统所有组 crontab -l 查看当前用户的计划任务 useradd -s /sbin/nologin -M nginx 添加用户 服务 命令 说明 chkconfig –list 列出所有系统服务 程序 命令 说明 rpm -qa 查看所有安装的软件包 yum install &lt;程序名&gt; yum安装 yum search &lt;程序名&gt; yum搜索安装包 yum list 搜索yum已安装程序 tar -xcvf &lt;包名&gt; &lt;文件&gt; 打包压缩文件 tar -xzvf &lt;包名&gt; 解压缩 find / -name nginx.conf 在根目录下查找文件nginx.conf grep ‘test’ d* 显示所有以d开头的文件中包含test的行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装maven]]></title>
    <url>%2F2019%2F02%2F26%2FCentOS7%E5%AE%89%E8%A3%85maven%2F</url>
    <content type="text"><![CDATA[下载maven-3.5.4, 可以在官网中选择不同版本1wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz 解压1tar -zxvf apache-maven-3.5.4-bin.tar.gz 配置环境变量, 编辑文件:1vim /etc/profile 加入以下内容 ( 根据自己maven实际解压路径配置 )123MAVEN_HOME=/home/software/maven-3.5.4PATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOME 使配置生效1source /etc/profile 测试是否安装成功1mvn -v]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用GitLab-Runner搭建GitLab持续集成/部署环境]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%BD%BF%E7%94%A8GitLab-Runner%E6%90%AD%E5%BB%BAGitLab%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90-%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[相关背景 GitLab 是一套基于Ruby开发的开源Git项目管理应用，其提供的功能和Github类似，不同的是GitLab提供一个GitLab CE社区版本，用户可以将其部署在自己的服务器上，这样就可以用于团队内部的项目代码托管仓库。 GitLab CI 是GitLab 提供的持续集成服务(从8.0版本之后，GitLab CI已经集成在GitLab中了)，只要在你的仓库根目录下创建一个.gitlab-ci.yml 文件， 并为该项目指派一个Runner，当有合并请求或者Push操作时，你写在.gitlab-ci.yml中的构建脚本就会开始执行。 GitLab Runner 是配合GitLab CI进行构建任务的应用程序，GitLab CI负责yml文件中各种阶段流程的执行，而GitLab Runner就是具体的负责执行每个阶段的脚本执行，一般来说GitLab Runner需要安装在单独的机器上通过其提供的注册操作跟GitLab CI进行绑定，当然，你也可以让其和GitLab安装在一起，只是有的情况下，你代码的构建过程对资源消耗十分严重的时候，会拖累GitLab给其他用户提供政策的Git服务。 持续集成/部署环境 持续集成是程序开发人员在频繁的提交代码之后，能有相应的环境能对其提交的代码自动执行构建(Build)、测试(Test),然后根据测试结果判断新提交的代码能否合并加入主分支当中,而持续部署也就是在持续集成之后自动将代码部署(Deploy)到生成环境上 开启GitLab可持续集成功能, 你需要通过如下两步启用GitLab CI功能 为你的项目配置一个GitLab Runner 新建一个.gitlab-ci.yml文件在你项目的根目录 创建GitLab Runner以及配置拉取官方镜像, alpine版镜像体积比较小, 也可以使用latest版1docker pull gitlab/gitlab-runner:alpine 启动gitlab-runner容器1234docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:alpine 执行下面命令注册一个runner :1docker exec -it gitlab-runner gitlab-ci-multi-runner register 接下来出现以下内容, 根据提示输入123456789101112131415161718192021Please enter the gitlab-ci coordinator URL:# 示例：http://10.12.2.22Please enter the gitlab-ci token for this runner:# xxxxxxPlease enter the gitlab-ci description for this runner:# 示例：testPlease enter the gitlab-ci tags for this runner (comma separated):# 示例：testPlease enter the executor: docker, parallels, shell, kubernetes, docker-ssh, ssh, virtualbox, docker+machine, docker-ssh+machine:# sshPlease enter the SSH server address (e.g. my.server.com):# 10.12.2.22Please enter the SSH server port (e.g. 22):# 22 Please enter the SSH user (e.g. root):# rootPlease enter the SSH password (e.g. docker.io):# 123456Please enter path to SSH identity file (e.g. /home/user/.ssh/id_rsa):Runner registered successfully. Feel free to start it, but if it&apos;s running already the config should be automatically reloaded! 说明： gitlab ci 的地址以及token，从你要配置该runner到哪个项目，就去gitlab下该项目首页右侧设置—》CI/CD Pipelines—》Specific Runners下可以找到。 gitlab-ci tags这个很重要，在项目构建流程yaml文件里面指定tag，就是匹配使用哪个tag的runner，这里我定义了test，回头再配置文件里面就指定这个tag。 executor：执行者可以有很多种，这里我们使用ssh, 登录进入后再构建。 如果想修改注册信息, 可以编辑文件 vim /srv/gitlab-runner/config/config.toml, 内容如下:12345678910111213141516171819concurrent = 1check_interval = 0[session_server] session_timeout = 1800[[runners]] name = &quot;wta-admin&quot; url = &quot;http://10.12.2.22/&quot; token = &quot;JKLASJDFIAOSKJ&quot; executor = &quot;ssh&quot; [runners.ssh] user = &quot;root&quot; password = &quot;123456&quot; host = &quot;10.12.2.22&quot; port = &quot;22&quot; [runners.cache] [runners.cache.s3] [runners.cache.gcs] 修改完记得重启docker1docker restart gitlab-runner gitlab-runner已经配置完成。 在gitlab项目的根目录新建.gitlab-ci.yml文件gitlab-ci.yml文件是用来配置GitLab CI进行构建流程的配置文件，其采用YAML语法,所以你需要额外注意要用空格来代替缩进，而不是Tabs。.gitlab-ci.yml文件如下。查看详细配置或官方配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 利用caches字段来指定下面将要进行的job任务中需要共享的文件目录,如果没有，# 每个Job开始的时候，GitLab Runner都会删掉.gitignore里面的文件cache: key: $&#123;CI_BUILD_REF_NAME&#125; paths: - target# 利用stages关键字来定义持续构建过程中的三个阶段: package、build_docker、deploy_docker# 1. 所有 Stages 会按照顺序运行，即当一个 Stage 完成后，下一个 Stage 才会开始# 2. 只有当所有 Stages 完成后，该构建任务 (Pipeline) 才会成功# 3. 如果任何一个 Stage 失败，那么后面的 Stages 不会执行，该构建任务 (Pipeline) 失败stages: - package - build_docker - deploy_docker############################### maven打包 ################################ 定义一个叫package的Job任务, package为job名, 可随意命名。下同# stage字段声明属于package阶段，这个job会第一个执行，执行一些环境的初始化工作。# script字段指定该任务执行的内容, 由于是CentOS, 此处执行shell语句。下同package: stage: package tags: #这里的tags一定要属于注册时填的tags中，下面同理 - test script: - echo &quot;begining to execute package project&quot; - docker stop test &amp;&amp; docker rm test &amp;&amp; docker rmi test:1.0 - mvn clean install -Dmaven.test.skip=true - cp -f target/*.jar /data/ artifacts: paths: - target/*.jar # 将maven构建成功的jar包作为构建产出导出，可在下一个stage的任务中使用 目前没卵用############################### 构建镜像 ############################### build_docker: stage: build_docker script: - echo &quot;begining to execute build project&quot; - docker build -t test:1.0 /data/ tags: - test############################### 部署运行 ############################### # only字段指定需要执行的所在分支或者标签deploy_docker: stage: deploy_docker script: - echo &quot;begining to execute deploy project&quot; - docker run -d -p 80:80 --restart always --name=test test:1.0 - echo &quot;dev部署成功, 嘻嘻嘻......&quot; only: - dev tags: - testdeploy_docker: stage: deploy_docker script: - echo &quot;begining to execute deploy project&quot; - docker run -d -p 8080:80 --restart always --name=test test:1.0 - echo &quot;master部署成功, 嘻嘻嘻......&quot; only: - master tags: - test 创建完成后push到gitlab, 此时打开项目首页的Piplines标签页，会发现一个状态标识为pending的构建任务, gitlab-CI搭建完成]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab-CI</tag>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装Nginx及配置详解]]></title>
    <url>%2F2019%2F02%2F25%2Fcentos7%E5%AE%89%E8%A3%85Nginx%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx是一款轻量级的网页服务器、反向代理服务器。相较于Apache、lighttpd具有占有内存少，稳定性高等优势。它主要的用途是提供反向代理服务。 安装所需环境 gcc 安装 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装：1yum install gcc-c++ PCRE pcre-devel 安装 PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令：1yum install -y pcre pcre-devel zlib 安装 zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。1yum install -y zlib zlib-devel OpenSSL 安装 OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。1yum install -y openssl openssl-devel 安装Nginx 直接下载.tar.gz安装包，地址：https://nginx.org/en/download.html 使用wget命令下载（推荐）: 1wget -c https://nginx.org/download/nginx-1.14.2.tar.gz 解压 1tar -zxvf nginx-1.14.2.tar.gz 执行以下命令配置安装 123cd nginx-1.14.2 # 进入Nginx目录./configure # 使用默认配置make &amp;&amp; make install # 编辑安装 Nginx默认配置 12345678910111213nginx path prefix: &quot;/usr/local/nginx&quot;nginx binary file: &quot;/usr/local/nginx/sbin/nginx&quot;nginx modules path: &quot;/usr/local/nginx/modules&quot;nginx configuration prefix: &quot;/usr/local/nginx/conf&quot;nginx configuration file: &quot;/usr/local/nginx/conf/nginx.conf&quot;nginx pid file: &quot;/usr/local/nginx/logs/nginx.pid&quot;nginx error log file: &quot;/usr/local/nginx/logs/error.log&quot;nginx http access log file: &quot;/usr/local/nginx/logs/access.log&quot;nginx http client request body temporary files: &quot;client_body_temp&quot;nginx http proxy temporary files: &quot;proxy_temp&quot;nginx http fastcgi temporary files: &quot;fastcgi_temp&quot;nginx http uwsgi temporary files: &quot;uwsgi_temp&quot;nginx http scgi temporary files: &quot;scgi_temp&quot; 查找安装路径： 1whereis nginx 安装完成, 以下是Nginx常用命令:1234/usr/local/nginx/sbin/nginx –t # 测试配置文件是否正常/usr/local/nginx/sbin/nginx # 启动Nginx/usr/local/nginx/sbin/nginx -s stop # 停止Nginx/usr/local/nginx/sbin/nginx -s reload # 重新加载配置文件 开机自启动 编辑文件 rc.local1vim /etc/rc.local 在最下面增加一行:1/usr/local/nginx/sbin/nginx 设置执行权限：1chmod 755 /etc/rc.local Nginx安装完毕, 打开浏览器访问 http://localhost查看是否安装成功 配置NginxNginx配置文件nginx.conf大致分为以下几块:1234567891011121314151617181920212223mainevents &#123; ....&#125;http &#123; .... upstream myproject &#123; ..... &#125; server &#123; .... location &#123; .... &#125; &#125; server &#123; .... location &#123; .... &#125; &#125; ....&#125; nginx配置文件主要分为六个区域：main(全局设置)、events(nginx工作模式)、http(http设置)、 sever(主机设置)、location(URL匹配)、upstream(负载均衡服务器设置)。 main模块 main模块是一个全局的设置： 12345user nobody nobody;worker_processes 2;error_log /usr/local/var/log/nginx/error.log notice;pid /usr/local/var/run/nginx/nginx.pid;worker_rlimit_nofile 1024; user 指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。 worker_processes 指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。 error_log 用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。 pid 用来指定进程id的存储文件位置。 worker_rlimit_nofile 用于指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。 events 模块 events模块来用指定nginx的工作模式和连接数上限1234events &#123; use epoll; #linux平台 worker_connections 1024;&#125; use 用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在Mac中。 worker_connections 用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients=worker_processes*worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4 (注: 可能有出入) 。进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。 http 模块http模块是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块至关重要，等到反向代理和负载均衡以及虚拟目录等会仔细说。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374http&#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 charset utf-8; #默认编码 #设置日志的格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址 #第二个参数：zone=one:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息 #第三个参数：rate=1r/s表示允许相同标识的客户端的访问频次，这里限制的是每秒1次，还可以有比如30r/m的 limit_zone crawler $binary_remote_addr 10m;](limit_req_zone binary_remote_addr zone=one:10m rate=1r/s; # 第一个参数：zone=one 设置使用哪个配置区域来做限制，与上面limit_req_zone 里的name对应 # 第二个参数：burst=5，这个配置的意思是设置一个大小为5的缓冲区当有大量请求过来时，超过了访问频次限制的请求可以先放到这个缓冲区内 # 第三个参数：nodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队 server &#123; location /search/ &#123; limit_req zone=one burst=5 nodelay; &#125; &#125;&#125; include 用来设定文件的mime类型, 类型在配置文件目录下的mime.type文件定义，来告诉nginx识别文件类型。 default_type 设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置asp 的locate 环境时，Nginx是不予解析的，此时，用浏览器访问asp文件就会出现下载了。 log_format 用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来记录这种类型。 main的类型日志如下：也可以增删部分参数。1127.0.0.1 - - [21/Apr/2015:18:09:54 +0800] &quot;GET /index.php HTTP/1.1&quot; 200 87151 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36&quot; access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。 sendfile 参数用于开启高效文件传输模式。将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。 keepalive_timeout 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。 其他参数后面介绍 server 模块 sever 模块是http的子模块，它用来定一个虚拟主机，基本的配置:123456789101112131415161718192021222324252627server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.w3cschool.cn w3cschool.cn; index index.html index.htm index.php; root /data/www/w3cschool; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;&#125; server 标志定义虚拟主机开始。 listen 用于指定虚拟主机的服务端口。 server_name 用来指定IP地址或者域名，多个域名之间用空格分开。 root 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。 index 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。 access_log 用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。 location 模块 location 用来定位/解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#对 &quot;/&quot; 启用反向代理location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k;&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080;&#125; #所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d;&#125; location ~ 开启正则匹配。 后面详细介绍location的匹配规则 upstream 模块 upstream 模块用来作负载均衡1234567upstream backend&#123; ip_hash; server 192.168.12.1:80; server 192.168.12.2:80 down; server 192.168.12.3:8080 max_fails=3 fail_timeout=20s; server 192.168.12.4:8080;&#125; upstream 指令指定了一个负载均衡器的名称backend。这个名称可以任意指定，在后面需要的地方直接调用即可。 ip_hash 是其中的一种负载均衡调度算法。紧接着就是各种服务器了。用server关键字表识，后面接ip。 Nginx的负载均衡模块目前支持以下几种调度算法: weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。 ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。 fair。依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。 url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。 least_conn 下一个请求将被分派到活动连接数量最少的服务器 在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有： down，表示当前的server暂时不参与负载均衡。 backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。 max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。 fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。 注意 当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。 location匹配规则语法:1location [=|~|~*|^~] /uri/ &#123;...&#125; 符号 含义 = 表示精确匹配 ^~ 表示 URI 以某个常规字符串开头。Nginx 不对 URL 做编码，因此请求为 /static/20%/aa，可以被 ^~ /static/ /aa 匹配到 ~ 表示区分大小写的正则匹配 ~* 表示不区分大小写的正则匹配 / 通用匹配，任何请求都会匹配 多个 location 配置的情况下匹配顺序为： 首先匹配 = 其次匹配 ^~ 其次是按文件中顺序的正则匹配 最后是交给 / 当有匹配成功时候，停止匹配，按当前匹配规则处理请求 若规则如下:1234567891011121314151617181920212223location = / &#123; #规则A&#125;location = /login &#123; #规则B&#125;location ^~ /static/ &#123; #规则C&#125;location ~ \.(gif|jpg|png|js|css)$ &#123; #规则D&#125;location ~* \.png$ &#123; #规则E&#125;location / &#123; #规则F&#125; 访问根目录 /， 比如 http://localhost/ 将匹配规则 A 访问 http://localhost/login 将匹配规则 B，http://localhost/register 则匹配规则 F 访问 http://localhost/static/a.html 将匹配规则 C 访问 http://localhost/a.png 符合规则 D 和规则 E，但是只匹配较前的D， 访问 http://localhost/static/c.png 则优先匹配到规则 C 访问 http://localhost/a.PNG 则匹配规则 E，而不会匹配规则 D，因为规则 E 不区分大小写。 访问 http://localhost/category/id/1111 则最终匹配到规则 F，这个时候 nginx 可以作为反向代理服务器。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装redis及开机自启动]]></title>
    <url>%2F2019%2F02%2F25%2Fcentos7%E5%AE%89%E8%A3%85redis%E5%8F%8A%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[安装首先确认是否具有root权限，因为vim、设定redis开机启动需要root权限1su 新建软件安装目录和配置文件存放目录(已有可以不用新建)12mkdir -p /home/software # 存放redismkdir -p /usr/local/redis # 存放配置文件 下载redis, 可以在官网获取指定版本12cd /home/software # 进入安装目录wget http://download.redis.io/releases/redis-5.0.3.tar.gz #下载 依次执行以下命令123tar xzf redis-5.0.3.tar.gz # 解压缩cd redis-5.0.3 # 进入解压后的文件目录make # 编译安装 目前已经安装完毕 配置复制配置文件( 相当于备份 )123cp /home/software/redis-5.0.3/src/redis-server /usr/local/redis/cp /home/software/redis-5.0.3/src/redis-cli /usr/local/redis/cp /home/software/redis-5.0.3/redis.conf /usr/local/redis/ 编辑配置文件 redis.conf1vim /usr/local/redis/redis.conf daemonize 改为yes 后台运行123# By default Redis does not run as a daemon. Use &apos;yes&apos; if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes 把 bind 127.0.0.1注释掉, 放开ip限制 ( 可选 )1# bind 127.0.0.1 把# requirepass foobared注释放开并修改密码为123456( 可选 )1requirepass 123456 添加开机自启动服务文件1vim /etc/systemd/system/redis.service 加入以下内容, 在vim中一定要检查是否一致12345678910111213[Unit]Description=The redis-server Process ManagerAfter=syslog.target network.target[Service]Type=simplePIDFile=/var/run/redis_6379.pidExecStart=/usr/local/redis/redis-server /usr/local/redis/redis.conf ExecReload=/bin/kill -USR2 $MAINPIDExecStop=/bin/kill -SIGINT $MAINPID[Install]WantedBy=multi-user.target 设置开机自启动123systemctl daemon-reload systemctl start redis.service systemctl enable redis.service 测试redis, 启动redis客户端, 依次执行以下命令1234567/usr/local/redis/redis-cli127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; set name HoleskiOK127.0.0.1:6379&gt; get name&quot;holeski&quot; redis安装配置成功]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装mariaDB最新版]]></title>
    <url>%2F2019%2F02%2F24%2FCentOS7%E5%AE%89%E8%A3%85mariaDB%E6%9C%80%E6%96%B0%E7%89%88%2F</url>
    <content type="text"><![CDATA[安装Maria DB来自官网的包源 编辑新增文件: vim /etc/yum.repos.d/MariaDB.repo 保存以下内容 12345[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.3/centos7-amd64/gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 移除已安装的mariaDB/MySQL:12yum remove $(rpm -qa | grep -i mysql)yum remove $(rpm -qa | grep -i mari) 安装1yum install -y MariaDB-server MariaDB-client 配置数据库运行以下命令：123systemctl start mariadb # 启动mariaDBsystemctl enable mariadb # 设置开机自启动mysql_secure_installation # 开始初始化数据库 首先是设置密码，会提示先输入密码，后面是一些其他配置123456789101112131415Enter current password for root (enter for none): &lt;–初次运行直接回车Set root password? [Y/n] &lt;– 是否设置root用户密码，输入y并回车或直接回车New password: &lt;– 设置root用户的密码Re-enter new password: &lt;– 再输入一次你设置的密码Remove anonymous users? [Y/n] &lt;– 是否删除匿名用户，回车Disallow root login remotely? [Y/n] &lt;–是否禁止root远程登录,回车,Remove test database and access to it? [Y/n] &lt;– 是否删除test数据库，回车Reload privilege tables now? [Y/n] &lt;– 是否重新加载权限表，回车 初始化MariaDB完成，接下来测试登录1mysql&gt; mysql -uroot -ppassword 登录成功，查看数据库版本：1mysql&gt; select version(); 配置MariaDB的字符集 编辑文件：vi /etc/my.cnf ，在[mysqld]标签下添加12345init_connect=&apos;SET collation_connection = utf8_unicode_ci&apos; init_connect=&apos;SET NAMES utf8&apos; character-set-server=utf8 collation-server=utf8_unicode_ci skip-character-set-client-handshake 编辑文件：vi /etc/my.cnf.d/client.cnf ，在[client]下添加 ( 如果没有可以不加 )1default-character-set=utf8 编辑文件： vi /etc/my.cnf.d/mysql-clients.cnf ，在[mysql]下添加1default-character-set=utf8 全部配置完成，重启mariadb1systemctl restart mariadb 之后进入MariaDB查看字符集1mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;; 显示为：12345678910111213141516171819202122+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_unicode_ci || collation_database | utf8_unicode_ci || collation_server | utf8_unicode_ci |+----------------------+-----------------+3 rows in set (0.00 sec) 字符集配置完成。 添加用户，设置权限 创建用户命令 1mysql&gt; create user username@&apos;localhost&apos; identified by &apos;password&apos;; 授予外网登陆权限 1mysql&gt; grant all privileges on *.* to username@&apos;%&apos; identified by &apos;password&apos;; 授予权限并且可以授权 1mysql&gt; grant all privileges on *.* to username@&apos;hostname&apos; identified by &apos;password&apos; with grant option; 刷新权限 1mysql&gt; flush privileges; 安装成功。]]></content>
      <categories>
        <category>mariaDB</category>
      </categories>
      <tags>
        <tag>mariaDB</tag>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot]]></title>
    <url>%2F2019%2F01%2F31%2Fspringboot%2F</url>
    <content type="text"><![CDATA[构建微服务：Spring boot 入门篇什么是spring bootSpring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是spring boot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架（有点夸张）。 使用spring boot有什么好处其实就是简单、快速、方便！平时如果我们需要搭建一个spring web项目的时候需要怎么做呢？ 配置web.xml，加载spring和spring mvc 配置数据库连接、配置spring事务 配置加载配置文件的读取，开启注解 配置日志文件 快速入门说了那么多，手痒痒的很，马上来一发试试! maven构建项目 访问http://start.spring.io/ 选择构建工具Maven Project、Spring Boot版本1.3.6以及一些工程基本信息，点击“Switch to the full version.”java版本选择1.7。 点击Generate Project下载项目压缩包 解压后，使用IDEA Import 项目结构介绍Spring Boot的基础结构共三个文件： 123l src/main/java 程序开发以及主程序入口l src/main/resources 配置文件l src/test/java 测试程序 另外，spingboot建议的目录结果如下：root package结构：com.example.myproject 123456789101112131415com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- controller | +- CustomerController.java | Application.java 建议放到跟目录下面,主要用于做一些框架配置 domain目录主要用于实体（Entity）与数据访问层（Repository） service 层主要是业务类代码 controller 负责页面访问控制 采用默认配置可以省去很多配置，当然也可以根据自己的喜欢来进行更改。最后，启动Application main方法，至此一个java项目搭建好了！ 引入web模块 pom.xml中添加支持web的模块： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; pom.xml文件中默认有两个模块： spring-boot-starter：核心模块，包括自动配置支持、日志和YAML；spring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito。 编写controller内容1234567@RestControllerpublic class HelloWorldController &#123; @RequestMapping(&quot;/hello&quot;) public String index() &#123; return &quot;Hello World&quot;; &#125;&#125; @RestController的意思就是controller里面的方法都以json格式输出，不用再写什么jackjson配置的了！ 启动主程序，打开浏览器访问http://localhost:8080/hello，就可以看到效果了，有木有很简单！ 如何做单元测试打开的src/test/下的测试入口，编写简单的http请求来测试；使用mockmvc进行，利用MockMvcResultHandlers.print()打印出执行结果。1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = MockServletContext.class)@WebAppConfigurationpublic class HelloWorldControlerTests &#123; private MockMvc mvc; @Before public void setUp() throws Exception &#123; mvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build(); &#125; @Test public void getHello() throws Exception &#123; mvc.perform(MockMvcRequestBuilders.get(&quot;/hello&quot;).accept(MediaType.APPLICATION_JSON)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125;&#125; 开发环境的调试热启动在正常开发项目中已经很常见了吧，虽然平时开发web项目过程中，改动项目启重启总是报错；修改之后可以实时生效，需要添加以下的配置：123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab]]></title>
    <url>%2F2019%2F01%2F31%2Fgitlab%2F</url>
    <content type="text"><![CDATA[gitlab安装配置拉取gitlab镜像11. git pull gitlab/gitlab-ce]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
</search>
