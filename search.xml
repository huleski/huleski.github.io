<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SSH无密码登录]]></title>
    <url>%2F2023%2F03%2F08%2FSSH%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[环境: 本机Linux, 远程Linux 首先我们在本机Linux系统上生成一对SSH Key：SSH密钥和SSH公钥．密钥保存在本机Linux系统上。 然后公钥上传到远程Linux服务器．之后我们就能在本机Linux无密码SSH登录远程Linux了．SSH密钥就好比是你的身份证明． 本机Linux生成秘钥在本机Linux命令行使用 ssh-keygen 生成密钥和公钥, 也可以添加参数: 1ssh-keygen -b 4096 -t rsa -b是指定生成秘钥长度为4096, 默认是2048 -t表示加密类型, 默认是RSA加密 生成SSH Key的过程中会要求你指定一个文件来保存密钥，按Enter键使用默认的文件就行了．然后需要输入一个密码来加密你的SSH Key．密码至少要5位长度． 生成过程如下: 1234567891011121314151617181920Generating public/private rsa key pair.Enter file in which to save the key (/home/.ssh/id_rsa): 按Enter键Enter passphrase (empty for no passphrase): 输入一个密码Enter same passphrase again: 再次输入密码Your identification has been saved in ~/.ssh/id_rsa.Your public key has been saved in ~/.ssh/id_rsa.pub.The key fingerprint is:e1:dc:ab:ae:b6:19:b0:19:74:d5:fe:57:3f:32:b4:d0 matrix@vividThe key's randomart image is:+---[RSA 4096]----+| .. || . . || . . .. . || . . o o.. E .|| o S ..o ...|| = ..+...|| o . . .o .|| .o . || .++o |+-----------------+ SSH密钥会默认保存在 ~/.ssh/id_rsa文件中．SSH公钥保存在 ~/.ssh/id_rsa.pub 文件中． 远程连接Linux使用ssh-copy-id命令将SSH公钥上传到远程Linux服务器 1ssh-copy-id username@remote-server 输入远程用户密码后, SSH公钥就会自动上传了．SSH公钥保存在远程Linux服务器的 ~/.ssh/authorized_keys 文件中． 上传完成后，SSH登录就不需要再次输入密码了．但是首次使用SSH Key登录时需要输入一次SSH密钥的加密密码．（只需要输入一次，将来会自动登录，不再需要输入密钥的密码） 测试一下远程ssh查看系统版本:1ssh -p 22 username@remote-server "cat /etc/redhat-release" OK! 以后使用scp命令来传送文件时也不需要输入密码了．]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker部署shadowsocksR]]></title>
    <url>%2F2023%2F02%2F17%2Fdocker%E9%83%A8%E7%BD%B2shadowsocksR%2F</url>
    <content type="text"><![CDATA[前期准备 系统: CentOS7 环境：docker 17.0 一台在 境外/国外 的云服务器 一键部署: 1234567docker run -d --name ssr \ -p 38989:8989 -p 38989:8989/udp malaohu/ssr-with-net-speeder \ -s 0.0.0.0 -p 8989 \ -k 123456 \ -m rc4-md5 \ -o http_simple \ -O auth_sha1_v4 123456解释一下服务器端口：38989密码：123456加密：rc4-md5协议：auth_sha1_v4 这里需要注意，auth_sha1这个协议已经被此软件弃用了，注意有_v4混淆：http_simple 最后, 需要放开云服务器的38989端口访问权限(tcp和udp), 可以访问了 血泪总结(写于搭建SSR后的第3天)阿里云香港服务器公网ip被墙了，服务器已作废，***，退钱！ ####不要用阿里云！ 不要用阿里云！不要用阿里云！#这里不是家！！！ T_T]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>shadowsocksR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot集成ELK]]></title>
    <url>%2F2021%2F12%2F16%2FSpringboot%E9%9B%86%E6%88%90ELK%2F</url>
    <content type="text"><![CDATA[ELK简介ELK是由 Elasticsearch、Logstash和Kibana 三部分组件组成。 Elasticsearch 是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 Logstash 是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。一般工作方式为c/s架构，client端安装在需要收集日志的主机上（本例中为集成在Springboot项目中），server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。 kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。 在本示例中, 工作流畅是: Springboot集成Logstash收集日志, 再把日志发送到ElasticSearch中, 最后用户通过kibana连接ElasticSearch查看日志数据 ELK安装直接使用docker-compose安装简单粗暴, 不整那些花里胡哨的操作, 先新建目录: mkdir -p /data/elk/{elasticsearch/data,kibana,logstash,} 保存配置文件: docker-compose.yml (软件版本要统一, 当前最新版为 7.16.1) : 123456789101112131415161718192021222324252627282930313233343536373839version: '3'services: elasticsearch: image: elasticsearch:7.16.1 #镜像 container_name: elk_elasticsearch #定义容器名称 restart: always #开机启动，失败也会一直重启 environment: - "cluster.name=elasticsearch" #设置集群名称为elasticsearch - "discovery.type=single-node" #以单一节点模式启动 - "ES_JAVA_OPTS=-Xms512m -Xmx1024m" #设置使用jvm内存大小 volumes: - /data/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins #插件文件挂载 - /data/elk/elasticsearch/data:/usr/share/elasticsearch/data #数据文件挂载 ports: - 9200:9200 kibana: image: kibana:7.16.1 container_name: elk_kibana restart: always depends_on: - elasticsearch #kibana在elasticsearch启动之后再启动 environment: - ELASTICSEARCH_URL=http://elasticsearch:9200 #设置访问elasticsearch的地址 volumes: - /data/elk/kibana/config:/opt/kibana/config #配置文件挂载 ports: - 5601:5601 logstash: image: logstash:7.16.1 container_name: elk_logstash restart: always volumes: - /data/elk/logstash/logstash-springboot.conf:/usr/share/logstash/pipeline/logstash.conf #挂载logstash的配置文件 depends_on: - elasticsearch #kibana在elasticsearch启动之后再启动 links: - elasticsearch:es #可以用es这个域名访问elasticsearch服务 ports: - 4560:4560 123456789101112131415161718192021222324# 授权目录cd /data/elkchmod 777 elasticsearch/data# 新建logstash/logstash-springboot.conf文件，新增以下内容input &#123; tcp &#123; mode =&gt; "server" host =&gt; "0.0.0.0" port =&gt; 4560 codec =&gt; json_lines &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; "es:9200" index =&gt; "springboot-logstash-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;# 安装，运行ELKdocker-compose up -d# 查看容器运行状态docker ps 等一会容器都启动成功了就打开浏览器访问Kibana: http://localhost:5601, 正常情况就会出现欢迎界面 汉化kibana编辑配置文件 /data/elk/kibana/config/kibana.yml, 新增: i18n.locale: zh-CN 改完配置后重启kibana: docker restart elk_kibana Springboot整合Logstash在pom.xml新增依赖 12345&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;7.0.1&lt;/version&gt;&lt;/dependency&gt; 修改Springboot项目中日志配置文件logback.xml, 在相应位置增加配置: 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false" scan="true" scanPeriod="1 seconds"&gt; &lt;appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender"&gt; &lt;destination&gt;localhost:4560&lt;/destination&gt; &lt;encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder"/&gt; &lt;/appender&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="LOGSTASH" /&gt; &lt;/root&gt;&lt;/configuration&gt; 启动Springboot项目后再查看kibana就可以看到日志了]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置目录浏览及美化主题]]></title>
    <url>%2F2021%2F11%2F30%2Fnginx%E9%85%8D%E7%BD%AE%E7%9B%AE%E5%BD%95%E6%B5%8F%E8%A7%88%E5%8F%8A%E7%BE%8E%E5%8C%96%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[nginx可以配置浏览目录服务, 这样用户可以直接在浏览器中查看文件目录, 并且可以下载文件, 非常方便 ngx_http_autoindex_module 模块目录浏览服务由ngx_http_autoindex_module模块提供 命令 默认值 值域 作用域 例子 autoindex off on：开启目录浏览；off：关闭目录浏览 http, server, location autoindex on; 打开目录浏览功能 autoindex_format html html、xml、json、jsonp 分别用这几个风格展示目录 http, server, location autoindex_format html; 以网页的风格展示目录内容。该属性在1.7.9及以上适用 autoindex_exact_size on on：展示文件字节数；off：以可读的方式显示文件大小 http, server, location autoindex_exact_size off; 以可读的方式显示文件大小，单位为 KB、MB 或者 GB，autoindex_format为html时有效 autoindex_localtime off on、off：是否以服务器的文件时间作为显示的时间 http, server, location autoindex_localtime on; 以服务器的文件时间作为显示的时间,autoindex_format为html时有效 修改nginx配置 12345678910111213141516server &#123; listen 10000; server_name localhost; location / &#123; root /home; # 开启目录浏览 autoindex on; # 以可读的方式显示文件大小 autoindex_exact_size off; # 以服务器的文件时间作为显示的时间 autoindex_localtime on; # 展示中文文件名 charset utf-8,gbk; &#125;&#125; 执行命令 nginx -s reload 重载配置, 打开浏览器访问 http://localhost:10000 就可以在浏览器中访问 /home 目录中的文件了, 但是nginx原始的目录很简陋, 不是正常人看的, 可以美化一下 安装Nginx FancyIndex模块先安装所需模块 FancyIndex, 在nginx的源码文件夹下下载插件: 1git clone https://github.com/aperezdc/ngx-fancyindex.git ngx-fancyindex 查看已安装的nginx完整编译参数: 1nginx -V 控制台会打印出参数: 123456nginx version: nginx/1.16.1built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body --http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi --http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi --pid-path=/run/nginx.pid --lock-path=/run/lock/subsys/nginx --user=nginx --group=nginx --with-file-aio --with-ipv6 --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-stream_ssl_preread_module --with-http_addition_module --with-http_xslt_module=dynamic...(略) configure arguments:后面一大串的都是编译参数, 复制下来, 执行: 12./configure --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body --http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi --http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi --pid-path=/run/nginx.pid --lock-path=/run/lock/subsys/nginx --user=nginx --group=nginx --with-file-aio --with-ipv6 --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-stream_ssl_preread_module --with-http_addition_module --with-http_xslt_module=dynamic...(略) --add-module=ngx-fancyindex-0.4.2 也就是 ./configure 跟着上面复制的一大串再加上 --add-module=ngx-fancyindex-0.4.2 执行就可以了, 如果执行过程中有报错缺少什么依赖组件就网上搜一下, 少什么安装什么, 转好了再执行直到成功 再执行编译:1make 再执行: 12&gt;&amp;1 ./nginx -V | tr ' ' '\n'|grep fan 如果看到输出 ngx-fancyindex 就说明编译好了 先备份原来的nginx文件(如果有问题可以还原) 12# /usr/sbin/nginx 是原执行文件mv /usr/sbin/nginx /usr/sbin/nginx.bak 把编译目录中objs文件中的nginx移过去就安装完成了: 1mv objs/nginx /usr/sbin/ 选择Fancy Index主题在 /home 目录中下载Fancy Index主题: 1git clone https://github.com/lanffy/Nginx-Fancyindex-Theme.git 修改nginx配置 123456789101112131415161718server &#123; listen 10000; server_name localhost; location / &#123; root /home; # 开启目录浏览 autoindex on; # 以可读的方式显示文件大小 autoindex_exact_size off; # 以服务器的文件时间作为显示的时间 autoindex_localtime on; # 展示中文文件名 charset utf-8,gbk; # 新增目录美化配置 include /home/Nginx-Fancyindex-Theme/fancyindex.conf; &#125;&#125; 重启Nginx即可 1nginx -s reload]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7调整根目录和home目录的空间大小]]></title>
    <url>%2F2021%2F07%2F09%2FCentOS7%E8%B0%83%E6%95%B4%E6%A0%B9%E7%9B%AE%E5%BD%95%E5%92%8Chome%E7%9B%AE%E5%BD%95%E7%9A%84%E7%A9%BA%E9%97%B4%E5%A4%A7%E5%B0%8F%2F</url>
    <content type="text"><![CDATA[当安装完 CentOS7 操作系统，发现磁盘分区大小错误，或者后期使用过程发现 /home 还剩余很多空间，/ 下空间不足，需要将 /home 下空间重新分配给 / 目录。 查看分区空间和格式123456789[root@localhost portainer]$ df -hT文件系统 类型 容量 已用 可用 已用% 挂载点devtmpfs devtmpfs 3.8G 0 3.8G 0% /devtmpfs tmpfs 3.8G 0 3.8G 0% /dev/shmtmpfs tmpfs 3.8G 51M 3.8G 2% /runtmpfs tmpfs 3.8G 0 3.8G 0% /sys/fs/cgroup/dev/mapper/centos-root xfs 50G 27G 23G 56% //dev/sda1 xfs 1014M 193M 822M 19% /boot/dev/mapper/centos-home xfs 873G 33M 873G 1% /home 这里 /dev/mapper/centos-root 就是根目录, 只有50G太小了, 而 /dev/mapper/centos-home 有800多G, 因此可以分一部分 /home 给 /目录 可以看到 /home 分区是 xfs 格式，这里特别注意： ext2/ext3/ext4文件系统的调整命令是resize2fs（增大和减小都支持） 12345lvextend -L 120G /dev/mapper/centos-home //增大至120Glvextend -L +20G /dev/mapper/centos-home //增加20Glvreduce -L 50G /dev/mapper/centos-home //减小至50Glvreduce -L -8G /dev/mapper/centos-home //减小8Gresize2fs /dev/mapper/centos-home //执行调整 xfs文件系统的调整命令是xfs_growfs（只支持增大） 123lvextend -L 120G /dev/mapper/centos-home //增大至120Glvextend -L +20G /dev/mapper/centos-home //增加20Gxfs_growfs /dev/mapper/centos-home //执行调整 就是说：xfs文件系统只支持增大分区空间的情况，不支持减小的情况 硬要减小的话，只能在减小后将逻辑分区重新通过 mkfs.xfs 命令重新格式化才能挂载上，这样的话这个逻辑分区上原来的数据就丢失了。如果有重要文件就先复制备份到其他地方, 然后再进行下面的操作 1234567891011121314151617# 卸载 /home 分区 (注意: 不要在home目录下执行这个操作)umount /home# 将 /home 分区减小600G（根据自己实际情况设定大小）lvreduce -L -600G /dev/mapper/centos-home# 格式化 /home 分区mkfs.xfs /dev/mapper/centos-home -f# 重新挂载 /home 分区mount /dev/mapper/centos-home /home/# 查看剩余空间vgdisplay# 上面空余的 600G 分到 / 分区下lvextend -L +600G /dev/mapper/centos-root 再次查看分区, 分配成功 123456789[root@localhost portainer]$ df -h文件系统 容量 已用 可用 已用% 挂载点devtmpfs 3.8G 0 3.8G 0% /devtmpfs 3.8G 0 3.8G 0% /dev/shmtmpfs 3.8G 51M 3.8G 2% /runtmpfs 3.8G 0 3.8G 0% /sys/fs/cgroup/dev/mapper/centos-root 650G 27G 624G 5% //dev/sda1 1014M 193M 822M 19% /boot/dev/mapper/centos-home 273G 33M 273G 1% /home]]></content>
      <categories>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装docker]]></title>
    <url>%2F2021%2F07%2F08%2FCentOS7%E5%AE%89%E8%A3%85docker%2F</url>
    <content type="text"><![CDATA[Docker 官方建议要 CentOS7.0 及以上系统版本，本文介绍 Docker CE 在CentOS7下的安装使用。 Device MapperDocker默认使用AUFS作为存储驱动，但是AUFS并没有被包括在Linux的主线内核中。 1234# 安装yum install -y device-mapper# 重新加载dm_mod内核模块modprobe dm_mod 环境准备123456789101112131415# 卸载旧版本yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine# 安装编译环境yum -y install gcc gcc-c++# 安装依赖包yum install -y yum-utils device-mapper-persistent-data lvm2# 设置stable镜像仓库, 下面二选一1. yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo2. yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 更新yum软件包索引yum makecache fast 安装配置1234567891011121314#从高到低列出Docker-ce的版本yum list docker-ce.x86_64 --showduplicates | sort -r # 安装最新版yum -y install docker-ce# 启动dockersystemctl start docker# 让docker开机自启动systemctl enable docker# 查看docker版本docker -v 修改容器默认存储路径 docker安装之后默认的服务数据存放根路径为/var/lib/docker目录下，var目录默认使用的是根分区的磁盘空间；所以这是非常危险的事情；随着我们镜像、启动的容器实例开始增多的时候，磁盘所消耗的空间也会越来越大，所以我们必须要做数据迁移和修改docker服务的默认存储位置路径；有多种方式是可以修改docker默认存储目录路径的，但是最好是在docker安装完成后，第一时间便修改docker的默认存储位置路径为其他磁盘空间较大的目录(一般企业中为/data目录)，规避迁移数据过程中所造成的风险。 12345678# 创建docker容器存放的路径mkdir -p /home/data/docker# 停止dockersystemctl stop docker# 迁移数据到新目录rsync -avz /var/lib/docker/ /home/data/docker/ 编辑docker配置文件 vim /etc/docker/daemon.json, 指定存储路劲 1"graph":"/home/data/docker" 设置docker容器日志大小限制编辑docker配置文件 vim /etc/docker/daemon.json,添加log-dirver和log-opts参数。 1234&#123; "log-driver":"json-file" "log-opts":&#123;"max-size":"500m","max-file":"3"&#125;&#125; max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决。 Docker国内镜像： 网易加速器：http://hub-mirror.c.163.com 官方中国加速器：https://registry.docker-cn.com ustc的镜像：https://docker.mirrors.ustc.edu.cn 编辑docker配置文件 vim /etc/docker/daemon.json, 加入以下配置 1"registry-mirrors": ["https://hub-mirror.c.163.com"] 开启docker API(开启docker远程访问管理)在 /etc/docker/daemon.json 文件中添加 12// 不限制ip"hosts":["tcp://0.0.0.0:2375", "unix:///var/run/docker.sock"] 配置好后docker却异常报错了, 这里需要修改启动文件 /usr/lib/systemd/system/docker.service 12# ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 注释掉改为下面这样ExecStart=/usr/bin/dockerd 然后执行以下步骤即可 123systemctl daemon-reloadsystemctl reset-failed docker.servicesystemctl restart docker 安装docker-compose12345# 获取脚本curl -L "https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose# 添加可执行权限chmod +x /usr/local/bin/docker-compose 单容器的日志限制配置1234567nginx: image: nginx:1.12.1 restart: always logging: driver: "json-file" options: max-size: "5g"]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab版本升级]]></title>
    <url>%2F2021%2F07%2F08%2Fgitlab%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[以前用的gitlab-ce是别人构建的中文版镜像, 版本太低, 作者现在也没有再维护更新, 而官方最新版现在已支持中文, 所以打算升级gitlab。 当前的gitlab版本：V10.7.5，准备更新到最新版V14.0.4 Gitlab官方升级版本指南 数据备份和恢复（可选）为了防止更新失败后能够复原，可以备份数据（实际上我没有备份上来就是干。。。） 备份进入docker容器输入命令备份数据 1gitlab-rake gitlab:backup:create 完成后会在 /var/opt/gitlab/backups/ 文件夹下生成备份文件 1572606813_gitlab_backup.tar， 其中，1572606813 是备份版本号后面会用到，然后将文件从容器中复制出来留作备份。 恢复等gitlab的docker镜像启动后将备份文件复制进容器到gitlab的备份目录 backup 文件夹下, 在gitlab容器执行命令： 1gitlab-rake gitlab:backup:restore BACKUP=备份版本号 还原备份，这里实际执行：gitlab-rake gitlab:backup:restore BACKUP=1572606813 版本升级由于不同版本之间的差异导致不能直接升级到指定版本, 必须经过中间版本过渡升级到指定版本, 下面是升级版本路线: 8.11.Z -&gt; 8.12.0 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.8.7 -&gt; 11.11.8 -&gt; 12.0.12 -&gt; 12.1.17 -&gt; 12.10.14 -&gt; 13.0.14 -&gt; 13.1.11 -&gt; latest 13.12.Z -&gt; latest 14.0.Z -&gt; latest 14.Y.Z 升级过程就是启动不同的docker版本, 由低到高逐步升级成功]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用frp实现内网穿透]]></title>
    <url>%2F2021%2F05%2F24%2F%E4%BD%BF%E7%94%A8frp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%2F</url>
    <content type="text"><![CDATA[FRP作用 FRP是一个内网穿透工具FRP让本地局域网的机器可以暴露到公网，简单的说就是在世界的任何地方，你可以访问家里开着的那台电脑!FRP 支持 TCP、UDP、HTTP、HTTPS， 就是说不仅仅限于本地web服务器可以暴露，整台机器都可以暴露。 1.在办公室访问家里的电脑，反之亦然（可以使用NAS+FRP实现私有云盘） 2.自己电脑上的项目，方便发给客户朋友演示。比如我做了个小网站，发给朋友看看未上线版本，发个url给他就好了。 3.调试一些需要远程调用的程序，远程调用比如微信的API 回调接口。 因为我有了外网地址就不需要部署在公网服务器，直接进行本地调试。 下载安装下载地址获取压缩包 https://github.com/fatedier/frp/releases/download/v0.33.0/frp_0.33.0_linux_amd64.tar.gz 在安装的时候注意一下, 我们需要在公网服务器上安装服务端, 然后在本地电脑安装客户端, 这个压缩包里面已经同时包含了服务端和客户端, 安装都是一样的(都是Linux环境), 解压即可 123tar -zxvf frp_0.33.0_linux_amd64.tar.gzmv frp_0.33.0_linux_amd64 /usr/local/frpcd /usr/local/frp 文件介绍123456frpc # 客户端二进制文件frpc_full.ini # 客户端配置文件完整示例frpc.ini # 客户端配置文件frps # 服务端二进制文件frps_full.ini # 服务端配置文件完整示例frps.in1 # 服务端配置文件 配置服务端需要在安装在有公网的服务器上(例如公网ip:233.233.233.233), 配置文件在安装目录下的frps.ini, 编辑为以下内容 123bind_port = 7001vhost_http_port = 7002vhost_https_port = 7003 启动服务端 1nohup ./frps -c ./frps.ini &amp; 或者将frps注册为系统服务, 编辑文件 vim /usr/lib/systemd/system/frps.service 123456789101112[Unit]Description=frp serverAfter=network.target[Service]Type=simpleExecStart=/usr/local/frp/frps -c /usr/local/frp/frps.iniExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID[Install]WantedBy=multi-user.target 然后就可以用系统命令管理服务了 123systemctl enable frpssystemctl start frpssystemctl status frps 客户端需要安装在本地需要映射服务的电脑上, 配置文件在安装目录下的frpc.ini, 编辑为以下内容 123456789[common]server_addr = 233.233.233.233server_port = 7001[abc]type = tcplocal_ip = 127.0.0.1local_port = 2000remote_port = 2000 启动客户端 1nohup ./frpc -c ./frpc.ini &amp; 现在本地服务就能在外网通过233.233.233.233:2000访问到了。 如果有独立域名, 可以在服务端配置nginx反向代理转发域名到localhost:2000即可通过域名访问。 将frpc注册为系统服务, 编辑文件 vim /usr/lib/systemd/system/frpc.service, 内容: 1234567891011121314[Unit]Description=Frp Client ServiceAfter=network.target[Service]Type=simpleUser=nobodyRestart=on-failureRestartSec=5sExecStart=/usr/local/frp/frpc -c /usr/local/frp/frpc.iniExecReload=/usr/local/frp/frpc reload -c /usr/local/frp/frpc.ini[Install]WantedBy=multi-user.target]]></content>
      <categories>
        <category>frp</category>
      </categories>
      <tags>
        <tag>frp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose安装redis]]></title>
    <url>%2F2021%2F03%2F12%2Fdocker-compose%E5%AE%89%E8%A3%85redis%2F</url>
    <content type="text"><![CDATA[编写yml文件 123456789101112version: '3'services: redis: image: redis:latest restart: always container_name: redis-server command: redis-server /etc/redis/redis.conf volumes: - /root/middleware/redis/data:/data - /root/middleware/redis/redis.conf:/etc/redis/redis.conf ports: - "6379:6379" 同级目录中创建配置文件 reids.conf 12requirepass 123456appendonly yes 启动镜像 1docker-compose up -d]]></content>
      <categories>
        <category>docker-compose</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose安装MariaDB]]></title>
    <url>%2F2021%2F03%2F12%2Fdocker-compose%E5%AE%89%E8%A3%85MariaDB%2F</url>
    <content type="text"><![CDATA[创建docker-compose.yml文件 1234567891011121314151617181920212223version: '3'services: mariadb: container_name: mariadb image: mariadb environment: # root 密码 - MYSQL_ROOT_PASSWORD=root123 # root 允许登录的host - MYSQL_ROOT_HOST=% # 时区 - TIME_ZONE=Asia/Shanghai ports: - 3306:3306 volumes: # 容器与宿主机时间同步 - /etc/localtime:/etc/localtime # 数据库目录映射 - /data/mariadb/data/:/var/lib/mysql # 数据库配置文件 - /data/mariadb/config:/etc/mysql/conf.d privileged: true restart: always 在宿主机的配置目录/data/mariadb/config中创建自定义配置文件: 1vim my.cnf 配置文件内容: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[client]port = 3306socket = /var/run/mysqld/mysqld.sockdefault-character-set = utf8mb4# Here is entries for some specific programs# The following values assume you have at least 32M ram# This was formally known as [safe_mysqld]. Both versions are currently parsed.[mysqld_safe]socket = /var/run/mysqld/mysqld.socknice = 0[mysqld]character-set-server=utf8mb4collation-server=utf8mb4_unicode_cilower_case_table_names = 1pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockport = 3306basedir = /usrdatadir = /var/lib/mysqltmpdir = /tmplc_messages_dir = /usr/share/mysqllc_messages = en_USskip-external-lockingmax_connections = 1000connect_timeout = 5wait_timeout = 600max_allowed_packet = 16Mthread_cache_size = 128sort_buffer_size = 4Mbulk_insert_buffer_size = 16Mtmp_table_size = 32Mmax_heap_table_size = 32M# This replaces the startup script and checks MyISAM tables if needed# the first time they are touched. On error, make copy and try a repair.myisam_recover_options = BACKUPkey_buffer_size = 128M#open-files-limit = 2000table_open_cache = 400myisam_sort_buffer_size = 512Mconcurrent_insert = 2read_buffer_size = 2Mread_rnd_buffer_size = 1Mquery_cache_limit = 128Kquery_cache_size = 64Mslow_query_log_file = /var/log/mysql/mariadb-slow.loglong_query_time = 10#log_slow_rate_limit = 1000#log_slow_verbosity = query_plan#sync_binlog = 1expire_logs_days = 10max_binlog_size = 100M# InnoDB is enabled by default with a 10MB datafile in /var/lib/mysql/.# Read the manual for more InnoDB related options. There are many!default_storage_engine = InnoDB# you can&apos;t just change log file size, requires special procedure#innodb_log_file_size = 50Minnodb_buffer_pool_size = 256Minnodb_log_buffer_size = 8Minnodb_file_per_table = 1innodb_open_files = 400innodb_io_capacity = 400innodb_flush_method = O_DIRECT[galera][mysqldump]quickquote-namesmax_allowed_packet = 16M[mysql]default-character-set = utf8mb4[isamchk]key_buffer = 16M!include /etc/mysql/mariadb.cnf!includedir /etc/mysql/conf.d/ 保存后启动镜像: docker-compose up -d 启动成功后可进入镜像查看myql运行情况 123456# 进入镜像$ docker exec -it mariadb /bin/bash# 登录mariadb&gt; mysql -uroot -p123456# 查看编码&gt; show variables like '%character%' 创建数据库时指定编码 1CREATE DATABASE `user` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;]]></content>
      <categories>
        <category>docker-compose</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker镜像的导入导出]]></title>
    <url>%2F2021%2F03%2F12%2Fdocker%E9%95%9C%E5%83%8F%E7%9A%84%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%2F</url>
    <content type="text"><![CDATA[docker镜像导入导出的主要命令: export、import、save、load save命令 docker save [options] images [images…] 示例 docker save -o nginx.tar nginx:latest 或 docker save &gt; nginx.tar nginx:latest 其中-o和&gt;表示输出到文件，nginx.tar为目标文件，nginx:latest是源镜像名（name:tag） load命令 docker load [options] 示例 docker load -i nginx.tar 或 docker load &lt; nginx.tar 其中-i和&lt;表示从文件输入。会成功导入镜像及相关元数据，包括tag信息 export命令 docker export [options] container 示例 docker export -o nginx-test.tar nginx-test 其中-o表示输出到文件，nginx-test.tar为目标文件，nginx-test是源容器名（name） import命令 docker import [options] file|URL|- [REPOSITORY[:TAG]] 示例 docker import nginx-test.tar nginx:imp 或 cat nginx-test.tar | docker import - nginx:imp 区别 export命令导出的tar文件略小于save命令导出的 export命令是从容器（container）中导出tar文件，而save命令则是从镜像（images）中导出 基于第二点，export导出的文件再import回去时，无法保留镜像所有历史（即每一层layer信息，不熟悉的可以去看Dockerfile），不能进行回滚操作；而save是依据镜像来的，所以导入时可以完整保留下每一层layer信息。 若是只想备份images，使用save、load即可 若是在启动容器后，容器内容有变化，需要备份，则使用export、import]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo基本命令]]></title>
    <url>%2F2021%2F03%2F12%2FHexo%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[由于不是经常使用hexo写笔记, 偶尔会有忘记的时候, 所以就记下来常用的基本命令 123456# 创建新文件$ hexo new [layout] &lt;title&gt;# 生成文件并部署$ hexo g -d# 启动服务$ hexo s 预知详情如何, 请看 Hexo官网文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装rabbitmq]]></title>
    <url>%2F2020%2F10%2F12%2Fdocker%E5%AE%89%E8%A3%85rabbitmq%2F</url>
    <content type="text"><![CDATA[下载镜像进入docker hub官方镜像仓库 搜索rabbitMq，进入官方的镜像，可以看到以下几种类型的镜像；我们选择带有“mangement”的版本（包含web管理页面） 编写docker-compose文件 docker-compose.yml 123456789101112131415version: '3'services: rabbitmq: container_name: rabbitmq image: rabbitmq:management-alpine:3.8.9 environment: - RABBITMQ_DEFAULT_USER=root - RABBITMQ_DEFAULT_PASS=123456 ports: - 5672:5672 - 15672:15672 volumes: - /root/middleware/rabbitmq/data:/var/lib/rabbitmq privileged: true restart: always 启动容器(在docker-compose.yml文件同级目录执行) 1docker-compose up -d 启动rabbitmq_management 1docker exec -it rabbit rabbitmq-plugins enable rabbitmq_management 现在已经启动完成了, 浏览器打开web管理端：http://ip:15672 输入前面docker-compose里面设置的用户名密码登录即可 官方安装的默认是不带延迟队列插件的, 需要自己安装 docker构建延迟队列插件rabbitmq前面已经下载好镜像了, 另外需要下载插件 官方插件下载地址：github下载, 选择对应版本, 这里我们同样选3.8.9版本下载, 放到服务器上 创建DockerFile文件(在插件同级目录, 插件名为rabbitmq_delayed_message_exchange-3.8.9.ez), 内容如下 123FROM rabbitmq:3-managementCOPY ["rabbitmq_delayed_message_exchange-3.8.9.ez" , "/plugins/"]RUN rabbitmq-plugins enable rabbitmq_delayed_message_exchange rabbitmq_management 开始打包构建 1docker build -t holeski/rabbitmq-delay:3.8.9 . 修改docker-compose.yml文件: 123456789101112131415version: '3'services: rabbitmq: container_name: rabbitmq image: holeski/rabbitmq-delay:3.8.9 environment: - RABBITMQ_DEFAULT_USER=root - RABBITMQ_DEFAULT_PASS=123456 ports: - 5672:5672 - 15672:15672 volumes: - /root/middleware/rabbitmq/data:/var/lib/rabbitmq privileged: true restart: always 现在可以一个命令启动就行了 1docker-compose up -d 镜像已上传到dockerhub, 可以直接拉取使用 1docker pull holeski/rabbitmq-delay:3.8.9]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 8 本新特性]]></title>
    <url>%2F2019%2F11%2F12%2Fjava%208%20%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[官网介绍 参考: 【译】Java 8的新特性—终极版 Lambda 表达式 和 函数式接口 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 12345678910111213141516171819// Function&lt;T, R&gt; -T作为输入， 返回的R作为输出Function&lt;String,String&gt; fun = (x) -&gt; &#123;System.out.print(x+&quot;: &quot;);return &quot;Function&quot;;&#125;;System.out.println(function.apply(&quot;hello world&quot;));//Predicate&lt;T&gt; -T作为输入， 返回的boolean值作为输出Predicate&lt;String&gt; pre = (x) -&gt;&#123;System.out.print(x);return false;&#125;;System.out.println(&quot;: &quot;+pre.test(&quot;hello World&quot;));//Consumer&lt;T&gt; - T作为输入， 执行某种动作但没有返回值Consumer&lt;String&gt; con = (x) -&gt; &#123;System.out.println(x);&#125;;con.accept(&quot;hello world&quot;);//Supplier&lt;T&gt; - 没有任何输入， 返回TSupplier&lt;String&gt; supp = () -&gt; &#123;return &quot;Supplier&quot;;&#125;;System.out.println(supp.get());//BinaryOperator&lt;T&gt; -两个T作为输入， 返回一个T作为输出， 对于“reduce”操作很有用BinaryOperator&lt;String&gt; bina = (x,y) -&gt;&#123;System.out.print(x+&quot; &quot;+y);return &quot;Binary Operator&quot;;&#125;;System.out.println(&quot; &quot;+bina.apply(&quot;hello &quot;,&quot;world&quot;)) 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 应用范围扩大的注解, 可以重复注解, 更好的类型推断 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 流的特点 只能遍历一次 我们可以把流想象成一条流水线， 流水线的源头是我们的数据源(一个集合)， 数据源中的元素依次被输送到流水线上， 我们可以在流水线上对元素进行各种操作。 一旦元素走到了流水线的另一头， 那么这些元素就被“消费掉了” ， 我们无法再对这个流进行操作。 当然，我们可以从数据源那里再获得一个新的流重新遍历一遍。 采用内部迭代方式 若要对集合进行处理， 则需我们手写处理代码， 这就叫做外部迭代。 而要对流进行处理， 我们只需告诉流我们需要什么结果， 处理过程由流自行完成， 这就称为内部迭代。 流的操作种类 流的操作分为两种， 分别为中间操作和终端操作。 中间操作 当数据源中的数据上了流水线后， 这个过程对数据进行的所有操作都称为“中间操作” 。中间操作仍然会返回一个流对象， 因此多个中间操作可以串连起来形成一个流水线。 终端操作 当所有的中间操作完成后， 若要将数据从流水线上拿下来， 则需要执行终端操作。终端操作将返回一个执行结果， 这就是你想要的数据 List 转 Stream 1234// 转streamlist.stream()// 并发处理list.parallelStream() filter（ 过滤） 1Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate); map（ 元素转换） 1234&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper);IntStream mapToInt(ToIntFunction&lt;? super T&gt; mapper);LongStream mapToLong(ToLongFunction&lt;? super T&gt; mapper);DoubleStream mapToDouble(ToDoubleFunction&lt;? super T&gt; mapper); flatMap（ 元素转换） 123&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T, ? extends Stream&lt;? extends R&gt;&gt; mapper); IntStream flatMapToInt(Function&lt;? super T, ? extends IntStream&gt; mapper);LongStream flatMapToLong(Function&lt;? super T, ? extends LongStream&gt; mapper);DoubleStream flatMapToDouble(Function&lt;? super T, ? extends DoubleStream&gt; mapper); distinct（ 去除重复， 对象需要重写 equals、 hashCode） 1Stream&lt;T&gt; distinct(); sorted（ 排序） 12Stream&lt;T&gt; sorted();Stream&lt;T&gt; sorted(Comparator&lt;? super T&gt; comparator); peek（ 生成新的流： 流是单向的， 例如用于日志打印） 1Stream&lt;T&gt; peek(Consumer&lt;? super T&gt; action); limit（ 取前面 n 个元素） 1Stream&lt;T&gt; limit(long maxSize); skip（ 跳过 n 个元素） 1Stream&lt;T&gt; skip(long n); forEach（ 遍历） 12void forEach(Consumer&lt;? super T&gt; action);void forEachOrdered(Consumer&lt;? super T&gt; action); toArray（ 转换成数组） 12Object[] toArray();&lt;A&gt; A[] toArray(IntFunction&lt;A[]&gt; generator); reduce（ 结果归并） 12345T reduce(T identity, BinaryOperator&lt;T&gt; accumulator);Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator);&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner); collect（ 转换成集合） 1234&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner);&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector); 转list 12345678// 转listCollectors.toList();// 转setCollectors.toSet();// 转mapList&lt;TestVo&gt; testList = new ArrayList&lt;&gt;(10);Map&lt;Long, TestVo&gt; data = releaseList.stream() .collect(Collectors.toMap(TestVo::getId, x -&gt; x)); count（ 计数） 1long count(); 查找 12345boolean anyMatch(Predicate&lt;? super T&gt; predicate);boolean allMatch(Predicate&lt;? super T&gt; predicate);boolean noneMatch(Predicate&lt;? super T&gt; predicate);Optional&lt;T&gt; findFirst();Optional&lt;T&gt; findAny(); Date Time API − 加强对日期与时间的处理。 时区类 java.time.ZoneId 12ZoneId shanghaiZoneId = ZoneId.of(&quot;Asia/Shanghai&quot;);ZoneId systemZoneId = ZoneId.systemDefault(); Instant类在Java日期与时间功能中， 表示了时间线上一个确切的点， 定义为距离初始时间的时间差 12345678// 一个Instant对象里有两个域： 距离初始时间的秒钟数、 在当前一秒内的第几纳秒Instant now = Instant.now();long seconds = systemZoneId.getEpochSecond();int nanos = systemZoneId.getNano();// 计算Instant later = now.plusSeconds(3);Instant earlier = now.minusSeconds(3); Clock类提供了访问当前日期和时间的方法， Clock是时区敏感的 12345// 可以用来取代System.currentTimeMillis() 来获取当前的微秒数。Clock clock = Clock.systemDefaultZone();long millis = clock.millis();Instant instant = clock.instant();Date legacyDate = Date.from(instant); LocalDate类是Java 8中日期时间功能里表示一个本地日期的类， 它的日期是无时区属性的。 12345678910111213LocalDate localDate = LocalDate.now();LocalDate localDate2 = LocalDate.of(2018, 3, 3);// 可以用如下方法访问LocalDate中的日期信息int year = localDate.getYear();Month month = localDate.getMonth();int dayOfMonth = localDate.getDayOfMonth();int dayOfYear = localDate.getDayOfYear();DayOfWeek dayOfWeek = localDate.getDayOfWeek();// 计算LocalDate d1 = localDate.plusYears(3);LocalDate d2 = localDate.minusYears(3); LocalTime类是Java 8中日期时间功能里表示一整天中某个时间点的类， 它的时间是无时区属性的 12345678910LocalTime localTime = LocalTime.now();LocalTime localTime2 = LocalTime.of(21, 30, 59, 11001);// 通过这些方法访问其时、 分、 秒、 纳秒getHour()getMinute()getSecond()getNano()// 计算LocalTime localTimeLater = localTime.plusHours(3);LocalTime localTimeEarlier = localTime.minusHours(3); LocalDateTime类是Java8中无时区的日期时间, 相当于LocalDate与LocalTime两个类的结合，使用方法也类似 12LocalDateTime localDateTime = LocalDateTime.now();······ ZonedDateTime类是Java 8中日期时间功能里， 用于表示带时区的日期与时间信息的类 123456ZonedDateTime dateTime = ZonedDateTime.now();ZoneId zoneId = ZoneId.of(&quot;UTC+1&quot;);ZonedDateTime dateTime2 = ZonedDateTime.of(2015, 11, 30, 23, 45, 59, 1234, zoneId);// 方法使用,计算同上······ DateTimeFormatter类是Java 8中日期时间功能里， 用于解析和格式化日期时间的类 12345678910// 类中包含如下预定义的实例BASIC_ISO_DATEISO_LOCAL_DATEISO_LOCAL_TIMEISO_LOCAL_DATE_TIME······// 格式化为某种字符串DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE;String formattedDate = formatter.format(LocalDate.now()); Duration对象表示两个Instant间的一段时间 12345678910111213141516171819Instant first = Instant.now();// wait some time while something happensInstant second = Instant.now();Duration duration = Duration.between(first, second);// 一个Duration对象里有两个域： 纳秒值（ 小于一秒的部分） ， 秒钟值（ 一共有几秒） long seconds = getSeconds()int nanos = getNano()// 转换long days = duration.toDays(); // 这段时间的总天数long hours = duration.toHours(); // 这段时间的小时数long minutes = duration.toMinutes(); // 这段时间的分钟数long seconds = duration.getSeconds(); // 这段时间的秒数// 计算Duration start = ... //obtain a start durationDuration added = start.plusDays(3);Duration subtracted = start.minusDays(3) TemporalAdjuster类可以更方便的调整时间———————————————————————————— 12345LocalDateTime localDateTime = LocalDateTime.now();// 返回下一个距离当前时间最近的星期六LocalDateTime dateTime1 = localDateTime.with(TemporalAdjusters.nextOrSame(DayOfWeek.SATURDAY));// 返回本月最后一个星期五LocalDateTime dateTime2 = localDateTime.with(TemporalAdjusters.lastInMonth(DayOfWeek.FRIDAY)); Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 1234567891011121314// 参数不能是nullOptional optional1 = Optional.of(1);// 参数可以是nullOptional optional2 = Optional.ofNullable(null);// 参数可以是非nullOptional optional3 = Optional.ofNullable(2);// isPresent判断值是否存在System.out.println(optional1.isPresent() == true);System.out.println(optional2.isPresent() == false);// orElseSystem.out.println(optional1.orElse(1000) == 1);// trueSystem.out.println(optional2.orElse(1000) == 1000);// true Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。 JVM的新特性 - 使用Metaspace（JEP 122）代替持久代（PermGen space）。在JVM参数方面，使用-XX:MetaSpaceSize和-XX:MaxMetaspaceSize代替原来的-XX:PermSize和-XX:MaxPermSize。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx设置反向代理访问pixiv图片]]></title>
    <url>%2F2019%2F10%2F17%2Fnginx%E8%AE%BE%E7%BD%AE%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%AE%BF%E9%97%AEpixiv%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[反向代理正常情况下, pixiv 的图片服务器域名为 i.pximg.net，因为有防盗链保护，只要 Referer 是空值或不是來自 pixiv 的域名就会返回403。 使用nginx反向代理只需要將 www.pixiv.net 设置到 Referer中就可以直接访问图片了 nginx配置例如在自己的电脑上安装好nginx后, 修改配置文件, 加上以下配置 12345678910111213141516171819202122proxy_cache_path D:\logs levels=1:2 keys_zone=pximg:10m max_size=10g inactive=7d use_temp_path=off;server &#123; server_name localhost; listen 80; access_log off; location / &#123; proxy_cache pximg; proxy_pass https://i.pximg.net; proxy_cache_revalidate on; proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504; proxy_cache_lock on; add_header X-Cache-Status $upstream_cache_status; proxy_set_header Host i.pximg.net; proxy_set_header Referer &quot;https://www.pixiv.net/&quot;; proxy_set_header User-Agent &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36&quot;; proxy_cache_valid 200 7d; proxy_cache_valid 404 5m; &#125;&#125; 修改完后重启nginx, 随便访问一张pixiv图片, 只需把https换成http, 并且把i.pximg.net域名换成localhost即可, 例如: pixiv网站上原始链接 (直接访问会返回403): https://i.pximg.net/img-original/img/2017/12/20/00/12/19/66360679_p0.png 经过我们的nginx反向代理 (可以正常访问)：http://localhost/img-original/img/2017/12/20/00/12/19/66360679_p0.png 这样我们就能绕过pixiv的防盗链从而直接访问pixiv图片了, 其实网上有一个公开的pixiv反向代理域名i.pixiv.cat, 在访问pixiv图片时, 只需将i.pximg.net 更換成 i.pixiv.cat 就可以使用 table th:first-of-type { width: 50%; } 直接访问图片 反向代理访问图片]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux设置闹钟定时播放一首歌]]></title>
    <url>%2F2019%2F10%2F08%2FLinux%E8%AE%BE%E7%BD%AE%E9%97%B9%E9%92%9F%E5%AE%9A%E6%97%B6%E6%92%AD%E6%94%BE%E4%B8%80%E9%A6%96%E6%AD%8C%2F</url>
    <content type="text"><![CDATA[命令行播放音乐现在听歌都是播放mp3文件, 一些Linux系统没有提供对mp3的支持, 需要安装一些软件, 这里我选audacious, 安装 1yum install -y audacious 命令行输入: audacious就可以弹出一个音乐播放窗口, 然后在窗口中操作播放音乐 也可以命令行播放某个mp3文件 1audacious -Hq /usr/local/src/inspire.mp3 将上面的播放命令写到/usr/local/src/play.sh脚本中, 后面会用到 cron介绍linux内置的cron进程能帮我们实现这些需求，cron搭配shell脚本，非常复杂的指令也没有问题。 我们经常使用的是crontab命令是cron table的简写，它是cron的配置文件，也可以叫它作业列表，我们可以在以下文件夹内找到相关配置文件。 /var/spool/cron/ 目录下存放的是每个用户包括root的crontab任务，每个任务以创建者的名字命名 /etc/crontab 这个文件负责调度各种管理和维护任务。 /etc/cron.d/ 这个目录用来存放任何要执行的crontab文件或脚本。 我们还可以把脚本放在/etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly、/etc/cron.monthly目录中，让它每小时/天/星期、月执行一次。 crontab的常用的命令如下： 1234crontab [-u username] //省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) 我们用crontab -e进入当前用户的工作表编辑，是常见的vim界面。每行是一条命令。 crontab的命令构成为 时间+动作，其时间有分、时、日、月、周五种，操作符有: 1234* 取值范围内的所有数字/ 每过多少个数字- 从X到Z，散列数字 加入一条命令: 12# 每个工作日中午12点执行一次播放音乐脚本0 12 * * 1,2,3,4,5 /usr/local/src/play.sh 闹钟就设定好了]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装最新版git]]></title>
    <url>%2F2019%2F09%2F19%2FCentOS7%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%89%88git%2F</url>
    <content type="text"><![CDATA[一般新装的linux会自带低版本的git, 如果需要安装新版git, 需要下载源码安装 下载源码可以从github 或者 镜像站下载源码 1wget https://github.com/git/git/archive/v2.22.0.tar.gz 安装1234567891011121314151617# 卸载旧版本gityum remove -y git# 依赖库安装yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum install gcc perl-ExtUtils-MakeMaker# 解压gz源码压缩包tar -xzf git-2.22.0.tar.gz# 进入解压目录cd git-2.22.0# 编译安装make prefix=/usr/local/git allmake prefix=/usr/local/git install# 添加到环境变量echo "export PATH=$PATH:/usr/local/git/bin" &gt;&gt; /etc/bashrcsource /etc/bashrc# 查看版本号git --version 安装完成!]]></content>
      <categories>
        <category>categories</category>
      </categories>
      <tags>
        <tag>tag</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot解决跨域]]></title>
    <url>%2F2019%2F09%2F07%2FSpringboot%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[跨域访问概念 CORS（Cross Origin Resource Sharing）跨域资源共享：表示 JavaScript 代码所在的机器和后端 api 所在的机器不是同一台的情况下实现资源访问。 广义的跨域 资源跳转： A链接、重定向、表单提交 资源嵌入： &lt;link&gt;、&lt;script&gt;、&lt;img&gt;、&lt;frame&gt;等dom标签 脚本请求： js发起的ajax请求、dom和js对象的跨域操作等 在前后端分离的项目中，前端一般是 SPA （Single Page Application）类型的应用，所有的 JavaScript 代码都会“下载”到用户机器的浏览器中，后端 api 在服务器端以单个机器或者集群的形式存在。 同源策略 同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。 常见跨域场景 URL 说明 是否允许通信 http://www.domain.com/a.jshttp://www.domain.com/b.jshttp://www.domain.com/lab/c.js 同一域名，不同文件或路径 允许 http://www.domain.com:8000/a.jshttp://www.domain.com/b.js 同一域名，不同端口 不允许 http://www.domain.com/a.jshttps://www.domain.com/b.js 同一域名，不同协议 不允许 http://www.domain.com/a.jshttp://192.168.4.12/b.js 域名和域名对应相同ip 不允许 http://www.domain.com/a.jshttp://x.domain.com/b.jshttp://domain.com/c.js 主域相同，子域不同 不允许 http://www.domain1.com/a.jshttp://www.domain2.com/b.js 不同域名 不允许 跨域解决方案1234567891、 通过jsonp跨域2、 document.domain + iframe跨域3、 location.hash + iframe4、 window.name + iframe跨域5、 postMessage跨域6、 跨域资源共享（CORS）7、 nginx代理跨域8、 nodejs中间件代理跨域9、 WebSocket协议跨域 通过jsonp跨域 jquery ajax: 1234567$.ajax(&#123; url: 'http://www.domain2.com:8080/login', type: 'get', dataType: 'jsonp', // 请求方式为jsonp jsonpCallback: "handleCallback", // 自定义回调函数名 data: &#123;&#125;&#125;); vue.js 123456this.$http.jsonp('http://www.domain2.com:8080/login', &#123; params: &#123;&#125;, jsonp: 'handleCallback'&#125;).then((res) =&gt; &#123; console.log(res); &#125;) jsonp缺点：只能实现get一种请求。 跨域资源共享（CORS） 普通跨域请求：只服务端设置Access-Control-Allow-Origin即可，前端无须设置，若要带cookie请求：前后端都需要设置。 原生ajax 12// 前端设置xhr.withCredentials = true; jquery 12345678$.ajax(&#123; ... xhrFields: &#123; withCredentials: true // 前端设置是否带cookie &#125;, crossDomain: true, // 会让请求头中包含跨域的额外信息，但不会含cookie ...&#125;); axios 1axios.defaults.withCredentials = true java后台设置 (springboot) 123456789101112131415161718192021@Configurationpublic class FilterConfig &#123; /** * 支持跨域请求 * @author Holeski * @date 2019/8/28 9:48 */ @Bean public CorsFilter corsFilter() &#123; CorsConfiguration config = new CorsConfiguration(); config.addAllowedOrigin("*"); config.setAllowCredentials(true); config.addAllowedMethod("*"); config.addAllowedHeader("*"); UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration("/**", config); return new CorsFilter(configSource); &#125;&#125; nginx反向代理 123456789101112131415#proxy服务器server &#123; listen 81; server_name www.domain1.com; location / &#123; proxy_pass http://www.domain2.com:8080; #反向代理 proxy_cookie_domain www.domain2.com www.domain1.com; #修改cookie里域名 index index.html index.htm; #当前端只跨域不带cookie时，可以为 * add_header Access-Control-Allow-Origin http://www.domain1.com; add_header Access-Control-Allow-Credentials true; &#125;&#125; 遇到一个非常奇怪的bug是, 在本地按照springboot的方式设置好了, 调试也没问题, 打好jar包放到服务器上就跨域失败, 后来捣鼓了一天找到一个方法: 1spring.mvc.dispatch-options-request=true 设置完就好了, 可是查看源码发现他的默认值就是true。。。。。。后面有时间再仔细看看这个问题]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7搭建api文档管理工具--YApi]]></title>
    <url>%2F2019%2F07%2F29%2FCentOS7%E6%90%AD%E5%BB%BAapi%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7-YApi%2F</url>
    <content type="text"><![CDATA[YApi简介 YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。可以帮助开发者轻松创建、发布、维护 API，YApi 还为用户提供了优秀的交互体验，开发人员只需利用平台提供的接口数据写入工具以及简单的点击操作就可以实现接口的管理。 国内几大互联网公司都在用的本地api文档管理工具 环境要求: nodejs（7.6+) mongodb（2.6+） git 安装nodejs下载nodejs并解压: 12wget http://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.gztar -zxf node-v10.16.0-linux-x64.tar.gz 编辑配置文件 vim /etc/profile 在文件最后添加: 123### nodejs environmentexport NODE_HOME=/data/cordova/node-v10.16.0-linux-x64export PATH=$NODE_HOME/bin:$PATH 使配置立即生效: 1source /etc/profile 检查node版本命令: node -v 检查npm 版本命令: npm -v 安装mongodb新建一个文件 /etc/yum.repos.d/mongodb-org-4.0.repo 并加入以下内容: 123456[mongodb-org-4.0]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.0/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc 123456## 开始安装sudo yum install -y mongodb-org## 启动mongosystemctl start mongod## 查看版本mongo --version 修改mongo的配置文件能够远程访问: 1vim /etc/mongod.conf 1234net: port: 27017 # 将下面127.0.0.1换成 0.0.0.0就可以远程访问mongodb了 bindIp: 127.0.0.1 全局安装yapi-cli并启动安装程序123npm install -g yapi-cli --registry https://registry.npm.taobao.org# 启动api安装程序yapi server 浏览器访问: http://ip:9090, 选择好配置, 点击部署 如果中途报错: generated/aesprim-browser.js: Permission denied则执行以下命令: 12npm config set user 0 npm config set unsafe-perm true 安装成功会提示: 切换到部署目录输入：node vendors/server/app.js, 按照提示去部署目录启动, 再去浏览器访问部署地址就完成了。可是一关闭shell终端yapi会停止运行 所以我们需要使用pm2来保证进程永远都活着 1234567891011121314151617# 安装pm2npm install pm2 -g# pm2启动项目pm2 start vendors/server/app.js --name YApi# 显示所有进程状态pm2 list# 停止指定的进程pm2 stop 0# 杀死指定的进程pm2 delete 0# pm2开机自启动项目 (在此之前先启动项目)pm2 save # 保存当前状态pm2 startup # 开启自启动# 禁用开机自启动pm2 unstartup]]></content>
      <categories>
        <category>YApi</category>
      </categories>
      <tags>
        <tag>YApi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cordova入门教程]]></title>
    <url>%2F2019%2F07%2F29%2Fcordova%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[简介 ( Cordova官网/Cordova中文网) Apache Cordova是一个开源的移动开发框架。允许你用标准的web技术-HTML5,CSS3和JavaScript做跨平台开发。 应用在每个平台的具体执行被封装了起来，并依靠符合标准的API绑定去访问每个设备的功能，比如说：传感器、数据、网络状态等。 简单来说 Cordova 就是一个能将html/js/css打包成各个平台应用功能的框架, 原理是他内置了一个浏览器, 然后把H5显示出来, 并能够打包成不同平台的App, 目前支持的平台有: Android Blackberry 10 iOS OS X Ubuntu Windows WP8 安装环境 ( /data/cordova目录下操作 )1. 安装JDK下载jdk-8u162-linux-x64.tar.gz 并解压到当前目录 1tar -xzvf jdk-8u162-linux-x64.tar.gz 编辑配置文件 vim /etc/profile 在最后添加: 12345##### Java environment #####export JAVA_HOME=/data/cordova/jdk1.8.0_162export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 使配置立即生效: 1source /etc/profile 2. 安装Android SDK下载 Android SDK并解压 (可以在这里下载) 12wget http://dl.google.com/android/android-sdk_r24.4.1-linux.tgztar -xzf android-sdk_r24.4.1-linux.tgz 编辑配置文件 vim /etc/profile 并在文件最后添加: 123##### Android environment #####export ANDROID_HOME=/data/cordova/android-sdk-linuxexport PATH=$ANDROID_HOME/tools:$PATH 使配置立即生效: 1source /etc/profile 其他可能用到的命令: 1234### 查看可用的组件:android list sdk --all### 安装安卓依赖工具包android update sdk -u --all --filter 1,2,3,5,11,12,22,23,24,25,26,27,28,29,45,88,89 3. 安装gradle在 https://gradle.org/releases/ 中复制对应版本gradle下载地址,在/data/cordova中下载并解压: 12wget https://services.gradle.org/distributions/gradle-3.3-bin...(替换为你复制的那个下载地址)unzip gradle-3.3-linux.zip 编辑配置: vim /etc/profile 在文件最后添加: 123### gradle environmentexport GRADLE_HOME=/data/cordova/gradle-3.3export PATH=$GRADLE_HOME/bin:$PATH 使配置立即生效: 1source /etc/profile 4. 安装node.js下载nodejs并解压: 12wget http://nodejs.org/dist/v10.16.0/node-v10.16.0-linux-x64.tar.gztar -zxf node-v10.16.0-linux-x64.tar.gz 编辑配置文件 vim /etc/profile 在文件最后添加: 123### nodejs environmentexport NODE_HOME=/data/cordova/node-v10.16.0-linux-x64export PATH=$NODE_HOME/bin:$PATH 使配置立即生效: 1source /etc/profile 检查node版本命令: node -v检查npm 版本命令: npm -v 最后/etc/profile文件添加的配置为: 1234567891011121314151617### Java environmentJAVA_HOME=/data/gradle/jdk1.8.0_152CLASSPATH=$JAVA_HOME/lib/PATH=$PATH:$JAVA_HOME/binexport PATH JAVA_HOME CLASSPATH### Nodejs environmentexport NODE_HOME=/data/cordova/node-v8.9.4-linux-x64export PATH=$NODE_HOME/bin:$PATH### Android environmentexport ANDROID_HOME=/data/cordova/android-sdk-linuxexport PATH="$PATH:$ANDROID_HOME/tools:$ANDROID_HOME/tools/bin"### gradle environmentexport GRADLE_HOME=/data/cordova/gradle-3.3export PATH=$PATH:$GRADLE_HOME/bin 5. 安装Cordova执行命令 1npm install -g cordova --registry https://registry.npm.taobao.org 创建Cordova项目12345678## 可以指定应用ID和应用名: cordova create project_name app_id app_namecordova create hello## 进入项目路径cd hello## 添加Android平台cordova platform add android --save 修改安卓平台构建文件的maven地址为阿里云镜像: vim platforms/android/build.gradle (可以跳过, 如果构建失败再来配置) 12345678// 将buildscript和allprojects中repositories 的内容都替换成:repositories &#123; jcenter() google() maven &#123; url "http://maven.aliyun.com/nexus/content/groups/public/" &#125;&#125; 把写好的H5文件放入www文件夹下 自定义app logo和启动画面需要添加插件 (参考文章): 1cordova plugin add cordova-plugin-splashscreen 打包安装App 1cordova build android 若打包过程中下载依赖时timeout, 则需要番蔷 打包成功会出现 BUILD SUCCESSFUL , 打包后的文件为: platforms/android/app/build/outputs/apk/debug/app-debug.apk Cordova打包release版本 12## 打包未签名的apk包cordova build android --release 12## 生成秘钥keytool -genkey -v -keystore ~/myKey.keystore -alias myKey -keyalg RSA -validity 20000 keytool 秘钥工具 -keystore D:/myKey.keystore 表示生成的证书及其存放路径，如果直接写文件名则默认生成在用户当前目录下； -alias myKey 表示证书的别名是 myKey,不写这一项的话证书名字默认是mykey； -keyalg RSA 表示采用的RSA算法； -validity 20000表示证书的有效期是20000天。 12## 签名jarsigner -verbose -keystore myKey.keystore -signedjar name.apk app-release-unsigned.apk myKey jarsigner 签名工具 name.apk 需要生成的apk名字 app-release-unsigned.apk 待签名的apk]]></content>
      <categories>
        <category>cordova</category>
      </categories>
      <tags>
        <tag>cordova</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Elasticsearch]]></title>
    <url>%2F2019%2F07%2F11%2FSpringboot%E6%95%B4%E5%90%88Elasticsearch%2F</url>
    <content type="text"><![CDATA[版本兼容请一定注意版本兼容问题。这关系到很多maven依赖。参考: Spring Data Elasticsearch Spring Boot version matrix Spring Boot Version (x) Spring Data Elasticsearch Version (y) Elasticsearch Version (z) x &lt;= 1.3.5 y &lt;= 1.3.4 z &lt;= 1.7.2* x &gt;= 1.4.x 2.0.0 &lt;=y &lt; 5.0.0** 2.0.0 &lt;= z &lt; 5.0.0** maven依赖 pom.xml:12345678910&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; 配置文件application.yml 123456789101112spring: data: elasticsearch: # 集群名 cluster-name: syncwt-es # 连接节点,注意在集群中通信都是9300端口，否则会报错无法连接上！ cluster-nodes: localhost:9300,119.29.38.169:9300 # 是否本地连接 local: false repositories: # 仓库中数据存储 enabled: true 启动项目后没有报错，日志出现以下说明代表成功。 12017-03-30 19:35:23.078 INFO 20881 --- [ main] o.s.d.e.c.TransportClientFactoryBean : adding transport node : localhost:9300 实体类123456789101112131415161718192021222324252627@Document(indexName = "news", type = "news", shards = 3, replicas = 0)public class News &#123; @Id @Field(type = FieldType.Long) private Long newsId; @Field(type = FieldType.Text, searchAnalyzer = "ik_smart", analyzer = "ik_max_word") private String title; @Field(type = FieldType.Text, searchAnalyzer = "ik_smart", analyzer = "ik_max_word") private String summary; @Field(type = FieldType.Date, format = DateFormat.custom, pattern = "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis") private Date publishTime; @Field(type = FieldType.Keyword) private String lang; @Field(type = FieldType.Date, format = DateFormat.custom, pattern = "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis") private Date createTime; @Field(type = FieldType.Date, format = DateFormat.custom, pattern = "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis") private Date updateTime; // setter and getter method&#125; dao接口可以直接继承spring封装好的接口1234public interface NewsRepository extends ElasticsearchRepository&lt;News, Long&gt; &#123; // 自定义查询 public List&lt;News&gt; findByTitle(String title);&#125; Controller类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@RestController@RequestMapping("/es")public class NewsController &#123; @Autowired private NewsRepository newsRepository; /** * 添加 * @return */ @RequestMapping("add") public String add() &#123; News news = new News(); news.setId("1"); news.setTitle("this is a title"); news.summary("China No.1 !!!"); news.setCreateTime(new Date()); newsRepository.save(news); return "success"; &#125; /** * 删除 * @return */ @RequestMapping("delete") public String delete() &#123; News news = newsRepository.queryById("1"); newsRepository.delete(news); return "success"; &#125; /** * 局部更新 * @return */ @RequestMapping("update") public String update() &#123; News news = newsRepository.queryById("1"); news.setTitle("哈哈"); newsRepository.save(news); return "success"; &#125; /** * 查询 * @return */ @RequestMapping("query") public News query() &#123; News news = newsRepository.getById("1"); return news; &#125;&#125; NewsRepository已经封装好了基本的增删改查: 12345678910111213141516@NoRepositoryBeanpublic interface ElasticsearchRepository&lt;T, ID extends Serializable&gt; extends ElasticsearchCrudRepository&lt;T, ID&gt; &#123; &lt;S extends T&gt; S index(S var1); Iterable&lt;T&gt; search(QueryBuilder var1); Page&lt;T&gt; search(QueryBuilder var1, Pageable var2); Page&lt;T&gt; search(SearchQuery var1); Page&lt;T&gt; searchSimilar(T var1, String[] var2, Pageable var3); void refresh(); Class&lt;T&gt; getEntityClass();&#125; 分页排序查询123456@NoRepositoryBeanpublic interface PagingAndSortingRepository&lt;T, ID&gt; extends CrudRepository&lt;T, ID&gt; &#123; Iterable&lt;T&gt; findAll(Sort var1); Page&lt;T&gt; findAll(Pageable var1);&#125; 支持异步查询 12@AsyncFuture&lt;News&gt; findByTitle(String title); NativeSearchQueryBuilder构建查询 123456789@Autowiredprivate ElasticsearchTemplate elasticsearchTemplate;SearchQuery searchQuery = new NativeSearchQueryBuilder() .withQuery(matchAllQuery()) .withFilter(boolFilter().must(termFilter("id", documentId))) .build();Page&lt;SampleEntity&gt; sampleEntities = elasticsearchTemplate.queryForPage(searchQuery,SampleEntity.class); 利用Scan和Scroll进行大结果集查询 12345678910111213141516171819202122232425262728293031323334SearchQuery searchQuery = new NativeSearchQueryBuilder() .withQuery(matchAllQuery()) .withIndices("test-index") .withTypes("test-type") .withPageable(new PageRequest(0,1)) .build();String scrollId = elasticsearchTemplate.scan(searchQuery,1000,false);List&lt;SampleEntity&gt; sampleEntities = new ArrayList&lt;SampleEntity&gt;();boolean hasRecords = true;while (hasRecords)&#123; Page&lt;SampleEntity&gt; page = elasticsearchTemplate.scroll(scrollId, 5000L , new ResultsMapper&lt;SampleEntity&gt;() &#123; @Override public Page&lt;SampleEntity&gt; mapResults(SearchResponse response) &#123; List&lt;SampleEntity&gt; chunk = new ArrayList&lt;SampleEntity&gt;(); for(SearchHit searchHit : response.getHits())&#123; if(response.getHits().getHits().length &lt;= 0) &#123; return null; &#125; SampleEntity news = new SampleEntity(); news.setId(searchHit.getId()); news.setTitle((String)searchHit.getSource().get("title")); chunk.add(news); &#125; return new PageImpl&lt;SampleEntity&gt;(chunk); &#125; &#125;); if(page != null) &#123; sampleEntities.addAll(page.getContent()); hasRecords = page.hasNextPage(); &#125; else&#123; hasRecords = false; &#125;&#125; 自行封装Util方法 1234567891011121314151617181920212223@Autowiredprivate ElasticsearchTemplate elasticsearchTemplate;public void searchHelper() throws IOException &#123; Client transportClient = elasticsearchTemplate.getClient(); News news = new News(1, "title", "content"); ObjectMapper mapper = new ObjectMapper(); String json = mapper.writeValueAsString(news); XContentBuilder builder = jsonBuilder() .startObject() .field("title", "China No.1") .endObject(); IndexResponse response = transportClient.prepareIndex("es-news", "news") .setSource(jsonBuilder() .startObject() .field("title", "China No.1") .endObject() ) .execute() .actionGet(); transportClient.close(); &#125; spring-data-elasticsearch对es有很好的支持, 我们能通过spring-data很方便地操作Elasticsearch]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat配置]]></title>
    <url>%2F2019%2F07%2F10%2F%E4%B8%80%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AAtomcat%2F</url>
    <content type="text"><![CDATA[一台机器启动多个tomcat从Apache官网下载好Tomcat, 解压两份到不同的文件夹下即可 第一个tomcat不做任何修改，使用默认端口和配置 第二个tomcat需要编辑tomcat/conf目录下server.xml文件, 修改3个端口, 使其与前面的tomcat端口不同: 1234567891011121314&lt;!-- 修改关闭端口为8015, 第22行左右 --&gt;&lt;Server port="8015" shutdown="SHUTDOWN"&gt;......&lt;!-- 修改服务端口为8081, 第70行左右 --&gt;&lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;......&lt;!-- 修改连接端口为8019, 第91行左右 --&gt;&lt;Connector port="8019" protocol="AJP/1.3" redirectPort="8443" /&gt; 配置完成, 可以去启动两个tomcat了 看网上有些说还需要改redirectPort, 设置啥CATALINA_HOME等等, 都是多余的步骤, 完全不用 指定JDK版本启动tomcat有些复杂环境中有多个JDK, 默认会使用系统环境中的JAVA_HOME来启动tomcat, 如需要指定不同JDK版本启动tomcat, 这就需要修改tomcat的启动配置了 在Windows中启动Tomcat时，双击startup.bat然后会调用catalina.bat文件，而catalina.bat会调用setclasspath.bat文件来获取JAVA_HOME和JRE_HOME这两个环境变量的值，因此只要在tomcat启动时指向特定的JDK即可 在Windows中, 需要在setclasspath.bat文件的开头处加入以下内容 12set JAVA_HOME=C://Program Files/Java/jdk1.7.0_79set JRE_HOME=C://Program Files/Java/jdk1.7.0_79/jre 在Linux中, 则需要在setclasspath.sh文件的开头处加入以下内容 12export JAVA_HOME=/usr/local/java/jdk1.7.0_79export JRE_HOME=/usr/local/java/jdk1.7.0_79/jre 修改session默认的cookie名字在tomcat的conf目录下, 修改server.xml文件, 在节点中加入配置: 1&lt;Context path="/" sessionCookiePath="/" sessionCookieName="MY-SESSION"/&gt; console控制台输出有乱码在tomcat安装路径conf/logging.properties文件中注释掉其中一行 12## 将下面这行注释掉# java.util.logging.ConsoleHandler.encoding = UTF-8 Tomcat部署项目的3种方式 常规的webapps下 直接部署到${TOMCAT_HOME}/webapps下 外部部署 修改${TOMCAT_HOME}/conf/server.xml 在标签下添加web所在的目录指定path，如: 1&lt;Context path="/xx" docBase="D:\\workspace\\xx\\target\\xx" reloadable="true" sessionCookiePath="/xx"sessionCookieName="yoursessionname"&gt; &lt;/Context&gt; ${TOMCAT_HOME}/conf下建工程目录镜像 在conf目录中，新建 Catalina＼localhost目录，在该目录中新建一个xml文件，名字可以随意取，只要和当前文件中的文件名不重复就行了，该xml文件的内容为： 1&lt;Context path="/xx" docBase="D:\\workspace\\xx\\target\\xx" debug="0" privileged="true"&gt; &lt;/Context&gt;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建Hexo]]></title>
    <url>%2F2019%2F07%2F10%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BAHexo%2F</url>
    <content type="text"><![CDATA[参考文章: 使用hexo快速搭建个人博客 Hexo+Next 添加菜单分类页面 NexT主题官网 Hexo进阶高级教程 hexo搭建个人博客–NexT主题优化 Hexo+NexT优化部署 asdfv1929 ‘s Home NexT主题的优化定制修改指南 Hexo提交百度和Google收录站点 Hexo NexT 主题6.x版本的使用配置与美化 碰到的问题 升级主题到Next6, 字体样式失效, 图标也丢失, 启动还会报错 12localhost/:1 Refused to apply style from 'http://localhost:4000/lib/font-awesome/css/font-awesome.min.css?v=4.6.2' because its MIME type ('text/html') is not a supported stylesheet MIME type, and strict MIME checking is enabled. 在hexo中有自带font-awesome字体的, 但是升级到hexo6时就没有了, 把next目录下（next -&gt; source -&gt; lib）的 font-awesome 文件夹复制到next6同样的目录下, 解决]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决MySQL数据库Too many connections问题]]></title>
    <url>%2F2019%2F07%2F09%2F%E8%A7%A3%E5%86%B3MySQL%E6%95%B0%E6%8D%AE%E5%BA%93Too-many-connections%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[方法一:因为这种方法是临时修改, 连上MySQL后重启后会失效 连上MySQL后执行: 1mysql&gt; set GLOBAL max_connections=500; 方法二:123456# 修改mysql配置文件my.cnfvi /etc/my.cnf# 在[mysqld]段中添加或修改max_connections值max_connections=500# 重启 查看mysql的最大连接数： 1234567mysql&gt; show variables like '%max_connections%';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 500 |+-----------------+-------+1 row in set (0.00 sec) 查询所有连接到这个服务器上的MySQL连接 1mysql&gt; show processlist; 获取到MySQL数据连接列表后，每一条记录都会有一个进程ID号（在上表的第一列）。执行以下命令关闭一条连接: 12# 其中1180421是进程列表里找到并且要杀掉的进程号mysql&gt; kill 1180421; 查看服务器响应的最大连接数 1mysql&gt; show global status like 'Max_used_connections';]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装JIRA和Confluence（破解版）以及JIRA版本升级方案]]></title>
    <url>%2F2019%2F07%2F08%2Fdocker%E5%AE%89%E8%A3%85JIRA%E5%92%8CConfluence%EF%BC%88%E7%A0%B4%E8%A7%A3%E7%89%88%EF%BC%89%E4%BB%A5%E5%8F%8AJIRA%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本文将演示通过Docker安装JIRA和Confluence，并破解过程。本文只做个人学习研究之用，不得用于商业用途！ 安装JIRA (7.12.3)1. 获取资源 Docker镜像 Github链接 补丁工具(atlassian-agent.jar) Github链接 原链接已失效, 附百度云: 百度网盘地址： 链接：https://pan.baidu.com/s/17zNwlp3sd1PLSCxPVjDwfQ 提取码：b84z 复制这段内容后打开百度网盘手机App，操作更方便哦 2. 制作Docker破解容器编写Dockerfile文件： 123456789FROM cptactionhank/atlassian-jira-software:7.12.3USER root# 将代理破解包加入容器COPY "atlassian-agent.jar" /opt/atlassian/jira/# 设置启动加载代理包RUN echo 'export CATALINA_OPTS="-javaagent:/opt/atlassian/jira/atlassian-agent.jar $&#123;CATALINA_OPTS&#125;"' &gt;&gt; /opt/atlassian/jira/bin/setenv.sh 将下载好的atlassian-agent.jar文件放在Dockerfile同目录下，例如： 123- JIRA |-Dockerfile |-atlassian-agent.jar 构建镜像, 执行命令(注意后面有一个点) 1docker build -t jira/jira:v7.12.3 . 构建成功后会显示 ‘Successfully built…` 字样 启动容器，执行命令： 12345docker run -d -p 10086:8080 \ -v /home/jira/data:/var/atlassian/jira \ --restart always --name=jira \ --health-cmd="curl --silent --fail localhost:8080 || exit 1" \ jira/jira:v7.12.3 访问: `http://127.0.0.1:10086,可见JIRA配置页面 3. 破解在见到JIRA配置页面后, 进行相关配置, 当要求输入许可证时 复制服务器ID: BY9B-GWD1-1C78-K2DE, 在存放atlassian-agent.jar的目录下执行命令, 生成许可证: 12345# 需替换邮箱（test@test.com）、名称（JIRA）、# 访问地址（http://192.168.0.1）、服务器ID（BY9B-GWD1-1C78-K2DE）# 为你的信息java -jar atlassian-agent.jar -d -m test@test.com -n JIRA -p jira -o http://192.168.0.89 -s BY9B-GWD1-1C78-K2DE 复制下面生成的一长串许可证填写到页面中, 完成破解 安装 Confluence（6.14.1)1. 编写Dockerfile文件123456789FROM cptactionhank/atlassian-confluence:6.14.1USER root# 将代理破解包加入容器COPY "atlassian-agent.jar" /opt/atlassian/confluence/# 设置启动加载代理包RUN echo 'export CATALINA_OPTS="-javaagent:/opt/atlassian/confluence/atlassian-agent.jar $&#123;CATALINA_OPTS&#125;"' &gt;&gt; /opt/atlassian/confluence/bin/setenv.sh 2. 构建镜像将下载好的atlassian-agent.jar文件放在Dockerfile同目录下，例如： 123- Confluence |-Dockerfile |-atlassian-agent.jar 构建镜像, 执行命令(注意后面有一个点) 1docker build -t confluence/confluence:v6.14.1 . 启动容器，执行命令： 12345docker run -d -p 10087:8080 \ -v /home/confluence/data:/var/atlassian/confluence \ --restart always --name=confluence \ --health-cmd="curl --silent --fail localhost:8080 || exit 1" \ confluence/confluence:v6.14.1 访问http://127.0.0.1:8090,参照JIRA的安装流程，进行操作。 生成confluence许可方法可参照前面JIRA的破解过程, 这里不再赘述 JIRA版本升级可以参考官方文档 由于之前安装的是jira6.4版本的, 现在需要升级到7.12.3版本, 根据官方提示需要先升级到7.0版本的jira再过渡升级到7.12.3 1. 备份数据a. 备份数据库 登录jira6.4版本, 进入设置 -&gt; 系统 -&gt; 备份系统, 输入备份的文件名字: 比如jira 点击备份后会在备份界面提示的某个路径下生成一个jira.zip数据库的备份文件 b . 备份图片 复制 /var/atlassian/application-data/jira/data下的attachments和avatars文件夹出来,备份好 2. 升级过渡版如果不过数据库文件过渡处理, 在jira v7.12.3中是无法使用的 获取JIRA v7.0.11 镜像并启动 12docker pull dchevell/jira-software:7.0.11docker run -d -p 8080:8080 dchevell/jira-software:7.0.11 启动后访问 http://127.0.0.1:8080, 开始配置, 当需要许可证时, 上面的方法破解不了, 由于只是做一个过度版本, 可以去官网注册然后申请一个30天有效期的许可证, 然后输入进去就好了 同样在备份系统的同级目录中点击恢复系统 按照提示将前面备份好的文件放到他指定目录下,点击复原, 如果需要填写许可证那就填写许可证在复原 复原成功后再重复上一步骤进行备份备份后将在 docker容器 /var/atlassian/jira/export目录下生成一个.zip数据库的备份文件 3. 升级最终版按照上面的步骤把jira v7.12.3运行起来, 并将数据库备份文件放入恢复界面指定的目录之下进行数据复原. 把前面图片备份文件分别放入/var/atlassian/application-data/jira/data/下即可 升级成功!]]></content>
      <categories>
        <category>JIRA</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>JIRA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识JMX]]></title>
    <url>%2F2019%2F06%2F15%2F%E5%88%9D%E8%AF%86JMX%2F</url>
    <content type="text"><![CDATA[JXM简介试想，一个正在运行中的程序，我们如果想改变程序中的一些属性，可以通过什么方法呢？可能有这么几个方法： 对于服务器式的程序，可以制作管理页面，通过HTTP post与servlet来更改服务器端程序的属性。 对于服务器式的程序，还可以通过SOAP方式。但这需要程序开启了SOAP端的服务。 可以使用RMI远程调用。但这需要设计开启RMI服务。 如果是SWT或Swing的程序，则可以通过设计UI管理界面，使用户可以和程序内部交互。 还有一种方式，是将可改变的属性放入配置文件XML，properties或数据库，程序轮询配置文件，以求获取最新的配置。 上面几个方法都是常见，但却无法通用的。所谓通用，是指解决方案符合一个标准，使得任何符合此标准的工具都能解析针对此标准的方案实现。这样A公司设计的方案，B公司可以根据标准来解析。JMX就是Java管理标准。 对于一些参数的修改，网上有一段描述还是比较形象的： 程序初哥一般是写死在程序中，到要改变的时候就去修改代码，然后重新编译发布。 程序熟手则配置在文件中（JAVA一般都是properties文件），到要改变的时候只要修改配置文件，但还是必须重启系统，以便读取配置文件里最新的值。 程序好手则会写一段代码，把配置值缓存起来，系统在获取的时候，先看看配置文件有没有改动，如有改动则重新从配置里读取，否则从缓存里读取。 程序高手则懂得物为我所用，用JMX把需要配置的属性集中在一个类中，然后写一个MBean，再进行相关配置。另外JMX还提供了一个工具页，以方便我们对参数值进行修改。 JMX(Java Management Extensions)是一个为应用程序植入管理功能的框架。JMX是一套标准的代理和服务，实际上，用户可以在任何Java应用程序中使用这些代理和服务实现管理。JMX让程序有被管理的功能，例如你开发一个WEB网站，它是在24小时不间断运行，那么你肯定会对网站进行监控，如每天的UV、PV是多少；又或者在业务高峰的期间，你想对接口进行限流，就必须去修改接口并发的配置值。 应用场景：中间件软件WebLogic的管理页面就是基于JMX开发的，而JBoss则整个系统都基于JMX构架。 JMX的构成JMX由三部分组成： 基础层：程序端的Instrumentation, 我把它翻译成可操作的仪器。这部分就是指的MBean. MBean类似于JavaBean。最常用的MBean则是Standard MBean和MXBean. 适配层：程序端的JMX agent. 这部分指的是MBean Server. MBean Server则是启动与JVM内的基于各种协议的适配器。用于接收客户端的调遣，然后调用相应的MBeans. 接入层：客户端的Remote Management. 这部分则是面向用户的程序。此程序则是MBeans在用户前投影，用户操作这些投影，可以反映到程序端的MBean中去。这内部的原理则是client通过某种协议调用agent操控MBeans.JMX agent与Remote Management之间是通过协议链接的，这协议可能包含： HTTP SNMP RMI IIOP JMX agent中有针对上面协议的各种适配器。可以解析通过相应协议传输过来的数据。Remote Management client则可以用现成的工具，如JConsole, 也可以自己书写java code。 实现一个JMX程序 1、 首先定义一个MBean接口，接口的命名规范为以具体的实现类为前缀（这个规范很重要） 123456789public interface HelloMBean &#123; public String getName(); public void setName(String name); public String getAge(); public void setAge(String age); public void helloWorld(); public void helloWorld(String str); public void getTelephone();&#125; 2、定义一个实现类，实现上面的接口： 123456789101112131415161718192021222324252627282930313233343536373839/* * 该类名称必须与实现的接口的前缀保持一致（即MBean前面的名称 */public class Hello implements HelloMBean &#123; private String name; private String age; public void getTelephone() &#123; System.out.println("get Telephone"); &#125; public void helloWorld() &#123; System.out.println("hello world"); &#125; public void helloWorld(String str) &#123; System.out.println("helloWorld:" + str); &#125; public String getName() &#123; System.out.println("get name 123"); return name; &#125; public void setName(String name) &#123; System.out.println("set name 123"); this.name = name; &#125; public String getAge() &#123; System.out.println("get age 123"); return age; &#125; public void setAge(String age) &#123; System.out.println("set age 123"); this.age = age; &#125; &#125; 3、定义agent层： 12345678910111213141516import java.lang.management.ManagementFactory;import javax.management.JMException;import javax.management.MBeanServer;import javax.management.ObjectName;public class HelloAgent &#123; public static void main(String[] args) throws JMException, Exception &#123; // 通过工厂类获取MBeanServer，用来做MBean的容器 MBeanServer server = ManagementFactory.getPlatformMBeanServer(); // ObjectName中的取名是有一定规范的，格式为：“域名：name=MBean名称”，其中域名和MBean的名称可以任意取。 ObjectName helloName = new ObjectName("jmxBean:name=hello"); //将Hello这个类注入到MBeanServer中，注入需要创建一个ObjectName类 server.registerMBean(new Hello(), helloName); Thread.sleep(60*60*1000); &#125;&#125; 这样，一个简单的JMX的DEMO已经写完了，现在我们通过JDK提供的Jconsole来进行操作。 4、在JDK安装路径 ·JAVA_HOME\bin· 下找到 jconsole.exe 这个小工具，双击打开。 在本地进程中找到 HelloAgent 并双击打开 在当前界面上，我们可以给程序中HelloMBean的属性赋值，也可以调用其中的方法 这样就做到动态修改运行中程序的状态进而管理程序。]]></content>
      <categories>
        <category>JMX</category>
      </categories>
      <tags>
        <tag>JMX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java爬虫-webmagic入门]]></title>
    <url>%2F2019%2F06%2F14%2Fjava%E7%88%AC%E8%99%AB-webmagic%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[webmagic简介 官方网站 webmagic是一个开源的Java垂直爬虫框架，目标是简化爬虫的开发流程，让开发者专注于逻辑功能的开发。webmagic的核心非常简单，但是覆盖爬虫的整个流程，也是很好的学习爬虫开发的材料。 webmagic的主要特色： 完全模块化的设计，强大的可扩展性。 核心简单但是涵盖爬虫的全部流程，灵活而强大，也是学习爬虫入门的好材料。 提供丰富的抽取页面API。 无配置，但是可通过POJO+注解形式实现一个爬虫。 支持多线程。 支持分布式。 支持爬取js动态渲染的页面。 无框架依赖，可以灵活的嵌入到项目中去。 该项目是参考了: python爬虫 scrapy Java爬虫 Spiderman 快速开始webmagic使用maven管理依赖，在项目中添加对应的依赖即可使用webmagic： 12345678910&lt;dependency&gt; &lt;groupId&gt;us.codecraft&lt;/groupId&gt; &lt;artifactId&gt;webmagic-core&lt;/artifactId&gt; &lt;version&gt;0.7.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;us.codecraft&lt;/groupId&gt; &lt;artifactId&gt;webmagic-extension&lt;/artifactId&gt; &lt;version&gt;0.7.3&lt;/version&gt;&lt;/dependency&gt; 注意: 这里都是参考官方文档, 但实际上maven库的包源有bug, 不过作者已经在源代码里修复了, 需要copy源代码重新编译打包 克隆源代码 1git clone https://github.com/code4craft/webmagic.git 或者直接下载zip源码压缩包, 下载完解压即可 下载完成后导入到开发工具中, 重新 install webmagic-core模块即可 创建第一个爬虫: 12345678910111213141516171819202122232425262728293031323334353637public class GithubRepoPageProcessor implements PageProcessor &#123; // 部分一：抓取网站的相关配置，包括编码、抓取间隔、重试次数等 private Site site = Site.me().setRetryTimes(3).setSleepTime(1000); @Override // process是定制爬虫逻辑的核心接口，在这里编写抽取逻辑 public void process(Page page) &#123; // 部分二：定义如何抽取页面信息，并保存下来 page.putField("author", page.getUrl().regex("https://github\\.com/(\\w+)/.*").toString()); page.putField("name", page.getHtml().xpath("//h1[@class='entry-title public']/strong/a/text()").toString()); if (page.getResultItems().get("name") == null) &#123; //skip this page page.setSkip(true); &#125; page.putField("readme", page.getHtml().xpath("//div[@id='readme']/tidyText()")); // 部分三：从页面发现后续的url地址来抓取 page.addTargetRequests(page.getHtml().links().regex("(https://github\\.com/[\\w\\-]+/[\\w\\-]+)").all()); &#125; @Override public Site getSite() &#123; return site; &#125; public static void main(String[] args) &#123; Spider.create(new GithubRepoPageProcessor()) //从"https://github.com/code4craft"开始抓 .addUrl("https://github.com/code4craft") //开启5个线程抓取 .thread(5) //启动爬虫 .run(); &#125;&#125; 点击运行, 就能看到爬虫工作了 如果运行的时候报错 javax.net.ssl.SSLException: Received fatal alert: protocol_version 那是你没有编译源码打包. 代码中注释已经很详细了, 相信大家也大概明白爬取的过程了. 更详细的爬虫教程看作者的官方教程]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统下几个有趣的命令]]></title>
    <url>%2F2019%2F05%2F20%2FLinux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%87%A0%E4%B8%AA%E6%9C%89%E8%B6%A3%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[作为一名程序员，在别人的眼里往往是充满科技感、神秘感的，而在我们自己的眼里却往往是觉得无聊、枯燥的。其实，在程序的世界里同样会充满着各种的彩蛋，这些彩蛋往往都是一些大神留下来的，我们未曾发现，只是我们缺少发现程序之美而已。今天我们就来介绍几个有趣的Linux命令, 来体验一波程序彩蛋之美。 文章参考: Linux系统下好玩有趣的命令，你又用过几个？ 由于原文都是在Ubuntu系统下安装使用的, 而我自己是在CentOS7系统下操作, 偶尔有些不同, 我也只选择了其中几个很有趣的试了试 sl （Steam Locomotive）安装, 这个是最简单的, 经常在你想要查看当前目录的时候错误的输入了sl, 现在就回出现一辆小火车开过的动画… 1yum -y install sl 运行 1sl oneko撸猫指令, oneko会生成一只图像猫, 在屏幕上乱跑 1yum -y install oneko 运行 1oneko cmatrix该指令会在屏幕上下一场字符雨 123456789101112## 下载压缩包wget https://jaist.dl.sourceforge.net/project/cmatrix/cmatrix/1.2a/cmatrix-1.2a.tar.gz## 解压tar xvf cmatrix-1.2a.tar.gz## 进入安装目录cd cmatrix-1.2a## 安装依赖yum install ncurses-devel## 编译源码并安装, 需要有gcc,gcc-c++, 如果没有就yum安装./configure &amp;&amp; make &amp;&amp; make install## 安装完毕, 运行cmatrix 启动成功后, 有看到字符雨, 按q退出 ASCIIquarium彩蛋：把你的linux终端变成一个海洋世界，各种生物在不断呈现，有鱼、有水、有草…, 好鬼酷哦(wzr…) 12345678910111213141516## 安装依赖工具yum -y install ncurses-devel perl-CPAN libyaml-devel perl-CGI perl-Curses perl-ExtUtils-MakeMaker## 安装依赖文件wget http://search.cpan.org/CPAN/authors/id/K/KB/KBAUCOM/Term-Animation-2.4.tar.gztar -zxvf Term-Animation-2.4.tar.gzcd Term-Animation-2.4/perl Makefile.PL &amp;&amp; makemake install## 安装ASCIIquariumwget http://www.robobunny.com/projects/asciiquarium/asciiquarium.tar.gztar -zxvf asciiquarium.tar.gzcd asciiquarium_1.1/cp asciiquarium /usr/local/bin/chmod 755 /usr/local/bin/asciiquarium## 运行asciiquarium 同样的运行成功后按q退出]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QQ/微信机器人的安装使用]]></title>
    <url>%2F2019%2F05%2F12%2FQQ-%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言经常在微信/QQ上看到可以自动聊天的机器人, 感觉很有趣, 今天我们就可以来创建这样一个机器人. 前期准备: 在图灵机器人网站上注册一个账号, 注册成功后在网站上创建一个机器人, 勾选qq/微信即可, 创建完成后会有一个apikey, 记住这个apikey, 后面会用到. 图灵机器人的作用: 在聊天机器人中, 当我们发送消息给机器人账号时, 机器人账号会将获取到的消息通过apikey发到图灵机器人网站上, 然后图灵机器人背后使用机器学习+大数据分析相结合的人工智能技术得出消息的回复, 并把该回复响应给机器人账号,进而呈现在你的屏幕上, 这就是整个聊天机器人的工作原理 注册好图灵机器人账号后, 它会免费提供给我们每天100次的调用次数, 也就是说他可以每天跟我们对话100次, 如果你觉得少了也可以升级到收费版, 调用次数会大幅提升. 微信机器人参考项目, 该项目使用python3来运行的, 因此我们先安装python3, 去python官网下载, 这里我选择Windows版本, 安装的时候有个地方add to path 需要勾选, 其他都点下一步就安装好了.验证是否安装成功, 在CMD命令行窗口里输入: 1python -V 如果输出版本号, 则表示安装成功 从github下载项目源码 下载后进入项目目录,当前目录下应该可以看到robot.py文件, 如果是下载zip包则先解压缩 安装依赖文件, 打开CMD窗口输入下面命令: 1pip3 install -U wxpy -i "https://pypi.doubanio.com/simple/" 等依赖安装结束后, 启动项目: 1python robot.py 此时会出现一个登陆用的二维码, 用手机微信扫码登陆, 登陆成功后会提示登陆成功, 这样一个微信机器人就创建成功了, 试着发消息给这个微信号, 和他聊聊天吧! 注意: 如果在扫码登陆的时候报错, 很可能是因为你使用了新申请的微信, 腾讯为了安全考虑做出的新号登录限制, 一个号是否可以用来作为机器人账号, 可以先试着登陆网页版微信成功与否来判断, 因为该项目的原理就是使用了网页端微信的api来收发消息的 该项目里使用了原作者自己提供的图灵机器人apikey, 可能由于使用次数达到限制而无法自动回复, 此时我们应该使用自己图灵账号的apikey了, 打开 config.py , 修改里面 tuling_api_key 这一项的值为自己的apikey. QQ机器人酷Q酷Q是一款免费的qq机器人, 以前是基于webqq、smartQQ协议做的自动收发消息功能, 但现在腾讯已经放弃了网页版的qq, 也就是以前的webqq、smartQQ协议都不行了。后来听说酷Q按照安卓的qq协议反编译出的，因此最新版应该是基于安卓协议的。 下载Windows版安装从酷Q官网下载软件压缩包，直接解压运行即可，此时会要求登录qq账号来作为机器人账号，建议使用小号来登录。登录完成后，会有提示下一步如何操作，根据提示完成后就可以大致明白如何使用QQ机器人的聊天等功能了。如需启用图灵机器人, 设置图灵的apikey后就可以聊天了. 这是最基本的功能，他还有一个强大之处在于，他的插件扩展功能更强大 在酷Q的应用官网，插件在酷Q官网叫应用，选择一个应用下载吧（需要注册登录），下载完后缀名是cpk的文件后，直接放入酷Q安装目录的app文件夹中，重启酷Q就可以加载进去，然后就可以体验机器人的乐趣了。 安装Linux版一般也不会挂着机器人在Windows上，所以如果我们有linux服务器，就比较好挂着机器人了。 这里使用的Docker安装酷Q，详细查看官网介绍 首先确保Linux已经装好Docker了，接下来拉取镜像运行就可以了 1docker pull coolq/wine-coolq 然后运行 酷Q 镜像： 1docker run --name=coolq --rm -p 9000:9000 -v /root/coolq-data:/home/user/coolq -e VNC_PASSWD=123456 -e COOLQ_ACCOUNT=123456 coolq/wine-coolq 运行后，会看到控制台中输出一系列日志。当你看到 [CQDaemon] Started CoolQ 时，说明已启动成功。此时，在浏览器中访问 http://你的服务器IP:9000 即可看到远程操作登录页面，输入密码123456，即可看到 酷Q Air 的登录界面啦。在登录后，右键点击悬浮窗 -&gt; 昵称 -&gt; 勾选「自动登录」，即可保证 酷Q 能自动登录。 这时候如果关闭linux界面酷Q就会停了, 所以我们需要后台运行酷Q: 1docker run --name=coolq -d -p 9000:9000 --restart always -v /root/coolq-data:/home/user/coolq -e VNC_PASSWD=123456 -e COOLQ_ACCOUNT=123456 coolq/wine-coolq 查看运行状态: 1docker logs coolq 启动/停止服务 12docker start coolqdocker stop coolq 如果想安装插件, 把插件放入挂载的文件/root/coolq-data/app, 重启酷Q即可]]></content>
      <categories>
        <category>机器人</category>
      </categories>
      <tags>
        <tag>机器人</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装Elasticsearch]]></title>
    <url>%2F2019%2F05%2F06%2FCentOS7%E5%AE%89%E8%A3%85Elasticsearch%2F</url>
    <content type="text"><![CDATA[版本选择Elasticsearch 目前有三个常用的稳定的主版本：2.x，5.x，6.x, 目前最新是7.0.0 中间没有3.x和4.x是为了ELK（ElasticSearch, logstash, kibana）技术栈的版本统一，免的给用户带来混乱。 版本选择可以从以下几个方面考虑： 123456789101112131415版本问题2.x 版本较老，无法体验新功能，且性能不如 5.x。6.x 版本有点新，网上资料相对比较少（开发时间充足的可以研究）。数据迁移2.x 版本数据可以直接迁移到 5.x；5.X 版本的数据可以直接迁移到 6.x； 但是 2.x 版本数据无法直接迁移到 6.x。周边工具2.x 版本周边工具版本比较混乱；Kibana 等工具的对应版本需要自己查，不好匹配。5.x 之后 Kibana 等工具的主版本号进行了统一。Sql 语法支持2.x，5.x，6.x 都可以安装 Elasticsearch-sql 插件，使用熟悉的SQL语法查询 Elasticsearch。6.3.0 以后内置支持 SQL 模块，这个 SQL 模块是属于 X-Pack 的一部分。 我选择目前最新的5.x版: elasticsearch-5.6.16 安装Elasticsearch安装包安装注意: Elasticsearch5.0之后的版本至少需要Java 8 下载对应版本安装包: 官方下载地址 下载后解压即可使用, 执行以下命令启动: Linux 1./bin/elasticsearch Windows 进入elasticsearch安装目录/bin 1双击 elasticsearch.bat Docker安装CentOS版太大了, 我选择alpine版的 1docker pull elasticsearch:5.6-alpine 启动容器 在启动容器之前, 容器挂载的配置文件目录下面得要有配置文件，不然es是起不来的，比较方便的办法是，先不挂载启动es，然后用docker cp命令，把配置文件复制到宿主机挂载目录，然后再进行修改： 1234567891011121314151617docker run -d -p 9200:9200 -p 9300:9300 --name=elasticsearch elasticsearch:5.6-alpinedocker cp elasticsearch:/usr/share/elasticsearch/config /data/software/elasticsearch/config docker cp elasticsearch:/usr/share/elasticsearch/data /data/software/elasticsearch/datadocker stop elasticsearchdocker rm elasticsearch如果需要更改配置，可以直接修改config目录下的 elasticsearch.yml 文件，然后启动esdocker run -d -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -e ES_JAVA_OPTS="-Xms512m -Xmx512m" \-v /data/software/elasticsearch/plugins:/usr/share/elasticsearch/plugins \-v /data/software/elasticsearch/config:/usr/share/elasticsearch/config \-v /data/software/elasticsearch/data:/usr/share/elasticsearch/data \--restart unless-stopped --name=elasticsearch elasticsearch:5.6-alpine 检查es是否安装成功: 访问 http://es_serverIp:9200 安装ik分词器下载地址 下载对应版本, 解压放入es安装目录中的plugin文件夹中, 重启es即可 安装KibanaKibana 和 elasticsearch 同属于 elastic 公司。 Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。使用Kibana搜索，可以查看和与存储在 Elasticsearch 索引中的数据进行交互。您可以轻松地执行高级数据分析，并在各种图表，表格和地图中可视化您的数据。 Windows 从官方下载地址中下载与elasticsearch 版本对应 的Kibana, 解压即可使用: 下载并解压缩 Kibana。 在编辑器中打开 config/kibana.yml。 设置 elasticsearch.url 为您的Elasticsearch实例，如本地：elasticsearch.url: “http://localhost:9200&quot;(与es装在同一机器可以不用设置)。 运行bin/kibana.bat。 浏览器输入 http://localhost:5601。 CentOS 123# --link可以用来链接2个容器，使得源容器（被链接的容器）和接收容器（主动去链接的容器）之间可以互相通信，并且接收容器可以获取源容器的一些数据，如源容器的环境变量。docker pull kibana:5.6.16docker run --init -d --name kibana --restart unless-stopped --link elasticsearch -p 5601:5601 kibana:5.6.16 如果elasticsearch没有用docker运行: 12# ELASTICSEARCH_URL指定elasticsearch的ipdocker run -it -d -e ELASTICSEARCH_URL=http://172.17.0.1:9200 -p 5601:5601 --name kibana kibana:5.6.16 碰到的问题: 不能以root身份启动elasticsearch, 否则会报错, 执行以下命令: 12345678# 创建一个非root用户, 比如创建新用户elasticsearchadduser elasticsearch# 授权chown -R elasticsearch /elasticsearch安装目录# 切换用户su elasticsearch# 后台启动./bin/elasticsearch -d elasticsearch默认开启9200端口作为接收http请求, 如果想要开启9300端口: 1234# 编辑elasticsearch配置文件vi elasticsearch.yml# 文件添加配置: network.host: 0.0.0.0 max virtual memory areas vm.max_map_count [65530] is too low 12345678# 编辑文件, 在最后添加一行 vm.max_map_count=655300vi /etc/sysctl.conf# 执行命令重新加载文件 sysctl -p# 重启elasticsearch: 先kill es进程再启动./bin/elasticsearch max number of threads [1024] for user [elsearch] is too low, increase to at least [4096] 123456# 编辑文件vim /etc/security/limits.d/90-nproc.conf# 将下面* soft nproc 1024# 修改为* soft nproc 4096 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 12345678# 编辑配置文件vim /etc/security/limits.conf # 在最下面添加以下内容* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 修改JVM参数(可选) 1234# 初始化内存分配2g-Xms2g# 最大分配内存2g-Xmx2g elasticsearch版本升级 详情参考: 官方文档 升级需要考虑到数据迁移, 不过也不难 安装好新版elasticsearch后, 修改新ES中的配置elasticsearch.yml文件,在里面添加一行: 12# 多个ip以逗号','隔开, 或者 127.0.10.*:9200reindex.remote.whitelist: oldhost:9200 然后向新ES执行下面请求即可 12345678910111213141516171819POST _reindex&#123; "source": &#123; // 获取来源的索引库 "remote": &#123; "host": "http://oldhost:9200", "username": "user", "password": "password" &#125;, "index": "indexName", "query": &#123; "match": &#123; "test": "data" &#125; &#125; &#125;, "dest": &#123; // 生成的目标索引库 "index": "indexName" &#125;&#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch入门教程]]></title>
    <url>%2F2019%2F04%2F30%2FElasticsearch%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Elasticsearch简介Elasticsearch是一个高度可扩展的、开源的、基于 Lucene 的全文搜索和分析引擎。它允许您快速，近实时地存储，搜索和分析大量数据，并支持多租户。 它使用Java开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的 RESTful API 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。 基本概念集群 集群(cluster)是一组具有相同cluster.name的节点集合，他们协同工作，共享数据并提供故障转移和扩展功能，当然一个节点也可以组成一个集群。 集群由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入集群的话，则该节点只能是集群的一部分。确保不同的环境中使用不同的集群名称，否则最终会导致节点加入错误的集群。 节点(Node) 一个运行的 ES 实例就是一个节点，节点存储数据并参与集群的索引和搜索功能。就像集群一样，节点由名称标识，默认情况下，该名称是在启动时分配给节点的随机通用唯一标识符（UUID）。如果不需要默认值，可以定义所需的任何节点名称。此名称对于管理目的非常重要，您可以在其中识别网络中哪些服务器与 Elasticsearch 集群中的哪些节点相对应。 可以将节点配置为按集群名称加入特定集群。默认情况下，每个节点都设置为加入一个名为 cluster 的 elasticsearch 集群，这意味着如果您在网络上启动了许多节点并且假设它们可以相互发现 - 它们将自动形成并加入一个名为 elasticsearch 的集群。 索引（名词） 一个索引类似于传统关系数据库中的一个数据库 ，是一个存储关系型文档的地方，是ES对逻辑数据的逻辑存储，索引的结构是为快速有效的全文检索做准备。 索引（动词） 索引一个文档就是存储一个文档到一个索引（名词）中以便它可以被检索和查询到。这非常类似于 SQL 语句中的 INSERT 关键词，除了文档已存在时新文档会替换旧文档情况之外。 倒排索引 倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件(inverted file)。 文档 存储在ES上的主要实体叫文档 文档类型（在 6.0.0 及以上废弃） 在ES中，一个索引对象可以存储很多不同用途的对象。 映射 存储有关字段的信息，每一个文档类型都有自己的映射。 面向文档 在应用程序中对象很少只是一个简单的键和值的列表。通常，它们拥有更复杂的数据结构，可能包括日期、地理信息、其他对象或者数组等。 也许有一天你想把这些对象存储在数据库中。使用关系型数据库的行和列存储，这相当于是把一个表现力丰富的对象挤压到一个非常大的电子表格中：你必须将这个对象扁平化来适应表结构–通常一个字段&gt;对应一列–而且又不得不在每次查询时重新构造对象。 Elasticsearch 是 面向文档 的，意味着它存储整个对象或 文档_。Elasticsearch 不仅存储文档，而且 _索引 每个文档的内容使之可以被检索。在 Elasticsearch 中，你 对文档进行索引、检索、排序和过滤–而不是对行列数据。这是一种完全不同的思考数据的方式，也是 Elasticsearch 能支持复杂全文检索的原因。 分片(Shards) 索引可能存储大量可能超过单个节点的硬件限制的数据。例如，占用1TB磁盘空间的十亿个文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独从单个节点提供搜索请求。 为了解决这个问题，Elasticsearch 提供了将索引细分为多个称为分片的功能。创建索引时，只需定义所需的分片数即可。每个分片本身都是一个功能齐全且独立的“索引”，可以托管在集群中的任何节点上。 设置分片的目的及原因主要是： 它允许您水平拆分/缩放内容量它允许您跨分片（可能在多个节点上）分布和并行化操作，从而提高性能/吞吐量分片的分布方式以及如何将其文档聚合回搜索请求的机制完全由 Elasticsearch 管理，对用户而言是透明的。 在可能随时发生故障的网络/云环境中，分片非常有用，建议使用故障转移机制，以防分片/节点以某种方式脱机或因任何原因消失。为此，Elasticsearch 允许您将索引的分片的一个或多个副本制作成所谓的副本分片或简称副本。 副本(Replicasedit) 副本，是对分片的复制。目的是为了当分片/节点发生故障时提供高可用性，它允许您扩展搜索量/吞吐量，因为可以在所有副本上并行执行搜索。 总而言之，每个索引可以拆分为多个分片。索引也可以复制为零次（表示没有副本）或更多次。复制之后，每个索引将具有主分片(从原始分片复制而来的)和复制分片(主分片的副本)。 副本是乘法，越多越浪费，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。 一个对比图来类比传统关系型数据库：12关系型数据库 -&gt; Databases(库) -&gt; Tables(表) -&gt; Rows(行) -&gt; Columns(列)。Elasticsearch -&gt; Indeces(索引) -&gt; Types(类型) -&gt; Documents(文档) -&gt; Fields(属性)。 与Elasticsearch交互目前与 elasticsearch 交互主要有两种方式：Client API 和 RESTful API。 Client API方式： Elasticsearch 为以下语言提供了官方客户端 –Groovy、JavaScript、.NET、 PHP、 Perl、 Python 和 Ruby–还有很多社区提供的客户端和插件，所有这些都可以在 Elasticsearch Clients 中找到。 RESTful API with JSON over HTTP： 所有其他语言可以使用 RESTful API 通过端口 9200 和 Elasticsearch 进行通信，你可以用你最喜爱的 web 客户端访问 Elasticsearch 。事实上，正如你所看到的，你甚至可以使用 curl 命令来和 Elasticsearch 交互。 一个 Elasticsearch 请求和任何 HTTP 请求一样由若干相同的部件组成：1curl -X&lt;VERB&gt; '&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;' -d '&lt;BODY&gt;' 参数 描述 VERB 适当的 HTTP 方法 或 谓词 : GET、 POST、 PUT、 HEAD 或者 DELETE PROTOCOL http 或者 https（如果你在 Elasticsearch 前面有一个https 代理） HOST Elasticsearch 集群中任意节点的主机名，或者用 localhost 代表本地机器上的节点 PORT 运行 Elasticsearch HTTP 服务的端口号，默认是 9200 PATH API 的终端路径（例如 _count 将返回集群中文档数量）。Path 可能包含多个组件，例如：_cluster/stats 和 _nodes/stats/jvm QUERY_STRING 任意可选的查询字符串参数 (例如 ?pretty 将格式化地输出 JSON 返回值，使其更容易阅读) BODY 一个 JSON 格式的请求体 (如果请求需要的话) 常用命令 12345678curl 'localhost:9200/brand/_search?pretty=true' # 查询索引数据curl -XPUT 'localhost:9200/customer?pretty' # 创建索引curl -XDELETE 'localhost:9200/customer' # 删除索引curl 'localhost:9200/_cat/health?v' # 检测集群是否健康curl 'localhost:9200/_cat/nodes?v' # 获取集群节点curl 'localhost:9200/_cat/indices?v' # 列出所有索引curl -x GET 'localhost:9200/index/_mapping' # 查询指定索引的映射curl -X GET 'localhost:9200/_cluster/health?pretty' # 查看分片状态 Example 创建第一个简单索引 创建一个 NBA 球队的索引 1234567891011121314151617181920212223242526272829303132PUT nba&#123; "settings":&#123; "number_of_shards": 3, "number_of_replicas": 1 &#125;, "mappings":&#123; "nba":&#123; "properties":&#123; "name_cn":&#123; "type":"text" &#125;, "name_en":&#123; "type":"text" &#125;, "gymnasium":&#123; "type":"text" &#125;, "topStar":&#123; "type":"text" &#125;, "championship":&#123; "type":"integer" &#125;, "date":&#123; "type":"date", "format":"yyyy-MM-dd HH:mm:ss|| yyy-MM-dd||epoch_millis" &#125; &#125; &#125; &#125;&#125; 字段说明： 字段名称 字段说明 nba 索引 number_of_shards 分片数 number_of_replicas 副本数 name_cn 球队中文名 name_en 球队英文名 gymnasium 球馆名称 championship 总冠军次数 topStar 当家球星 date 加入NBA年份 创建成功则返回信息:12345&#123; "acknowledged": true, "shards_acknowledged": true, "index": "nba"&#125; 新增索引数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849PUT /nba/nba/1&#123; "name_en":"San Antonio Spurs SAS", "name_cn":"圣安东尼安马刺", "gymnasium":"AT&amp;T中心球馆", "championship": 5, "topStar":"蒂姆·邓肯", "date":"1995-04-12"&#125;PUT /nba/nba/2&#123; "name_en":"Los Angeles Lakers", "name_cn":"洛杉矶湖人", "gymnasium":"斯台普斯中心球馆", "championship": 16, "topStar":"科比·布莱恩特", "date":"1947-05-12"&#125;PUT /nba/nba/3&#123; "name_en":"Golden State Warriors", "name_cn":"金州勇士队", "gymnasium":"甲骨文球馆", "championship": 6, "topStar":"斯蒂芬·库里", "date":"1949-06-13"&#125;PUT /nba/nba/4&#123; "name_en":"Miami Heat", "name_cn":"迈阿密热火队", "gymnasium":"美国航空球场", "championship": 3, "topStar":"勒布朗·詹姆斯", "date":"1988-06-13"&#125;PUT /nba/nba/5&#123; "name_en":"Cleveland Cavaliers", "name_cn":"克利夫兰骑士队", "gymnasium":"速贷球馆", "championship": 1, "topStar":"勒布朗·詹姆斯", "date":"1970-06-13"&#125; 查询全部球队的信息 123456POST /nba/nba/_search&#123; "query": &#123; "match_all": &#123;&#125; &#125;&#125; 响应结果: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; "took": 4, "timed_out": false, "_shards": &#123; "total": 3, "successful": 3, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 3, "max_score": 1, "hits": [ &#123; "_index": "nba", "_type": "nba", "_id": "2", "_score": 1, "_source": &#123; "name_en": "Los Angeles Lakers", "name_cn": "洛杉矶湖人", "gymnasium": "斯台普斯中心球馆", "championship": 16, "topStar": "科比·布莱恩特", "date": "1947-05-12" &#125; &#125;, &#123; "_index": "nba", "_type": "nba", "_id": "1", "_score": 1, "_source": &#123; "name_en": "San Antonio Spurs SAS", "name_cn": "圣安东尼安马刺", "gymnasium": "AT&amp;T中心球馆", "championship": 5, "topStar": "蒂姆·邓肯", "date": "1995-04-12" &#125; &#125;, &#123; "_index": "nba", "_type": "nba", "_id": "3", "_score": 1, "_source": &#123; "name_en": "Golden State Warriors", "name_cn": "金州勇士队", "gymnasium": "甲骨文球馆", "championship": 6, "topStar": "斯蒂芬·库里", "date": "1949-06-13" &#125; ··· &#125; ] &#125;&#125; 响应的数据结果分为两部分 1234567891011121314151617&#123;----------------first part-------------------- "took": 0, "timed_out": false, "_shards": &#123; "total": 3, "successful": 3, "skipped": 0, "failed": 0 &#125;,---------------second part--------------------- "hits": &#123; "total": 0, "max_score": null, "hits": [] &#125;&#125; 第一部分为：分片副本信息，第二部分 hits 包装的为查询的数据集。 查询英文名称为：”Golden State Warriors” 的球队信息 12345678POST /nba/nba/_search&#123; "query": &#123; "match": &#123; "name_en": "Golden State Warriors" &#125; &#125;&#125; 可得到的查询结果为： 123456789101112131415161718192021222324252627282930&#123; "took": 6, "timed_out": false, "_shards": &#123; "total": 3, "successful": 3, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 1, "max_score": 1.9646256, "hits": [ &#123; "_index": "nba", "_type": "nba", "_id": "3", "_score": 1.9646256, "_source": &#123; "name_en": "Golden State Warriors", "name_cn": "金州勇士队", "gymnasium": "甲骨文球馆", "championship": 6, "topStar": "斯蒂芬·库里", "date": "1949-06-13" &#125; &#125; ] &#125;&#125; 过滤查询 Filter 我们让搜索变的复杂一些。我们想要找到当家球星是勒布朗·詹姆斯，但是我们只想得到总冠军多于1次的球队。我们的语句将做一些改变用来添加过滤器(filter),它允许我们有效的执行一个结构化搜索 12345678910111213141516171819POST /nba/nba/_search&#123; "query": &#123; "bool": &#123; "filter": &#123; "range": &#123; "championship": &#123; "gt": 1 &#125; &#125; &#125;, "must": &#123; "match": &#123; "topStar": "勒布朗·詹姆斯" &#125; &#125; &#125; &#125;&#125; 我们发现每次查询，查询结果里面都有一个 _score字段，一般Elasticsearch根据相关评分排序，相关评分是根据文档与语句的匹配度来得出， _score值越高说明匹配度越高。 查询命令 query_string语法 12345curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' 分页查询 1234567curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "from" : 1, "size" : 1, "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' 增加version值 12345678curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "version" : true, "from" : 1, "size" : 1, "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' 限制得分 1234567curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "version" : true, "min_score" : 2.4, "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' 选择要返回的字段 12345678curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "fields" : ["brandName","spuName"], "version" : true, "min_score" : 2.4, "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' 选择要返回的字段 12345678curl -XGET 'localhost:9200/product/spu/_search?pretty=true' -d '&#123; "fields" : ["brandName","spuName"], "version" : true, "min_score" : 2.4, "query" : &#123; "query_string" : &#123;"query" : "brandName:本田"&#125; &#125;&#125;' SpringBoot与Elasticsearch集成 pom文件中添加添加依赖 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 解决es no jna warning--&gt;&lt;dependency&gt; &lt;groupId&gt;com.sun.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;version&gt;3.0.9&lt;/version&gt;&lt;/dependency&gt; application.yml添加配置 1234spring: data: elasticsearch: cluster-nodes: 127.0.0.1:9300 注意：elasticsearch jar版本要与安装的服务版本相容]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装RabbitMQ]]></title>
    <url>%2F2019%2F04%2F22%2FCentOS7%E5%AE%89%E8%A3%85RabbitMQ%2F</url>
    <content type="text"><![CDATA[安装ErLangrabbitmq依赖于erlang, 因此要先安装erlang 123wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpmyum install erlang 安装RabbitMQ12wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.14/rabbitmq-server-3.7.14-1.el7.noarch.rpmyum -y install rabbitmq-server-3.7.14-1.el7.noarch.rpm 启动RabbitMQ12345678910systemctl start rabbitmq-server # 启动RabbitMQsystemctl enable rabbitmq-server # 开机自启动RabbitMQsystemctl status rabbitmq-server # 查看状态# 其他启动方式rabbitmq-server # 启动 RabbitMQ服务rabbitmqctl stop # 停止RabbitMQ服务rabbitmqctl start_app # 启动applicationrabbitmqctl stop_app # 停止applicationrabbitmq-server -detached # 后台启动 RabbitMQ服务 访问web控制台初始帐号和密码都为：guest, 但是只能本地登录 123456rabbitmq-plugins enable rabbitmq-management # 启动RabbitMQ Web管理控制台chown -R rabbitmq:rabbitmq /var/lib/rabbitmq/ # 将RabbitMQ文件的所有权提供给RabbitMQ用户rabbitmqctl add_user admin 123456 # 为RabbitMQ Web管理控制台创建管理用户rabbitmqctl set_user_tags admin administrator # 为admin设置管理员角色rabbitmqctl set_permissions -p / admin ".*" ".*" ".*" # 为admin设置默认vhost（“/”）配置、写、读全部权限 访问: http://RabbitMQ_IP:15672/ 就能看到RabbitMQ管理页面 角色说明 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。]]></content>
      <categories>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ入门教程]]></title>
    <url>%2F2019%2F04%2F19%2FRabbitMQ%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[RabbitMQ 简介RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol ）基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持高并发，支持可扩展。 AMQP即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。 消息队列MQ 全称为Message Queue, 消息队列。是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。 消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信。队列的使用除去了接收和发送应用程序同时执行的要求。在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从而提高了系统的吞吐量。 RabbitMQ 应用场景对于一个大型的软件系统来说，它会有很多的组件或者说模块或者说子系统或者（subsystem or Component or submodule）。那么这些模块的如何通信？这和传统的IPC有很大的区别。传统的IPC很多都是在单一系统上的，模块耦合性很大，不适合扩展（Scalability）；如果使用socket那么不同的模块的确可以部署到不同的机器上，但是还是有很多问题需要解决。比如： 1）信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据如何防止丢失？ 2）如何降低发送者和接收者的耦合度？ 3）如何让Priority高的接收者先接到数据？ 4）如何做到load balance？有效均衡接收者的负载？ 5）如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。 6）如何做到可扩展，甚至将这个通信模块发到cluster上？ 7）如何保证接收者接收到了完整，正确的数据？ 概念介绍 Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 producer：消息生产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 RabbitMQ使用流程AMQP模型中，消息在producer中产生，发送到MQ的exchange上，exchange根据配置的路由方式发到相应的Queue上，Queue又将消息发送给consumer，消息从queue到consumer有push和pull两种方式。 消息队列的使用过程大概如下： 客户端连接到消息队列服务器，打开一个channel。 客户端声明一个exchange，并设置相关属性。 客户端声明一个queue，并设置相关属性。 客户端使用routing key，在exchange和queue之间建立好绑定关系。 客户端投递消息到exchange。 exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。 exchange也有几个类型，完全根据key进行投递的叫做Direct交换机，例如，绑定时设置了routing key为”abc”，那么客户端提交的消息，只有设置了key为”abc”的才会投递到队列。 RabbitMQ的安装 : 查看下一篇文章 Java入门实例(Helloworld)一个producer发送消息，一个接收者接收消息，并在控制台打印出来。 Java客户端配置 加入pom依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt;&lt;/dependency&gt; 发送端：Send.java 连接到RabbitMQ（此时服务需要启动），发送一条数据，然后退出。 1234567891011121314151617181920212223242526272829303132333435import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.util.concurrent.TimeoutException;public class Send &#123; //队列名称 private final static String QUEUE_NAME = "helloMQ"; public static void main(String[] argv) throws java.io.IOException, TimeoutException &#123; /** * 创建连接连接到MabbitMQ */ ConnectionFactory factory = new ConnectionFactory(); //设置MabbitMQ所在主机ip或者主机名 factory.setHost("localhost"); factory.setUsername("admin"); factory.setPassword("123456"); //创建一个连接 Connection connection = factory.newConnection(); //创建一个频道 Channel channel = connection.createChannel(); //指定一个队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //发送的消息 String message = "hello world!"; //往队列中发出一条消息 channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); //关闭频道和连接 channel.close(); connection.close(); &#125;&#125; 值得注意的是队列只会在它不存在的时候创建，多次声明并不会重复创建。信息的内容是字节数组，也就意味着你可以传递任何数据。 接收端：Recv.java 不断等待服务器推送消息，然后在控制台输出。 12345678910111213141516171819202122232425262728293031import com.rabbitmq.client.*;import java.io.IOException;public class Recv &#123; // 队列名称 private final static String QUEUE_NAME = "helloMQ"; public static void main(String[] argv) throws Exception &#123; // 打开连接和创建频道，与发送端一样 ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); factory.setUsername("admin"); factory.setPassword("123456"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //声明队列，主要为了防止消息接收者先运行此程序，队列还不存在时创建队列。 channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); //创建消费者 Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println(" [x] Received '" + message + "'"); &#125; &#125;; channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; RabbitMQ工作队列-Work Queues（Java实例）创建一个工作队列用来在工作者（consumer）间分发耗时任务。 工作队列的主要任务是：避免立刻执行资源密集型任务，然后必须等待其完成。相反地，我们进行任务调度：我们把任务封装为消息发送给队列。工作进行在后台运行并不断的从队列中取出任务然后执行。当你运行了多个工作进程时，任务队列中的任务将会被工作进程共享执行。 我们使用Thread.sleep来模拟耗时的任务, 然后启动两个work, 可以发现消费时间变短了 发送端 12345678910111213141516171819202122232425import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.MessageProperties;public class NewTask &#123; private static final String TASK_QUEUE_NAME = "task_queue"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); factory.setUsername("admin"); factory.setPassword("123456"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(TASK_QUEUE_NAME, true, false, false, null); String message = String.valueOf(System.currentTimeMillis()); channel.basicPublish("", TASK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes("UTF-8")); System.out.println(" [x] Sent '" + message + "'"); channel.close(); connection.close(); &#125;&#125; 接收端 123456789101112131415161718192021222324252627282930313233343536373839import com.rabbitmq.client.*;import java.io.IOException;public class Worker &#123; private static final String TASK_QUEUE_NAME = "task_queue"; public static void main(String[] argv) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost("localhost"); factory.setUsername("admin"); factory.setPassword("123456"); final Connection connection = factory.newConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(TASK_QUEUE_NAME, true, false, false, null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); channel.basicQos(1); final Consumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body, "UTF-8"); System.out.println(" [x] Received '" + message + "'"); try &#123; try &#123; Thread.sleep( 5000); // 执行耗时操作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; finally &#123; System.out.println(" [x] Done" + message); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125; &#125;; channel.basicConsume(TASK_QUEUE_NAME, false, consumer); &#125;&#125; 使用任务队列的好处是能够很容易的并行工作。如果我们积压了很多工作，我们仅仅通过增加更多的工作者就可以解决问题，使系统的伸缩性更加容易。 消息确认执行一个任务需要花费几秒钟。你可能会担心当一个工作者在执行任务时发生中断。我们上面的代码，一旦RabbItMQ交付了一个信息给消费者，会马上从内存中移除这个信息。在这种情况下，如果杀死正在执行任务的某个工作者，我们会丢失它正在处理的信息。我们也会丢失已经转发给这个工作者且它还未执行的消息。如下: 1234boolean ack = false ; //打开消息应答机制 channel.basicConsume(QUEUE_NAME, ack, consumer); //另外需要在每次处理完成一个消息后，手动发送一次应答。 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); 消息的持久性 虽然消费者被杀死，消息也不会被丢失。但是如果此时RabbitMQ服务被停止，我们的消息仍然会丢失。当RabbitMQ退出或者异常退出，将会丢失所有的队列和信息，除非你告诉它不要丢失。我们需要做两件事来确保信息不会被丢失：我们需要给所有的队列和消息设置持久化的标志。 第一， 我们需要确认RabbitMQ永远不会丢失我们的队列。为了这样，我们需要声明它为持久化的。 12boolean durable = true;channel.queueDeclare("task_queue", durable, false, false, null); 注：RabbitMQ不允许使用不同的参数重新定义一个队列，所以已经存在的队列，我们无法修改其属性。 第二， 我们需要标识我们的信息为持久化的。通过设置MessageProperties（implements BasicProperties）值为PERSISTENT_TEXT_PLAIN 1channel.basicPublish("", "task_queue",MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes()); 现在你可以执行一个发送消息的程序，然后关闭服务，再重新启动服务，运行消费者程序测试。 公平的分配 或许会发现，目前的消息转发机制（Round-robin）并非是我们想要的。例如，这样一种情况，对于两个消费者，有一系列的任务，奇数任务特别耗时，而偶数任务却很轻松，这样造成一个消费者一直繁忙，另一个消费者却很快执行完任务后等待。造成这样的原因是因为RabbitMQ仅仅是当消息到达队列进行转发消息。并不在乎有多少任务消费者并未传递一个应答给RabbitMQ。仅仅盲目转发所有的奇数给一个消费者，偶数给另一个消费者。 为了解决这样的问题，我们可以使用basicQos方法，传递参数为prefetchCount = 1。这样告诉RabbitMQ不要在同一时间给一个消费者超过一条消息。换句话说，只有在消费者空闲的时候会发送下一条信息。 12int prefetchCount = 1; channel.basicQos(prefetchCount); Exchange 的几种模式RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种，分别有以下一些属性: 123name：名称Durability：持久化标志，如果为true，则表明此exchange是持久化的。Auto-delete：删除标志，当所有队列在完成使用此exchange时，是否删除 1、fanout类型 fanout类型的Exchange路由规则非常简单，它会把所有发送到fanout Exchange的消息都会被转发到与该Exchange 绑定(Binding)的所有Queue上。 Fanout Exchange 不需要处理RouteKey 。只需要简单的将队列绑定到exchange 上。这样发送到exchange的消息都会被转发到与该交换机绑定的所有队列上。类似子网广播，每台子网内的主机都获得了一份复制的消息。所以，Fanout Exchange 转发消息是最快的。 2、direct类型 direct类型的Exchange路由规则也很简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。 direct Exchange是RabbitMQ Broker的默认Exchange，它有一个特别的属性对一些简单的应用来说是非常有用的，在使用这个类型的Exchange时，可以不必指定routing key的名字，在此类型下创建的Queue有一个默认的routing key，这个routing key一般同Queue同名。 direct模式,可以使用rabbitMQ自带的Exchange：default Exchange 。所以不需要将Exchange进行任何绑定(binding)操作 。消息传递时，RouteKey必须完全匹配，才会被队列接收，否则该消息会被抛弃。 3、topic类型 topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同，它约定： routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符“”与“#”，用于做模糊匹配，其中“”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） 所有发送到Topic Exchange的消息被转发到所有关心RouteKey中指定Topic的Queue上，Exchange 将RouteKey 和某Topic 进行模糊匹配。此时队列需要绑定一个Topic。可以使用通配符进行模糊匹配，符号“#”匹配一个或多个词，符号“”匹配不多不少一个词。因此“log.#”能够匹配到“log.info.oa”，但是“log.” 只会匹配到“log.error”。 4、headers类型 headers类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之JMS和AMQP的关系]]></title>
    <url>%2F2019%2F04%2F19%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BJMS%E5%92%8CAMQP%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[JMS通常而言提到JMS（Java MessageService）实际上是指JMS API。JMS是由Sun公司早期提出的消息标准，旨在为java应用提供统一的消息操作，包括create、send、receive等。JMS已经成为Java Enterprise Edition的一部分。从使用角度看，JMS和JDBC担任差不多的角色，用户都是根据相应的接口可以和实现了JMS的服务进行通信，进行相关的操作。 JMS通常包含如下一些角色：Elements | Notes———– | ——–JMS provider | 实现了JMS接口的消息中间件，如ActiveMQJMS client | 生产或者消费消息的应用JMS producer/publisher | JMS消息生产者JMS consumer/subscriber | JMS消息消费者JMS message | 消息，在各个JMS client传输的对象；JMS queue | Provider存放等待被消费的消息的地方JMS topic | 一种提供多个订阅者消费消息的一种机制；在MQ中常常被提到，topic模式。 JMS提供了两种消息模型，peer-2-peer(点对点)以及publish-subscribe（发布订阅）模型。当采用点对点模型时，消息将发送到一个队列，该队列的消息只能被一个消费者消费。而采用发布订阅模型时，消息可以被多个消费者消费。在发布订阅模型中，生产者和消费者完全独立，不需要感知对方的存在。 消息如何从producer端达到consumer端由message-routing来决定。在JMS中，消息路由非常简单，由producer和consumer链接到同一个queue（p2p）或者topic（pub/sub）来实现消息的路由。JMSconsumer同时支持message selector（消息选择器），通过消息选择器，consumer可以只消费那些通过了selector筛选的消息。在JMS兄中，消息路由机制的图示如下： 常见的消息队列，大部分都实现了JMS API，可以担任JMS provider的角色，如ActiveMQ，Redis以及RabbitMQ等。 AMQPAMQP（advanced message queuing protocol）在2003年时被提出，最早用于解决金融领不同平台之间的消息传递交互问题。顾名思义，AMQP是一种协议，更准确的说是一种binary wire-level protocol（链接协议）。这是其和JMS的本质差别，AMQP不从API层进行限定，而是直接定义网络交换的数据格式。这使得实现了AMQP的provider天然性就是跨平台的。意味着我们可以使用Java的AMQP provider，同时使用一个python的producer加一个rubby的consumer。从这一点看，AQMP可以用http来进行类比，不关心实现的语言，只要大家都按照相应的数据格式去发送报文请求，不同语言的client均可以和不同语言的server链接。 在AMQP中，消息路由（messagerouting）和JMS存在一些差别，在AMQP中增加了Exchange和binding的角色。producer将消息发送给Exchange，binding决定Exchange的消息应该发送到那个queue，而consumer直接从queue中消费消息。queue和exchange的bind有consumer来决定。AMQP的routing scheme图示过程如下： 目前AMQP逐渐成为消息队列的一个标准协议，当前比较流行的rabbitmq、stormmq都使用了AMQP实现。 JMS和AMQP的各项对比如下： 信息 JMS AMQP 定义 Java api Wire-protocol 跨语言 否 是 跨平台 否 是 Model 提供两种消息模型：（1）、Peer-2-Peer（2）、Pub/sub 提供了五种消息模型：（1）、direct exchange（2）、fanout exchange（3）、topic change（4）、headers exchange（5）、system exchange本质来讲，后四种和JMS的pub/sub模型没有太大差别，仅是在路由机制上做了更详细的划分； 支持消息类型 多种消息类型：TextMessageMapMessageBytesMessageStreamMessageObjectMessageMessage （只有消息头和属性） byte[]当实际应用时，有复杂的消息，可以将消息序列化后发送。 综合评价 JMS 定义了JAVA API层面的标准；在java体系中，多个client均可以通过JMS进行交互，不需要应用修改代码，但是其对跨平台的支持较差； AMQP定义了wire-level层的协议标准；天然具有跨平台、跨语言特性。 原文链接]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装JDK1.8]]></title>
    <url>%2F2019%2F04%2F17%2FCentOS7%E5%AE%89%E8%A3%85JDK1-8%2F</url>
    <content type="text"><![CDATA[查看已安装的jdk并卸载查询jdk ( 新装的centos会默认安装openjre ) 1234whereis javawhich java （java执行路径）echo $JAVA_HOMEecho $PATH 确定JDK的版本： 1rpm -qa | grep jdk 可能的结果是： 12java-1.7.0-openjdk-1.7.0.191-2.6.15.5.el7.x86_64java-1.7.0-openjdk-headless-1.7.0.191-2.6.15.5.el7.x86_64 卸载jdk 12yum -y remove java-1.7.0-openjdk-1.7.0.191-2.6.15.5.el7.x86_64 yum -y remove java-1.7.0-openjdk-headless-1.7.0.191-2.6.15.5.el7.x86_64 下载安装下载地址 将下载好的文件jdk-8u191-linux-x64.tar.gz放在 /data 目录下, 解压: 1tar -zxvf jdk-8u191-linux-x64.tar.gz 解压成功后，则可以看到jdk1.8.0_191文件夹 配置环境变量打开配置文件 1vim /etc/profile 在配置文件末尾添加一下内容 12345JAVA_HOME=/data/jdk1.8.0_191JRE_HOME=/data/jdk1.8.0_191/jrePATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 保存退出, 是配置文件立即生效 1source /etc/profie 查看java是否安装成功 1java -version]]></content>
      <categories>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机GC详解]]></title>
    <url>%2F2019%2F04%2F13%2FJava%E8%99%9A%E6%8B%9F%E6%9C%BAGC%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. GC的定义和价值​ 在C/C++里是由程序猿自己去申请、管理和释放内存空间，因此没有GC的概念。而在Java中，后台专门有一个专门用于垃圾回收的线程来进行监控、扫描，自动将一些无用的内存进行释放，这就是垃圾收集的一个基本思想，目的在于防止人为的内存泄露。 Java GC（Garbage Collection，垃圾收集，垃圾回收）机制，是Java与C++/C的主要区别之一，作为Java开发者，一般不需要专门编写内存回收和垃圾清理代 码，对内存泄露和溢出的问题，也不需要像C程序员那样战战兢兢。这是因为在Java虚拟机中，存在自动内存管理和垃圾清扫机制。 ​ 概括地说，该机制对 JVM（Java Virtual Machine）中的内存进行标记，并确定哪些内存需要回收，根据一定的回收策略，自动的回收内存，永不停息的保证JVM中的内存空间，防止出现内存泄露和溢出问题。 2. 思考GC的运行原理12第一步：确认那些对象需要回收第二步：使用什么方法回收 3. 确认哪些对象需要回收常见的算法有2种：引用计数算法和根搜索算法。 引用计算法无法解决循环引用问题，java不采用，采用了根搜索算法。 3-1 引用计数法3-1-1 概念1给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。 3-1-2 特点引用计数算法的实现简单，判定效率也高，大部分情况下是一个不错的算法。它很难解决对象之间相互循环引用的问题,对于循环引用的对象无法进行回收 由于循环引用的计数器都不为0，但是他们对于根对象都已经不可达了，但是无法释放。 3-2 根搜索算法3-2-1 概念1由于引用计数算法的缺陷，所以JVM一般会采用一种新的算法，叫做根搜索算法。它的处理方式就是，设立若干种根对象，当任何一个根对象到某一个对象均不可达时，则认为这个对象是可以被回收的。 3-2-2 特点1如上图所示, 由于GC roots到灰色对象部分不可达，所以最终灰色对象部分还是会被当做GC的对象，上图若是采用引用计数法，则灰色对象部分都不会被回收。 3-2-3 可达性的解释 12345678910111213141. 来历* 我们刚刚提到，设立若干种根对象，当任何一个根对象到某一个对象均不可达时，则认为这个对象是可以被回收的。* 我们在后面介绍标记-清理算法/标记整理算法时，也会一直强调从根节点开始，对所有可达对象做一次标记，那什么叫做可达呢？2. 讲解* 这里解释如下：可达性分析：从根（GC Roots）的对象作为起始点，开始向下搜索，搜索所走过的路径称为“引用链”，当一个对象到GC Roots没有任何引用链相连（用图论的概念来讲，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。 3. jvm常见的根(GC roots)对象 a. 栈（栈帧中的本地变量表）中引用的对象。 b. 方法区中的静态成员。 c. 方法区中的常量引用的对象（全局变量 d. 方法栈中JNI（一般说的Native方法）引用的对象。 **注：第一和第四种都是指的方法的本地变量表，第二种表达的意思比较清晰，第三种主要指的是声明为final的常量值。 4. 基础的GC回收算法1* 在根搜索算法的基础上，现代虚拟机的实现当中，垃圾搜集的算法主要有三种，分别是标记-清除算法、复制算法、标记-整理算法。 4-1 最基础：标记/清除算法12345678910111213141. 介绍标记/清除算法是几种GC算法中最基础的算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 2. 原理* 标记/清除算法的基本思想就跟它的名字一样，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 * 标记阶段：标记的过程其实就是前面介绍的可达性分析算法的过程，遍历所有的GC Roots对象，对从GC Roots对象可达的对象都打上一个标识，一般是在对象的header中，将其记录为可达对象； * 清除阶段：清除的过程是对堆内存进行遍历，如果发现某个对象没有被标记为可达对象（通过读取对象header信息），则将其回收。 3. 具体的算法过程* 在标记阶段，从对象GC Root 1可以访问到B对象，从B对象又可以访问到E对象，因此从GC Root 1到B、E都是可达的，同理，对象F、G、J、K都是可达对象；到了清除阶段，所有不可达对象都会被回收。 * 在垃圾收集器进行GC时，必须停止所有Java执行线程（也称&quot;STW, Stop The World&quot;），原因是在标记阶段进行可达性分析时，不可以出现分析过程中对象引用关系还在不断变化的情况，否则的话可达性分析结果的准确性就无法得到保证。在等待标记清除结束后，应用线程才会恢复运行。 12345存在的缺陷:1、效率问题。标记和清除两个阶段的效率都不高，因为这两个阶段都需要遍历内存中的对象，很多时候内存中的对象实例数量是非常庞大的，这无疑很耗费时间，而且GC时需要停止应用程序，这会导致非常差的用户体验。2、空间问题。标记清除之后会产生大量不连续的内存碎片（从上图可以看出），内存空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾回收动作。 * 内存碎片的影响 4-2 复制算法123451. 原理* 复制算法为了解决效率问题，复制算法出现了。复制算法的原理是：将可用内存按容量划分为大小相等的两块，每次使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一块内存上，然后把这一块内存所有的对象一次性清理掉。 2. 具体的算法过程* 复制算法每次都是对整个半区进行内存回收，这样就减少了标记对象遍历的时间，在清除使用区域对象时，不用进行遍历，直接清空整个区域内存，而且在将存活对象复制到保留区域时也是按地址顺序存储的，这样就解决了内存碎片的问题，在分配对象内存时不用考虑内存碎片等复杂问题，只需要按顺序分配内存即可。 123451. 优缺点* 复制算法简单高效，优化了标记/清除算法的效率低、内存碎片多的问题。* 缺点也很明显： a. 将内存缩小为原来的一半，浪费了一半的内存空间，代价太高 b. 如果对象的存活率很高，极端一点的情况假设对象存活率为100%，那么我们需要将所有存活的对象复制一遍，耗费的时间代价也是不可忽视的。 4-3 标记/整理算法123451. 原理 从名字上看，这种算法与标记/清除算法很像，事实上，标记/整理算法的标记过程任然与标记/清除算法一样，但后续步骤不是直接对可回收对象进行回收，而是让所有存活的对象都向一端移动，然后直接清理掉端边线以外的内存。 2. 算法分析 回收后可回收对象被清理掉了，存活的对象按规则排列存放在内存中。这样一来，当我们给新对象分配内存时，jvm只需要持有内存的起始地址即可。标记/整理算法不仅弥补了标记/清除算法存在内存碎片的问题，也消除了复制算法内存减半的高额代价，可谓一举两得。但任何算法都有缺点，就像人无完人，标记/整理算法的缺点就是效率也不高，不仅要标记存活对象，还要整理所有存活对象的引用地址，在效率上不如复制算法。 4-4 总结1234567* 弄清了以上三种算法的原理，下面我们来从几个方面对这几种算法做一个简单排行。效率：复制算法 &gt; 标记/整理算法 &gt; 标记/清除算法（标记/清除算法有内存碎片问题，给大对象分配内存时可能会触发新一轮垃圾回收）内存整齐率：复制算法 = 标记/整理算法 &gt; 标记/清除算法 内存利用率：标记/整理算法 = 标记/清除算法 &gt; 复制算法从上面简单的评估可以看出，标记/清除算法已经比较落后了，但是吃水不忘挖井人，它是后面几种算法的前辈、是基础，在某些场景下它也有用武之地。 5. JVM采用的GC回收算法：分代回收算法5-1 概念1234561. 引言* 通过上面的分析，每种算法都有各自的特点，没有完美的解决方案。所以，JVM虚拟机，根据自身的特点，设计了一个特别的GC回收机制： 分代回收算法。2. 分代回收算法概念* 根据对象的存活周期的不同，将内存划分为几块儿。* Java堆分为新生代和老年代：短命对象归为新生代，长命对象归为老年代。 5-2 原理123456分代回收算法原理a. 少量对象存活，适合复制算法：* 在新生代中，每次GC时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC。 b. 大量对象存活，适合用标记-清理/标记-整理：* 在老年代中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”/“标记-整理”算法进行GC。 5-3 新生代和老年代对象的来历12345a. 所有第一次分配的对象，都是新生代。b. 新生代的内存满后，启动GC，大概98%的对象会被回收，2%的对象，会存活下来。每经历一次GC，对象的年龄增长1岁。c. 当年龄达到阀值（默认是15，可设定），即经历了15次GC，仍然活着，就从新生代转移到老年代。d. 老年代还有来历特别的对象：新生代进行垃圾回收时，某个对象特别大，可能无需等到15岁，就直接进入老年代 5-3 新生代的回收策略123456789101112131. 新生代的特点* 新生代中的对象几乎都是“朝生夕死”的（达到98%，即98%的对象活不过1岁）2. 选择复制算法的原因分析* 复制算法的效率最高，但是浪费50%的内存。* 但是新生代的对象存活率低，所以并不需要按照1：1的比例来划分内存空间* 而是将内存分为一块较大的Eden空间和两块较小的Survivor1空间、Survivor2空间，三者的比例为8：1：1。 3. 算法的实现* 将内存分为一块比较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。* 当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。* 默认Eden和Survivor的大小比例是8:1，也就是说，每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的空间会被浪费。* 98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖于老年代进行分配担保，所以大对象直接进入老年代。 5-4 GC分类123Minor GC：只有新生代进行GC，发生频繁，但是，STW(stop the world)的时间短。Major GC: 年长代进行GC, 因年长代空间比新生代大，故运行次数少，其一般采用“标记-清理”/“标记-整理”，STW的时间长。FULL GC: 新生代和年老代，都进行GC操作。所需时间最长，STW最长。 5-5 STW(Stop-The-World)123456781. 概念* Java中一种全局暂停的现象。全局停顿，所有Java代码停止，native代码可以执行，但不能和JVM交互多半情况下是由于GC引起。 2. GC引起STW的原因* 打个比方：类比在聚会，突然GC要过来打扫房间，聚会时很乱，又有新的垃圾产生，房间永远打扫不干净，只有让大家停止活动了，才能将房间打扫干净。况且，如果没有全局停顿，会给GC线程造成很大的负担，GC算法的难度也会增加，GC很难去判断哪些是垃圾。 3. 危害* 长时间服务停止，没有响应 JVM GC 垃圾回收器类型JVM的垃圾回收器大致分为四种类型： 1、串行垃圾回收器 Serial Garbage Collector 串行垃圾回收器在进行垃圾回收时，它会持有所有应用程序的线程，冻结所有应用程序线程，使用单个垃圾回收线程来进行垃圾回收工作。串行垃圾回收器是为单线程环境而设计的，如果你的程序不需要多线程，启动串行垃圾回收。（一般是command line程序）使用方法：-XX:+UseSerialGCPs：在jdk client模式，不指定VM参数，默认是串行垃圾回收器 2、并行垃圾回收器 Parallel Garbage Collector 并行垃圾回收器在进行垃圾回收时，同样会持有所有应用程序的线程，并冻结所有应用程序线程，来进行垃圾回收工作。唯一和串行垃圾回收器不同的是，并行垃圾回收器是使用多线程来进行垃圾回收工作的。 3、并发标记扫描垃圾回收器 CMS Garbage Collector Concurrent Mark Sweep (CMS)垃圾回收器使用并发标记算法，使用多线程来扫描heap memory来标记实例，然后清理被标记过的实例。CMS垃圾回收器有时候会Hold所有的应用程序线程，但有时候只会Hold部分应用程序线程。 如果能分配更多的CPU给垃圾回收器，那么CMS会是一个比并行垃圾回收更好的选择。XX:+USeParNewGC 4、G1垃圾回收器 G1 Garbage Collector G1垃圾回收器是用在heap memory很大的情况下，把heap划分为很多很多的region块，然后并行的对其进行垃圾回收。G1垃圾回收器在清除实例所占用的内存空间后，还会做内存压缩。 G1垃圾回收器回收region的时候基本不会STW，而是基于 most garbage优先回收 的策略来对region进行垃圾回收的。 –XX:+UseG1GC java8中，使用-XX:+UseStringDeduplication。这个优化会优化冗余的string为一个char数组。 查看JVM使用的默认的垃圾收集器 1java -XX:+PrintCommandLineFlags -version jvm配置 Option Description -XX:+UseSerialGC Serial Garbage Collector 串行垃圾回收器 -XX:+UseParallelGC Parallel Garbage Collector并行垃圾回收器 -XX:+UseConcMarkSweepGC CMS Garbage Collector并发标记垃圾回收器 -XX:ParallelCMSThreads= CMS Collector – number of threads to use 并发标记垃圾回收器使用的线程数，通常是cpu个数 -XX:+UseG1GC G1 Gargbage Collector 使用G1垃圾回收器 优化选项 Option Description -Xms Initial heap memory size 初始化heap大小 -Xms512M -Xmx Maximum heap memory size 设置最大的heap大小 -Xmn Size of Young Generation 年轻代的大小 -XX:PermSize Initial Permanent Generation size 初始化永久带的大小 -XX:MaxPermSize Maximum Permanent Generation size 最大的永久带大小 总结垃圾回收器目前分为四种类型, 串行，并行，并发标记，G1。 小数据量和小型应用，使用串行垃圾回收器即可。 对于对响应时间无特殊要求的，可以使用并行垃圾回收器和并发标记垃圾回收器。（中大型应用） 对于heap可以分配很大的中大型应用，使用G1垃圾回收器比较好，进一步优化和减少了GC暂停时间。 没有银弹，针对不同的场景，选用不同的垃圾回收器。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java Future模式详解]]></title>
    <url>%2F2019%2F04%2F04%2Fjava-Future%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[假如你突然想做饭，但是没有厨具，也没有食材。网上购买厨具比较方便，食材去超市买更放心。 实现分析：在快递员送厨具的期间，我们肯定不会闲着，可以去超市买食材。所以，在主线程里面另起一个子线程去网购厨具。 但是，子线程执行的结果是要返回厨具的，而run方法是没有返回值的。所以，这才是难点，需要好好考虑一下。 模拟代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CommonCook &#123; public static void main(String[] args) throws InterruptedException &#123; long startTime = System.currentTimeMillis(); // 第一步 网购厨具 OnlineShopping thread = new OnlineShopping(); thread.start(); thread.join(); // 保证厨具送到 // 第二步 去超市购买食材 Thread.sleep(2000); // 模拟购买食材时间 Shicai shicai = new Shicai(); System.out.println("第二步：食材到位"); // 第三步 用厨具烹饪食材 System.out.println("第三步：开始展现厨艺"); cook(thread.chuju, shicai); System.out.println("总共用时" + (System.currentTimeMillis() - startTime) + "ms"); &#125; // 网购厨具线程 static class OnlineShopping extends Thread &#123; private Chuju chuju; @Override public void run() &#123; System.out.println("第一步：下单"); System.out.println("第一步：等待送货"); try &#123; Thread.sleep(5000); // 模拟送货时间 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("第一步：快递送到"); chuju = new Chuju(); &#125; &#125; // 用厨具烹饪食材 static void cook(Chuju chuju, Shicai shicai) &#123;&#125; // 厨具类 static class Chuju &#123;&#125; // 食材类 static class Shicai &#123;&#125;&#125; 运行结果： 123456第一步：下单第一步：等待送货第一步：快递送到第二步：食材到位第三步：开始展现厨艺总共用时7013ms 可以看到，多线程已经失去了意义。在厨具送到期间，我们不能干任何事。对应代码，就是调用join方法阻塞主线程。 那如果不阻塞呢?这是不行的, 因为run方法不执行完，属性chuju就没有被赋值，还是null。换句话说，没有厨具，做不了饭。 Java现在的多线程机制，核心方法run是没有返回值的；如果要保存run方法里面的计算结果，必须等待run方法计算完，无论计算过程多么耗时。 如果想在子线程run方法计算的期间，主线程继续异步执行呢?这种想法的核心就是Future模式，下面先应用一下Java自己实现的Future模式。 模拟代码2： 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class FutureCook &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; long startTime = System.currentTimeMillis(); // 第一步 网购厨具 Callable&lt;Chuju&gt; onlineShopping = new Callable&lt;Chuju&gt;() &#123; @Override public Chuju call() throws Exception &#123; System.out.println("第一步：下单"); System.out.println("第一步：等待送货"); Thread.sleep(5000); // 模拟送货时间 System.out.println("第一步：快递送到"); return new Chuju(); &#125; &#125;; FutureTask&lt;Chuju&gt; task = new FutureTask&lt;Chuju&gt;(onlineShopping); new Thread(task).start(); // 第二步 去超市购买食材 Thread.sleep(2000); // 模拟购买食材时间 Shicai shicai = new Shicai(); System.out.println("第二步：食材到位"); // 第三步 用厨具烹饪食材 if (!task.isDone()) &#123; // 联系快递员，询问是否到货 System.out.println("第三步：厨具还没到，心情好就等着（心情不好就调用cancel方法取消订单）"); &#125; Chuju chuju = task.get(); System.out.println("第三步：厨具到位，开始展现厨艺"); cook(chuju, shicai); System.out.println("总共用时" + (System.currentTimeMillis() - startTime) + "ms"); &#125; // 用厨具烹饪食材 static void cook(Chuju chuju, Shicai shicai) &#123;&#125; // 厨具类 static class Chuju &#123;&#125; // 食材类 static class Shicai &#123;&#125;&#125; 运行结果： 1234567第一步：下单第一步：等待送货第二步：食材到位第三步：厨具还没到，心情好就等着（心情不好就调用cancel方法取消订单）第一步：快递送到第三步：厨具到位，开始展现厨艺总共用时5005ms 可以看见，在快递员送厨具的期间，我们没有闲着，可以去买食材；而且我们知道厨具到没到，甚至可以在厨具没到的时候，取消订单不要了。 具体分析一下第二段代码： 把耗时的网购厨具逻辑，封装到了一个Callable的call方法里面。 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; Callable接口可以看作是Runnable接口的补充，call方法带有返回值，并且可以抛出异常。 把Callable实例当作参数，生成一个FutureTask的对象，然后把这个对象当作一个Runnable，作为参数另起线程。 1234567891011121314151617public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 这个继承体系中的核心接口是Future。Future的核心思想是：一个方法f，计算过程可能非常耗时，等待f返回，显然不明智。可以在调用f的时候，立马返回一个Future，可以通过Future这个数据结构去控制方法f的计算过程。 这里的控制包括： get方法：获取计算结果（如果还没计算完，也是必须等待的） cancel方法：还没计算完，可以取消计算过程 isDone方法：判断是否计算完 isCancelled方法：判断计算是否被取消 这些接口的设计很完美，FutureTask的实现注定不会简单，后面再说。 在第三步里面，调用了isDone方法查看状态，然后直接调用task.get方法获取厨具，不过这时还没送到，所以还是会等待3秒。对比第一段代码的执行结果，这里我们节省了2秒。这是因为在快递员送货期间，我们去超市购买食材，这两件事在同一时间段内异步执行。 下面具体分析下FutureTask的实现(JDK8), FutureTask也是一个Runnable，那就看看它的run方法 12345678910111213141516171819202122232425262728public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; // 这里的callable是从构造方法里面传人的 if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); // 保存call方法抛出的异常 &#125; if (ran) set(result); // 保存call方法的执行结果 &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; 先看try语句块里面的逻辑，发现run方法的主要逻辑就是运行Callable的call方法，然后将保存结果或者异常（用的一个属性result）。这里比较难想到的是，将call方法抛出的异常也保存起来了。 state属性有以下几个值: 1234567891011121314/* Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED*/private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 把FutureTask看作一个Future，那么它的作用就是控制Callable的call方法的执行过程，在执行的过程中自然会有状态的转换： 一个FutureTask新建出来，state就是NEW状态；COMPETING和INTERRUPTING用的进行时，表示瞬时状态，存在时间极短；NORMAL代表顺利完成；EXCEPTIONAL代表执行过程出现异常；CANCELED代表执行过程被取消；INTERRUPTED被中断 执行过程顺利完成：NEW -&gt; COMPLETING -&gt; NORMAL 执行过程出现异常：NEW -&gt; COMPLETING -&gt; EXCEPTIONAL 执行过程被取消：NEW -&gt; CANCELLED 执行过程中，线程中断：NEW -&gt; INTERRUPTING -&gt; INTERRUPTED get方法的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; get方法的逻辑很简单，如果call方法的执行过程已完成，就把结果给出去；如果未完成，就将当前线程挂起等待。awaitDone方法里面死循环的逻辑，推演几遍就能弄懂；它里面挂起线程的主要创新是定义了WaitNode类，来将多个等待线程组织成队列，这是与JDK6的实现最大的不同。 挂起的线程唤醒： 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); // 唤醒线程 &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 以上就是JDK8的大体实现逻辑 JDK6的FutureTask的基本操作都是通过自己的内部类Sync来实现的，而Sync继承自AbstractQueuedSynchronizer这个并发工具类 12345678910111213/** State value representing that task is running */private static final int RUNNING = 1;/** State value representing that task ran */private static final int RAN = 2;/** State value representing that task was cancelled */private static final int CANCELLED = 4;/** The underlying callable */private final Callable&lt;V&gt; callable;/** The result to return from get() */private V result;/** The exception to throw from get() */private Throwable exception; 里面的状态只有基本的几个，而且计算结果和异常是分开保存的。 12345678V innerGet() throws InterruptedException, ExecutionException &#123; acquireSharedInterruptibly(0); if (getState() == CANCELLED) throw new CancellationException(); if (exception != null) throw new ExecutionException(exception); return result;&#125; 这个get方法里面处理等待线程队列的方式是调用了acquireSharedInterruptibly方法 再上一个场景：我们自己写一个简单的数据库连接池，能够复用数据库连接，并且能在高并发情况下正常工作。 1234567891011121314151617181920212223import java.util.concurrent.ConcurrentHashMap;public class ConnectionPool &#123; private ConcurrentHashMap&lt;String, Connection&gt; pool = new ConcurrentHashMap&lt;String, Connection&gt;(); public Connection getConnection(String key) &#123; Connection conn = null; if (pool.containsKey(key)) &#123; conn = pool.get(key); &#125; else &#123; conn = createConnection(); pool.putIfAbsent(key, conn); &#125; return conn; &#125; public Connection createConnection() &#123; return new Connection(); &#125; class Connection &#123;&#125;&#125; 我们用了ConcurrentHashMap，这样就不必把getConnection方法置为synchronized(当然也可以用Lock)，当多个线程同时调用getConnection方法时，性能大幅提升。 貌似很完美了，但是有可能导致多余连接的创建，推演一遍： 某一时刻，同时有3个线程进入getConnection方法，调用pool.containsKey(key)都返回false，然后3个线程各自都创建了连接。虽然ConcurrentHashMap的put方法只会加入其中一个，但还是生成了2个多余的连接。如果是真正的数据库连接，那会造成极大的资源浪费。 所以，我们现在的难点是：如何在多线程访问getConnection方法时，只执行一次createConnection。 结合之前Future模式的实现分析：当3个线程都要创建连接的时候，如果只有一个线程执行createConnection方法创建一个连接，其它2个线程只需要用这个连接就行了。再延伸，把createConnection方法放到一个Callable的call方法里面，然后生成FutureTask。我们只需要让一个线程执行FutureTask的run方法，其它的线程只执行get方法就好了。 12345678910111213141516171819202122232425262728293031323334353637import java.util.concurrent.Callable;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class ConnectionPool &#123; private ConcurrentHashMap&lt;String, FutureTask&lt;Connection&gt;&gt; pool = new ConcurrentHashMap&lt;String, FutureTask&lt;Connection&gt;&gt;(); public Connection getConnection(String key) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Connection&gt; connectionTask = pool.get(key); if (connectionTask != null) &#123; return connectionTask.get(); &#125; else &#123; Callable&lt;Connection&gt; callable = new Callable&lt;Connection&gt;() &#123; @Override public Connection call() throws Exception &#123; return createConnection(); &#125; &#125;; FutureTask&lt;Connection&gt; newTask = new FutureTask&lt;Connection&gt;(callable); connectionTask = pool.putIfAbsent(key, newTask); if (connectionTask == null) &#123; connectionTask = newTask; connectionTask.run(); &#125; return connectionTask.get(); &#125; &#125; public Connection createConnection() &#123; return new Connection(); &#125; class Connection &#123; &#125;&#125; 当3个线程同时进入else语句块时，各自都创建了一个FutureTask，但是ConcurrentHashMap只会加入其中一个。第一个线程执行pool.putIfAbsent方法后返回null，然后connectionTask被赋值，接着就执行run方法去创建连接，最后get。后面的线程执行pool.putIfAbsent方法不会返回null，就只会执行get方法。 在并发的环境下，通过FutureTask作为中间转换，成功实现了让某个方法只被一个线程执行。当然这个还是有缺陷: 多个线程同时调用get方法时，得到的是同一个数据库连接的多个引用，这会导致严重的问题。这是另外一个问题, 就不再多说.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github上一款star过万的神器-thefuck]]></title>
    <url>%2F2019%2F03%2F25%2FGithub%E4%B8%8A%E4%B8%80%E6%AC%BEstar%E8%BF%87%E4%B8%87%E7%9A%84%E7%A5%9E%E5%99%A8-thefuck%2F</url>
    <content type="text"><![CDATA[简介 The Fuck is a magnificent app, inspired by a @liamosaur tweet, that corrects errors in previous console commands. 项目地址, 它可以帮你纠正大部分的命令行输入错误 想要返回上一级目录, 手速过快（你懂得）输成了cd..？ 。。。 想查看数据库的运行状态, 忘记单词拼写 (^_^;) systecl status mysql？ 。。。 以上这些都不是问题, fuck 一下就好了, 就像你遇到bug了, 大喊一声: 艹(第四声) 安装安装环境是CentOS7, The Fuck的环境要求: python (3.4+) pip python-dev 由于CentOS 7 默认安装了python2.7.5, 一些命令要用它比如yum, 因此我们需要安装python3并与python2共存 查看是否已经安装python, 使用命令: python -V. 使用命令: which python 查看python可执行文件的位置, 我的是在 /usr/bin 目录下, 切换到该目录下执行: ll python*命令查看 里面会有个python2和python软链接, python指向的是python2.7, 因为我们要装python3, 所以python要指向python3才行, 我们后面需要对它进行备份, 先安装相关环境:1yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make 备份:1mv python python.bak 安装python3 获取安装包:1wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tar.xz 下载完成, 解压:1tar -xvJf Python-3.6.8.tar.xz 切换进入1cd Python-3.6.8 编译安装12./configure prefix=/usr/local/python3make &amp;&amp; make install 安装完毕，/usr/local/目录下就会有python3了 因此我们可以添加软链到执行目录下/usr/bin1ln -s /usr/local/python3/bin/python3 /usr/bin/python 再去/usr/bin目录下, 可以看到已经创建了一个指向python3的软链接python,测试是否安装成功:1python -V 看看输出的是不是python3的版本, 再执行 python2 -V` 看到的就是python2的版本 因为执行yum需要python2版本，所以我们还要修改yum的配置，执行：1vi /usr/bin/yum 把 #! /usr/bin/python 修改为#! /usr/bin/python2 同理 vi /usr/libexec/urlgrabber-ext-down 文件里面的 #! /usr/bin/python 也要修改为#! /usr/bin/python2 现在python3已经安装成功, 同时python2也存在 安装pip并升级pip工具 方法一: 直接安装 12yum install -y python-pippip install --upgrade pip setuptools 方法二: python3安装完成后默认已经带有pip, 你可以用以下命令,创建软链接 1ln -s /usr/local/python3/bin/pip /usr/bin/pip 安装python-dev 需要注意的是: 在centOS7中该模块叫 python-devel 1yum install -y python-devel 安装thefuck 1pip install thefuck 修改文件 vim /usr/bin/thefuck, 把第一行的 #!/usr/bin/python2 改成 #!/usr/bin/python 查看thefuck是否安装成功: 1fuck -v 如果看到如下信息:1The Fuck 3.28 using Python 3.6.8 and Bash 4.2.46(2)-release 则安装成功下面我们来试一下:123456[root@localhost usr]# pwfbash: pwf: 未找到命令...[root@localhost usr]# fuck​​​​​​​​​​pwd [enter/↑/↓/ctrl+c]/usr[root@localhost usr]# OK! 以后有问题fuck一下就好了ヽ(￣▽￣)ﾉ]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql锁机制]]></title>
    <url>%2F2019%2F03%2F24%2Fmysql%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[概述相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。MySQL大致可归纳为以下3种锁： 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 MySQL表级锁的锁模式（MyISAM)MySQL表级锁有两种模式：表共享锁（Table Read Lock）和表独占写锁（Table Write Lock）。 对MyISAM的读操作，不会阻塞其他用户对同一表请求，但会阻塞对同一表的写请求； 对MyISAM的写操作，则会阻塞其他用户对同一表的读和写操作； MyISAM表的读操作和写操作之间，以及写操作之间是串行的。 当一个线程获得对一个表的写锁后，只有持有锁线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。 MySQL表级锁的锁模式 ＭySQL的表锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。锁模式的兼容如下表 请求锁模式/是否兼容 None 读锁 写锁 读锁 是 是 否 写锁 是 否 否 可见，对ＭyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对ＭyISAM表的写操作，则会阻塞其他用户对同一表的读和写请求；ＭyISAM表的读和写操作之间，以及写和写操作之间是串行的！（当一线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。） 如何加表锁 MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预 给MyISAM表显示加锁，一般是为了一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。例如，有一个订单表orders，其中记录有订单的总金额total，同时还有一个订单明细表order_detail，其中记录有订单每一产品的金额小计subtotal，假设我们需要检查这两个表的金额合计是否相等，可能就需要执行如下两条SQL： 12SELECT SUM(total) FROM orders;SELECT SUM(subtotal) FROM order_detail; 这时，如果不先给这两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，order_detail表可能已经发生了改变。因此，正确的方法应该是： 1234LOCK tables orders read local,order_detail read local;SELECT SUM(total) FROM orders;SELECT SUM(subtotal) FROM order_detail;Unlock tables; 上面的例子在LOCK TABLES时加了‘local’选项，其作用就是在满足MyISAM表并发插入条件的情况下，允许其他用户在表尾插入记录 在用LOCKTABLES给表显式加表锁是时，必须同时取得所有涉及表的锁，并且MySQL支持锁升级。也就是说，在执行LOCK TABLES后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。其实，在自动加锁的情况下也基本如此，MySQL问题一次获得SQL语句所需要的全部锁。这也正是MyISAM表不会出现死锁（Deadlock Free）的原因 一个session使用LOCK TABLE 命令给表film_text加了读锁，这个session可以查询锁定表中的记录，但更新或访问其他表都会提示错误；同时，另外一个session可以查询表中的记录，但更新就会出现锁等待。 当使用LOCK TABLE时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁多少次，否则也会出错！ 并发锁 在一定条件下，MyISAM也支持查询和操作的并发进行。MyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入的行为，其值分别可以为0、1或2。 当concurrent_insert设置为0时，不允许并发插入。 当concurrent_insert设置为1时，如果MyISAM允许在一个读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置。 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾插入记录，都允许在表尾并发插入记录。 可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入锁争用。例如，将concurrent_insert系统变量为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIONMIZE TABLE语句来整理空间碎片，收到因删除记录而产生的中间空洞。 MyISAM的锁调度 前面讲过，MyISAM存储引擎的读和写锁是互斥，读操作是串行的。那么，一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？答案是写进程先获得锁。不仅如此，即使读进程先请求先到锁等待队列，写请求后到，写锁也会插到读请求之前！这是因为MySQL认为写请求一般比读请求重要。这也正是MyISAM表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。这种情况有时可能会变得非常糟糕！幸好我们可以通过一些设置来调节MyISAM的调度行为。 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。 虽然上面3种方法都是要么更新优先，要么查询优先的方法，但还是可以用其来解决查询相对重要的应用（如用户登录系统）中，读锁等待严重的问题。 另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL变暂时将写请求的优先级降低，给读进程一定获得锁的机会。 这里还要强调一点：一些需要长时间运行的查询操作，也会使写进程“饿死”！因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题。因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。 InnoDB锁问题InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。行级锁和表级锁本来就有许多不同之处，另外，事务的引入也带来了一些新问题。 1.事务（Transaction）及其ACID属性 事务是由一组SQL语句组成的逻辑处理单元，事务具有4属性，通常称为事务的ACID属性。 原性性（Actomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以操持完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 2.并发事务带来的问题 相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况。 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改保存其更改副本的编辑人员覆盖另一个编辑人员所做的修改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。 不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。 幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 3.事务隔离级别 在并发事务处理带来的问题中，“更新丢失”通常应该是完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。 “脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。数据库实现事务隔离的方式，基本可以分为以下两种: 一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库。 数据库的事务隔离级别越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的，同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。 为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92定义了４个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己业务逻辑要求，通过选择不同的隔离级别来平衡＂隔离＂与＂并发＂的矛盾 事务４种隔离级别比较 隔离级别 读数据一致性及允许的并发副作用 读数据一致性 脏读 不可重复读 幻读 未提交读（Read uncommitted） 最低级别，只能保证不读取物理上损坏的数据 是 是 是 已提交度（Read committed） 语句级 否 是 是 可重复读（Repeatable read） 事务级 否 否 是 可序列化（Serializable） 最高级别，事务级 否 否 否 最后要说明的是：各具体数据库并不一定完全实现了上述４个隔离级别，例如，Oracle只提供Read committed和Serializable两个标准级别，另外还自己定义的Read only隔离级别：SQL Server除支持上述ISO/ANSI SQL92定义的４个级别外，还支持一个叫做＂快照＂的隔离级别，但严格来说它是一个用MVCC实现的Serializable隔离级别。ＭySQL支持全部４个隔离级别，但在具体实现时，有一些特点，比如在一些隔离级下是采用MVCC一致性读，但某些情况又不是。 获取InonoD行锁争用情况 可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况： 1234567891011mysql&gt; show status like 'innodb_row_lock%';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| Innodb_row_lock_current_waits | 0 || Innodb_row_lock_time | 0 || Innodb_row_lock_time_avg | 0 || Innodb_row_lock_time_max | 0 || Innodb_row_lock_waits | 0 |+-------------------------------+-------+5 rows in set (0.00 sec) 如果发现争用比较严重，如Innodb_row_lock_waits和Innodb_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。 InnoDB的行锁模式及加锁方法InnoDB实现了以下两种类型的行锁。 共享锁（s）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 排他锁（Ｘ）：允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。 另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。 意向共享锁（IS）：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。 InnoDB行锁模式兼容性列表 当前锁模式/是否兼容/请求锁模式 X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 如果一个事务请求的锁模式与当前的锁兼容，InnoDB就请求的锁授予该事务；反之，如果两者两者不兼容，该事务就要等待锁释放。 意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（Ｘ）；对于普通SELECT语句，InnoDB会自动给涉及数据集加排他锁（Ｘ）；对于普通SELECT语句，InnoDB不会任何锁；事务可以通过以下语句显示给记录集加共享锁或排锁。 共享锁（Ｓ）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE 排他锁（X）：SELECT * FROM table_name WHERE … FOR UPDATE 用SELECT .. IN SHARE MODE获得共享锁，主要用在需要数据依存关系时确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT … FOR UPDATE方式获取排他锁。 InnoDB行锁实现方式 InnoDB行锁是通过索引上的索引项来实现的，这一点ＭySQL与Oracle不同，后者是通过在数据中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味者：只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁！在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。 间隙锁（Next-Key锁） 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。 举例来说，假如emp表中只有101条记录，其empid的值分别是1,2,…,100,101，下面的SQL：1SELECT * FROM emp WHERE empid &gt; 100 FOR UPDATE 是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。 InnoDB使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。 很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。 什么时候使用表锁 对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在特殊事务中，也可以考虑使用表级锁。 第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。 第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。 当然，应用中这两种事务不能太多，否则，就应该考虑使用ＭyISAＭ表。在InnoDB下 ，使用表锁要注意以下两点。 使用LOCK TALBES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。 在用LOCAK TABLES对InnoDB锁时要注意，要将AUTOCOMMIT设为0，否则ＭySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁，正确的方式见如下语句。 12345SET AUTOCOMMIT=0;LOCAK TABLES t1 WRITE, t2 READ, ...;[do something with tables t1 and here];COMMIT;UNLOCK TABLES; 关于死锁 ＭyISAM表锁是deadlock free的，这是因为ＭyISAM总是一次性获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但是在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了InnoDB发生死锁是可能的。 发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。 通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小、以及访问数据库的SQL语句，绝大部分都可以避免。下面就通过实例来介绍几种死锁的常用方法。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序为访问表，这样可以大大降低产生死锁的机会。如果两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可能避免。 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的可能。 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应该先申请共享锁，更新时再申请排他锁，甚至死锁。 在REPEATEABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT…ROR UPDATE加排他锁，在没有符合该记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可以避免问题。 当隔离级别为READ COMMITED时，如果两个线程都先执行SELECT…FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第１个线程提交后，第２个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第３个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。 尽管通过上面的设计和优化等措施，可以大减少死锁，但死锁很难完全避免。因此，在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯。 如果出现死锁，可以用SHOW INNODB STATUS命令来确定最后一个死锁产生的原因和改进措施。 总结对于ＭyISAM的表锁，主要有以下几点 共享读锁（S）之间是兼容的，但共享读锁（S）和排他写锁（X）之间，以及排他写锁之间（X）是互斥的，也就是说读和写是串行的。 在一定条件下，ＭyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表和插入的锁争用问题。 ＭyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIPORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。 由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，ＭyISAM表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。 对于InnoDB表，主要有以下几点 InnoDB的行销是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。 InnoDB间隙锁机制，以及InnoDB使用间隙锁的原因。 在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。 ＭySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。 锁冲突甚至死锁很难完全避免。 在了解InnoDB的锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括： 尽量使用较低的隔离级别 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会。 选择合理的事务大小，小事务发生锁冲突的几率也更小。 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁。 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大减少死锁的机会。 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁。 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。 原文链接]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker块速搭建l2tp VPN服务器]]></title>
    <url>%2F2019%2F03%2F20%2Fdocker%E5%9D%97%E9%80%9F%E6%90%AD%E5%BB%BAl2tp-VPN%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[参考: docker快速搭建l2tp VPN服务器 docker就像一个大仓库, 我们只要从仓库中取出我们需要的应用(vpn服务器)运行起来就能用了。服务器是国外云服务器, 系统是CentOS7 搭建vpn服务器1. 获取 l2tp 的镜像1docker pull fcojean/l2tp-ipsec-vpn-server 2. 配置PSK，用户名和密码。先创建配置文件vpn.env1vim vpn.env 将一下配置复制到vpn.env文件中。该配置psk为“abcdefg”，两个用户名user1和user2，密码都为12345612VPN_IPSEC_PSK=abcdefgVPN_USER_CREDENTIAL_LIST=[&#123;&quot;login&quot;:&quot;user1&quot;,&quot;password&quot;:&quot;123456&quot;&#125;,&#123;&quot;login&quot;:&quot;user2&quot;,&quot;password&quot;:&quot;123456&quot;&#125;] 3. 加载 IPsec NETKEY 内核模块1sudo modprobe af_key 4. 启动镜像 该命令加载env文件做配置文件，并将对应端口和服务器的端口做绑定。注意：在执行该命令时当前目录下必须有之前创建的vpn.env文件，否则会报错。12345678docker run \ --name vpn-server \ --env-file ./vpn.env \ -p 500:500/udp \ -p 4500:4500/udp \ -v /lib/modules:/lib/modules:ro \ -d --privileged \ fcojean/l2tp-ipsec-vpn-server 查看当前的vpn服务是否正常启动1docker logs vpn-server 有如下输出则表示已正常启动vpn服务器。 5. 关闭防火墙，先查看防火墙状态 如果防火墙未开启则跳过此部1systemctl stop firewalld 除了关闭防火墙，云服务器还需要配置访问规则, 即开放端口, 一定要记得开放500端口和4500端口, 这两个端口是vpn使用的 配置客户端Windows10系统, 设置VPN: 右键单击系统托盘中的无线/网络图标。 选择 打开网络与共享中心。 单击 设置新的连接或网络。 选择 连接到工作区，然后单击 下一步。 单击 使用我的Internet连接 (VPN)。 在 Internet地址 字段中输入你的 VPN 服务器 IP。 在 目标名称 字段中输入任意内容。单击 创建。 返回 网络与共享中心。单击左侧的 更改适配器设置。 右键单击新创建的 VPN 连接: 填写之前创建的vpn服务器ip, PSK, 用户名和密码, 点击保存. 注意VPN类型选择 [使用预共享秘钥的L2TP/IPSec PSK] 以管理员身份启用命令提示符：执行以下两条命令 1REG ADD HKLM\SYSTEM\CurrentControlSet\Services\PolicyAgent /v AssumeUDPEncapsulationContextOnSendRule /t REG_DWORD /d 0x2 /f 1REG ADD HKLM\SYSTEM\CurrentControlSet\Services\RasMan\Parameters /v ProhibitIpSec /t REG_DWORD /d 0x0 /f 设置VPN连接属性.请参考: win10设置VPN连接 至此, 设置完毕, 请关机重启, 再点击连接VPN, 成功! (下图为方便说明, 连接了两个VPN) 安卓手机不用设置可以直接连VPN, 但注意vpn类型选择 L2TP/IPSec PSK, 建议先用安卓手机（连WiFi，流量可能有意外）检测vpn是否搭建成功, 再尝试Windows10连接VPN]]></content>
      <categories>
        <category>VPN</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker搭建GitLab-CE中文版详细教程]]></title>
    <url>%2F2019%2F03%2F19%2Fdocker%E6%90%AD%E5%BB%BAgitlab-ce%E4%B8%AD%E6%96%87%E7%89%88%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[我是在本机局域网搭建的gitlab, 切记服务器配置不能太低, gitlab比较耗资源, 这也是它功能强大的来源, 搭建环境: 系统: centOS7, 8G内存, i5处理器 ip: 10.12.2.22 预留端口: 8090 1.获取镜像1docker pull beginor/gitlab-ce:11.0.1-ce.0 查看镜像, 有1.5G大小 2.运行镜像由于是docker镜像运行, 所以我们需要把gitlab的配置, 数据, 日志存到容器外面, 即将其挂载到宿主机。先准备三个目录：123mkdir -p /home/software/gitlab/etcmkdir -p /home/software/gitlab/logsmkdir -p /home/software/gitlab/data 准备好这三个目录之后， 就可以开始运行 Docker 镜像了。完整的运行命令如下 ( 查看更多详细配置 )：12345678910111213docker run \--detach \--publish 8443:443 \ # 映射https端口, 不过本文中没有用到--publish 8090:80 \ # 映射宿主机8090端口到容器中80端口--publish 8022:22 \ # 映射22端口, 可不配--name gitlab \ --restart always \--hostname 10.12.2.22 \ # 局域网宿主机的ip, 如果是公网主机可以写域名-v /home/software/gitlab/etc:/etc/gitlab \ # 挂载gitlab的配置文件-v /home/software/gitlab/logs:/var/log/gitlab \ # 挂载gitlab的日志文件-v /home/software/gitlab/data:/var/opt/gitlab \ # 挂载gitlab的数据-v /etc/localtime:/etc/localtime:ro \ # 保持宿主机和容器时间同步--privileged=true beginor/gitlab-ce # 在容器中能以root身份执行操作 这个时候已经搭建完了, 查看一下 ( 启动需要几分钟, 我大概启动了2分钟多 ) : 看到状态显示为 healthy 就代表已经启动了, 这时候去访问 http://10.12.2.22:8090第一次访问时，将被重定向到密码重置屏幕, 默认帐户的用户名是root, 登录后, 您可以更改用户名 3.配置gitlab要能充分使用gitlab, 必须配置邮件发送功能, 修改配置文件 gitlab.rb (启动镜像后产生的文件), 这里我配置的是QQ邮箱 ( 查看其它邮箱配置 )1vim /home/software/gitlab/etc/gitlab.rb 在文件的最后加上配置:12345678910gitlab_rails[&apos;smtp_enable&apos;] = truegitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.qq.com&quot;gitlab_rails[&apos;smtp_port&apos;] = 465gitlab_rails[&apos;smtp_user_name&apos;] = &quot;fuck@qq.com&quot;gitlab_rails[&apos;smtp_password&apos;] = &quot;授权码&quot;gitlab_rails[&apos;smtp_domain&apos;] = &quot;smtp.qq.com&quot;gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = truegitlab_rails[&apos;smtp_tls&apos;] = truegitlab_rails[&apos;gitlab_email_from&apos;] = &apos;fuck@qq.com&apos; 网上很多教程说要配置external_url, 我按照加了配置后gitlab反而异常了, 不管它, 用默认的就好了, 保存退出, 再另外开一个终端, 进入容器:1docker exec -it gitlab /bin/bash 此时已经进入docker容器了, 容器中执行命令重新配置gitlab:1gitlab-ctl reconfigure # 重新配置 现在可以测试邮件是否配置正确了, 同样容器中执行:12gitlab-rails console # 进入邮件控制台, 稍等一会才能进入Notify.test_email(&apos;baka@qq.com&apos;, &apos;Message Subject&apos;, &apos;Message Body&apos;).deliver_now # 发送测试邮件 邮件配置已经完成了, 现在需要配置项目路径 (如果你预留的gitlab映射端口是80的话, 你已经配置完了), 在宿主机中 (容器外面) 修改文件gitlab.yml, 如果port不对, 要改过来1vim /home/software/gitlab/data/gitlab-rails/etc/gitlab.yml 改完之后在容器中重启gitlab就配置完成了。 注意: 此时不能再重新配置(gitlab-ctl reconfigure), 否则可能会改变刚修改的gitlab.yml文件1gitlab-ctl restart # 重启gitlab gitlab常用命令123456789101112131415# 重新应用gitlab的配置gitlab-ctl reconfigure # 重启gitlab服务gitlab-ctl restart # 查看gitlab运行状态gitlab-ctl status #停止gitlab服务gitlab-ctl stop # 查看gitlab运行日志gitlab-ctl tail gitlab邮件没收到? 看这里如果没收到邮件, 有两个可能 : 电脑没网络 (我就是犯了这个愚蠢的错误, 主机改成静态ip后没网了也不知道, 折腾了很久才发现) 邮件被当做垃圾邮件了 ( 去垃圾箱看看吧 -_-! ) 邮箱密码错了, 注意是授权码哦 gitlab搭建前后对比 搭建前, 内存只占用了500多M 搭建后, 内存就占用了5G]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程池实现原理]]></title>
    <url>%2F2019%2F03%2F16%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Java中的ThreadPoolExecutor类java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法：123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： 123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值：1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService AbstractExecutorService的实现：12345678910111213141516171819202122232425262728public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 ExecutorService接口的实现：123456789101112131415161718192021public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而ExecutorService又是继承了Executor接口 Executor接口的实现：123public interface Executor &#123; void execute(Runnable command);&#125; ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor之间的关系 Executor是一个顶层接口，在它里面只声明到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法：1234execute()submit()shutdown()shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果 shutdown()和shutdownNow()是用来关闭线程池的。 线程池实现原理1. 线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态：12345volatile int runState;static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2. 任务的执行 ThreadPoolExecutor类中其他的一些比较重要成员变量：12345678910111213141516171819private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可：123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下：1if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行1addIfUnderCorePoolSize(command) 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断：1if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行：1ddIfUnderMaximumPoolSize(command) 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面：1if (runState == RUNNING &amp;&amp; workQueue.offer(command)) 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断：1if (runState != RUNNING || poolSize == 0) 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行：1ensureQueuedTaskHandled(command) 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize：123456789101112131415private boolean addIfUnderCorePoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); //创建线程去执行firstTask任务 &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true;&#125; 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心线程池大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行1t = addThread(firstTask); 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现：123456789101112private Thread addThread(Runnable firstTask) &#123; Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); //创建一个线程，执行任务 if (t != null) &#123; w.thread = t; //将创建的线程的引用赋值为w的成员变量 workers.add(w); int nt = ++poolSize; //当前线程数加1 if (nt &gt; largestPoolSize) largestPoolSize = nt; &#125; return t;&#125; 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private final class Worker implements Runnable &#123; private final ReentrantLock runLock = new ReentrantLock(); private Runnable firstTask; volatile long completedTasks; Thread thread; Worker(Runnable firstTask) &#123; this.firstTask = firstTask; &#125; boolean isActive() &#123; return runLock.isLocked(); &#125; void interruptIfIdle() &#123; final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) &#123; try &#123; if (thread != Thread.currentThread()) thread.interrupt(); &#125; finally &#123; runLock.unlock(); &#125; &#125; &#125; void interruptNow() &#123; thread.interrupt(); &#125; private void runTask(Runnable task) &#123; final ReentrantLock runLock = this.runLock; runLock.lock(); try &#123; if (runState &lt; STOP &amp;&amp; Thread.interrupted() &amp;&amp; runState &gt;= STOP) boolean ran = false; beforeExecute(thread, task); //beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据 //自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 try &#123; task.run(); ran = true; afterExecute(task, null); ++completedTasks; &#125; catch (RuntimeException ex) &#123; if (!ran) afterExecute(task, ex); throw ex; &#125; &#125; finally &#123; runLock.unlock(); &#125; &#125; public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); //当任务队列中没有任务时，进行清理工作 &#125; &#125;&#125; 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样：1Thread t = new Thread(w); 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了：123456789101112public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125;&#125; 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现：123456789101112131415161718192021222324252627Runnable getTask() &#123; for (;;) &#123; try &#123; int state = runState; if (state &gt; SHUTDOWN) return null; Runnable r; if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) //如果线程数大于核心池大小或者允许为核心池线程设置空闲时间， //则通过poll取任务，若等待一定的时间取不到任务，则返回null r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); if (r != null) return r; if (workerCanExit()) &#123; //如果没取到任务，即r为null，则判断当前的worker是否可以退出 if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); //中断处于空闲状态的worker return null; &#125; // Else retry &#125; catch (InterruptedException ie) &#123; // On interruption, re-check runState &#125; &#125;&#125; 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现：12345678910111213141516private boolean workerCanExit() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean canExit; //如果runState大于等于STOP，或者任务缓存队列为空了 //或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1 try &#123; canExit = runState &gt;= STOP || workQueue.isEmpty() || (allowCoreThreadTimeOut &amp;&amp; poolSize &gt; Math.max(1, corePoolSize)); &#125; finally &#123; mainLock.unlock(); &#125; return canExit;&#125; 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现：12345678910void interruptIdleWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) //实际上调用的是worker的interruptIfIdle()方法 w.interruptIfIdle(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中：123456789101112void interruptIfIdle() &#123; final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) &#123; //注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的 //如果成功获取了锁，说明当前worker处于空闲状态 try &#123; if (thread != Thread.currentThread()) thread.interrupt(); &#125; finally &#123; runLock.unlock(); &#125; &#125;&#125; 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的：123456789101112131415private boolean addIfUnderMaximumPoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); &#125; finally &#123; mainLock.unlock(); &#125; if (t == null) return false; t.start(); return true;&#125; 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3. 线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现：12345678910public boolean prestartCoreThread() &#123; return addIfUnderCorePoolSize(null); //注意传进去的参数是null&#125; public int prestartAllCoreThreads() &#123; int n = 0; while (addIfUnderCorePoolSize(null))//注意传进去的参数是null ++n; return n;&#125; 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的1r = workQueue.take(); 即等待任务队列中有任务。 4. 任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5. 任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 6. 线程池的关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7. 线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 如何合理配置线程池的大小一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1 如果是IO密集型任务，参考值可以设置为2*NCPU 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 原文链接]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java四个线程池的实现]]></title>
    <url>%2F2019%2F03%2F11%2Fjava%E5%9B%9B%E4%B8%AA%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[多线程的几种实现方式1、实现Runnable接口12345678910111213public class DemoThreadTask implements Runnable&#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125; public static void main(String[] args) &#123; DemoThreadTask task = new DemoThreadTask(); Thread t = new Thread(task); t.start(); ... &#125;&#125; 实现Runnable接口，利用Runnable实例构造Thread，是较常用且最本质实现。此构造方法相当于对Runnable实例进行一层包装，在线程t启动时，调用Thread的run方法从而间接调用target.run()：1234567891011public class Thread implements Runnable &#123; /* What will be run. */ private Runnable target; public void run() &#123; if (target != null) &#123; target.run(); &#125; &#125; ...&#125; 2、继承Thread类12345678910111213public class DemoThread extends Thread&#123; @Override //重写run方法 public void run() &#123; // TODO Auto-generated method stub &#125; public static void main(String[] args) &#123; DemoThread t = new DemoThread(); t.start(); ... &#125;&#125; 这种实现方式是显示的继承了Thread，但从类图中我们可以看到，Thread类本身就继承自Runnable，所以继承Thread的本质依然是实现Runnable接口定义的run方法。 需要注意的是继承Thread方式，target对象为null，重写了run方法，导致方式1中的Thread原生的run方法失效，因此并不会调用到target.run()的逻辑，而是直接调用子类重写的run方法。 因为java是单根继承，此方式一般不常用。 3、实现Callable接口并通过FutureTask包装1234567891011121314151617public class DemoCallable implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; // TODO Auto-generated method stub return null; &#125; public static void main(String[] args) throws Exception &#123; DemoCallable c = new DemoCallable(); FutureTask&lt;String&gt; future = new FutureTask&lt;&gt;(c); Thread t = new Thread(future); t.start(); ... String result = future.get(); //同步获取返回结果 System.out.println(result); &#125;&#125; 实现Callable接口通过FutureTask包装，可以获取到线程的处理结果，future.get()方法获取返回值，如果线程还没执行完，则会阻塞。 FutureTask实现了RunnableFuture，RunnableFuture则实现了Runnable和Future两个接口。因此构造Thread时，FutureTask还是被转型为Runnable使用。因此其本质还是实现Runnable接口。 4、匿名内部类 匿名内部类也有多种变体，上述三种方式都可以使用匿名内部类来隐式实例化。123456789101112131415161718192021public class Demo&#123; public static void main(String[] args) throws Exception &#123; //方式一：Thread匿名内部类 new Thread()&#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125; &#125;.start(); //方式二：Runnable匿名内部类 new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125; &#125;).start(); ... &#125;&#125; 5、Lambda表达式 123456public class Demo&#123; public static void main(String[] args) throws Exception &#123; new Thread(() -&gt; System.out.println(&quot;running&quot;) ).start() ; ... &#125;&#125; 6、线程池 1234567891011121314public class DemoThreadTask implements Runnable&#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println(&quot;running&quot;); &#125; public static void main(String[] args) &#123; DemoThreadTask task = new DemoThreadTask(); ExecutorService ex = Executors.newCachedThreadPool(); ex.execute(task); ... &#125;&#125; 线程池与前面所述其他方式的区别在于执行线程的时候由ExecutorService去执行，最终还是利用Thread创建线程。线程池的优势在于线程的复用，从而提高效率。 7、定时器 123456789101112public class DemoTimmerTask &#123; public static void main(String[] args) throws Exception &#123; Timer timer = new Timer(); timer.scheduleAtFixedRate((new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;定时任务1执行了....&quot;); &#125; &#125;), 2000, 1000); &#125;&#125; TimerTask的实现了Runnable接口，Timer内部有个TimerThread继承自Thread，因此绕回来还是Thread + Runnable。 Java通过Executors提供四种线程池1234newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 1. newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。示例代码如下：123456789101112131415161718192021import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors;public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(index); &#125; &#125;); &#125; &#125; &#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下：1234567891011121314151617181920import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors;public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; fixedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors() 3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：1234567891011121314import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println(&quot;delay 3 seconds&quot;); &#125; &#125;, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟3秒执行。 定期执行示例代码如下：1234567891011121314import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; System.out.println(&quot;delay 1 seconds, and excute every 3 seconds&quot;); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟1秒后每3秒执行一次。 4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下：123456789101112131415161718192021import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 结果依次输出，相当于顺序执行各个任务。 可以使用JDK自带的监控工具来监控我们创建的线程数量，运行一个不终止的线程，创建指定量的线程，来观察： 工具目录：C:\Program Files\Java\jdk1.8.0_171\bin\jconsole.exe 运行程序做稍微修改：12345678910111213141516171819202122232425262728import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; while(true) &#123; System.out.println(index); Thread.sleep(10 * 1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 可以查看线程数的变化]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何向开源项目提交无法解答的问题]]></title>
    <url>%2F2019%2F03%2F06%2F%E5%A6%82%E4%BD%95%E5%90%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BA%A4%E6%97%A0%E6%B3%95%E8%A7%A3%E7%AD%94%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[作为一名互联网开发者，总会使用和参与过一些开源项目。开源社区里，有些你来我往，有些则石沉大海。人们提问的方式有许多迷人和实用的共通之处。有人专门把它们提炼出来，希望能帮助到那些像他们一样充满了好奇心、且愿意付诸行动去惹恼开源项目维护者的人们。 以下是『如何提出无法解答的问题』的十三个小技巧： 1.惜字如金『言多必失，不如闷声发大财』 压缩问题的字节数，不要让对方觉得你啰嗦。用最简单的字词描述你的问题，提炼关键字，简化掉冗长的过程和繁琐的细节。 正确示范: 样式编译报错 错误示范： 在我的项目里引入了 xxx.css，编译时出错了，报错信息如下：Module build failed: SyntaxError: Unexpected token我是这么引用的：import ‘xxx.css’;balalalala ….. 2.缓兵之计『和他成为长期笔友』 如果维护者答复你了，通常他们会索要进一步的信息。记住不要着急回复，那样显得你像个工作狂（时时刻刻泡在电脑边，可怜巴巴的等待回复）。你还有其他生活，喝杯咖啡，聊个微信，隔上十天半个月再回复。相信我，他们很快会失去耐心而关掉这个问题，或者因为一时关不了而心情郁闷。 正确示范： 你：使用 Button 时发现控制台报错，提示如下。维护者（两天内）：我没有重现出你的例子，可以提供一份可重现的示例么？维护者（三天后）：@你维护者（一周后）：ping~你（两周后）：哎呀抱歉，没有及时回复，我的代码在这里。 错误示范： 你：使用 Button 时发现控制台报错，提示如下。维护者（两天内）：我没有重现出你的例子，可以提供一份可重现的示例么？你（两天内）：可能我的情况有些不同，这里是重现代码。 3.夹带私货『我哪有时间排查，这绝对是你的锅』 在一个中型或者大型项目中引入开源模块容易遇到奇怪的问题。几十个文件上百个业务模块，项目工期又紧张，一一排查太辛苦了，还是另请高明吧，赶紧打个包发给对方。 正确示范： 我的数据库项目出现了一个前端组件问题，这里是我的代码，有人能帮我看看么。附件：db-service-app.rar (434MB) 错误示范： 我的项目里出现了一个前端组件问题，我简化了一下代码，发现是 xxx 组件和 yyy 组件同时使用时出现的，这里有个简单的重现例子。附件：component-xxx-yyy-bug.zip (12KB) 4.卖个关子『欲知后事如何，且听下回分解』 总是留个后手，不要一次性把话说完，让你的问题充满神秘感，充分调动起读者的好奇心。 正确示范： 你：我的代码出错了，不知道该怎么办？你：我这里有一个问题，有人能帮我解决么？你：在吗？ 错误示范： 你：我使用了刚刚发布的 xxx 最新版本，控制台出现如下错误…我是这么调用的…我的代码仓库在这里… 5.弄乱格式『怕他轻易看懂我的问题，我必须要做点什么』 从来，永远不要格式化问题。你又不是美工，美化格式不是你的特长。你的精力要用在项目开发中，也没有时间去学习什么格式化语法。至于对方能不能看明白，你才不需要关心。 正确示范： 123456789101112131415161718192021222324252627282930313233343536373839404142 renderBatchButton() &#123;return(&lt;Dropdown overlay=&#123;this.renderExportMenu(&quot;2&quot;)&#125;&gt;导出出库单);&#125;renderExportMenu(category) &#123;let exportFile=(&#123;key&#125;)=&gt;&#123;console.log(key)&#125;let items=[];if(this.props.global.template_list)&#123;items=this.props.global.template_list.map((item)=&gt;&#123;if(category===item.category)&#123;return (&lt;Menu.Item key=&#123;item.id&#125;&gt;&#123;item.name&#125;&lt;/Menu.Item&gt;);&#125;&#125;);&#125; 错误示范： 1234567891011121314151617import React from &apos;react&apos;;import ReactDOM from &apos;react-dom&apos;;import &#123; Menu, Icon &#125; from &apos;antd&apos;;class Demo extends React.Component &#123; state = &#123; collapsed: false, &#125;; toggle = () =&gt; &#123; this.setState(&#123; collapsed: !this.state.collapsed, &#125;); &#125; render() &#123; return &lt;Menu&gt;...&lt;/Menu&gt;; &#125;&#125; 6.遗漏关键信息『诶？我忘了说我没插电源了么？』 项目代码一开始总是跑的好好的，你做了某个操作、或改动了某些代码、或者在一个特殊的环境下，问题出现了。 这个区别往往是问题的关键，把它留在心里就好，不要轻易说出来。 正确示范： 你：我的代码出错了。维护者：我尝试了各种方式都没有重现出来，麻烦提供下重现？你（很久以后）：哦！我是在 chrome 35 中出现的这个问题。 错误示范： 你：我的代码在 chrome 35 出错了。维护者：好的，我也重现了，我看看怎么修复。 7.提供错误的信息『在错误的信息上解决问题才能体现你牛逼嘛！哈哈哈』 有时候需要做一些误导，有意或者无意，总之制造困难是你的强项。 正确示范： 你：我的代码出错了。维护者：你使用了什么版本？你：0.8.4（实际上本地是 0.8.3）维护者：你确定么，0.8.4 应该已经修复过这个问题。我再看看… 错误示范： 你：我的代码在 0.8.3 版本里出错了。维护者：0.8.4 应该已经修复过这个问题，升级到新版即可解决。 8.尽情宣泄情绪『你们把我项目搞挂了，狗屎！』 开源项目导致了你的项目出现 BUG，导致了你周六晚上还要加班，导致了男/女友抱怨你不理他/她，这必须要有人负责。你的工作和生活被他们毁了，也别让他们好过。 正确示范： 这个项目烂透了，用起来全是坑，文档也太简略了，这样做开源真是呵呵了 错误示范： 这个项目有很多细节问题，文档也不完善，请问有改进的计划么？我收集了以下具体问题，希望持续完善。 9.构思宏伟蓝图『我要造一台汽车，该怎么做？』 尝试问一个具有宏大目标的问题，只有那些祖母般慈祥的维护者才会尝试回答你（这简直不可能发生）。而且由于你表现出了在所有技术细节上的毫无准备以及极端无知，对方的回答也没办法让你满意。 正确示范： 请问怎么打包发布？ 错误示范： 我要开发一个前端单页项目，后端是 php，架构是前后端完全分离的方式。我尝试使用 xxx 进行打包构建时遇到一个问题…（省略五十字）请问这时我应该做什么？ 10.自由发挥『八股文的时代早就过去了！』 很多开源项目的维护者都是傲慢、迂腐、喜欢设定各种规矩的怪胎。例如他们常常会提供奇怪的问题模板，让你在一个又臭又长的表单里填空。一旦你不按他们说的来，他们就会视你为捣乱分子，把你批判一番。你哪里受得了这些拘束，想怎么写就怎么写，让他们和他们的模板都见鬼去吧！ 正确示范： 浮层没有关闭，代码如下，求解决 错误示范： 1234567891011121314151617xxx 组件浮层没有关闭- 使用版本：1.0.0- 浏览器：Chrome 56.0987- 操作系统：Windows 10## 你做了什么？我引入了组件 xxx，代码如下，我点击组件后打开浮层，做了如下操作。## 你期待的是什么？浮层应该关闭。## 实际上的情况是？浮层短暂关闭后又再次弹出。[GIF截图]## 可重现的在线演示http://demo.com/demo.html 11.重复提问『重要的事要说三遍』 在不同的地方重复你提过的问题，加深对方的印象，颠覆对方的想象！ 正确示范： 问题一：发请求时报错：405 Method not allowd。问题二：您好，我这里出现了 405 Method not allowd 的问题。问题三：请求 405 错误，请问我该怎么办？问题 n：… 错误示范： 问题一：发请求时报错：405 Method not allowd你：+1 我也出现了这个问题。 12.出其不意『到全世界提问，到他们想不到的地方提问』 即使你知道有官方渠道，也推荐用其他方式向维护者提问：微博、Twitter、知乎私信、知乎评论区、Email、微信、个人博客、蚂蚁森林、朋友圈、他对 TFboys 微博的转发，今日头条娱乐版的评论区……到一切你能找到他的地方去提问。 正确示范： 未关注人私信：你好，我们项目用的是你们的框架，我想问下可以让 xxx 组件获取到焦点吗？因为要做键盘切换 错误示范： 官方渠道：你好，我们项目用的是你们的框架，我想问下可以让 xxx 组件获取到焦点吗？因为要做键盘切换 13.上纲上线『接连便是难懂的话，什么”KPI”，”绩效”，”弃坑”之类，引得众人都哄笑起来』 把你的问题拔高一个层次，站在道德高地进行指责，一旦讨论涉及到政治，他们便百口莫辩。 正确示范： 原来大公司团队也就这样啊，都不好好测试的么？就这玩意还好意思拿出来，就是个 KPI 产物，晋升完就不管了。 错误示范： 这个项目虽然是大公司的产品，在以下方面比起竞品还有劣势，个人不建议使用。 总结总而言之，开源项目的维护者在尝试解答和解决问题时，总是希望能亲眼看到问题发生，不要让他们得逞。另外，他们大多对未关闭的问题有强迫症，尽量多制造一些这样的问题。 原文链接]]></content>
      <categories>
        <category>开源</category>
      </categories>
      <tags>
        <tag>提问</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10-你需要提供管理员权限才能删除此文件]]></title>
    <url>%2F2019%2F03%2F02%2Fwin10-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8F%90%E4%BE%9B%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%89%8D%E8%83%BD%E5%88%A0%E9%99%A4%E6%AD%A4%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[新买的电脑配置环境, 在系统盘新建/修改/删除文件的时候会弹框提示: 你需要提供管理员权限才能新建/修改/删除此文件 去网上搜索解决方法, 清一色的复制粘贴: 去修改文件夹权限! 这个智障答案是最多的, 难道我每操作一个文件就去修改一次文件夹权限?甚至还有用命令行操作、添加脚本的, 我的妈啊, 就一个权限问题还得把操作系统学一遍不成? 解决方法 按WIN+R，打开运行对话框 输入gpedit.msc，打开组策略 一步步地选择: 计算机配置-&gt;Windows 设置-&gt;安全设置-&gt;本地策略-&gt;安全选项 找到右侧的用户账户控制：以管理员批准模式运行所有管理员这个项，默认设置是启用的，把它设成禁用。 重启电脑 完成! 试试新建/修改/删除文件看是否还会出现权限提示]]></content>
      <categories>
        <category>win10</category>
      </categories>
      <tags>
        <tag>win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2019%2F02%2F27%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[日志文件 日志文件 说明 /var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一 /var/log/secure 与安全相关的日志信息 /var/log/maillog 与邮件相关的日志信息 /var/log/cron 与定时任务相关的日志信息 /var/log/spooler 与UUCP和news设备相关的日志信息 /var/log/boot.log 守护进程启动和停止相关的日志消息 系统 命令 说明 uname -a 查看内核/操作系统/CPU信息 cat /etc/issue 登陆信息显示数据 cat /etc/redhat-release 查看操作系统版本 cat /proc/cpuinfo 查看CPU信息 hostname 查看计算机名 lspci -tv 列出所有PCI设备 lsusb -tv 列出所有USB设备 lsmod 列出加载的内核模块 env 查看环境变量 资源 命令 说明 free -m 查看内存使用量和交换区使用量 df -h 查看各分区使用情况 du -sh &lt;目录名&gt; 查看指定目录的大小 grep MemTotal /proc/meminfo 查看内存总量 grep MemFree /proc/meminfo 查看空闲内存量 uptime 查看系统运行时间、用户数、负载 cat /proc/loadavg 查看系统负载 磁盘和分区 命令 说明 fdisk -l # 查看所有分区 swapon -s # 查看所有交换分区 fdisk /dev/vdb # 对磁盘/dev/edb进行分区 mount /dev/vdb1 /data # 将磁盘分区/dev/vdb1挂载到/data下 echo /dev/vdb1 /data ext4 defaults 0 0 &gt;&gt; /etc/fstab 启动时自动挂载分区 网络 命令 说明 ifconfig 查看所有网络接口的属性 iptables -L 查看防火墙设置 route -n 查看路由表 netstat -lntp 查看所有监听端口 netstat -antp 查看所有已经建立的连接 netstat -s 查看网络统计信息 进程 命令 说明 ps -ef 查看所有进程 top 实时显示进程状态 用户 命令 说明 w 查看活动用户 id &lt;用户名&gt; 查看指定用户信息 last 查看用户登录日志 cut -d: -f1 /etc/passwd 查看系统所有用户 cut -d: -f1 /etc/group 查看系统所有组 crontab -l 查看当前用户的计划任务 useradd -s /sbin/nologin -M nginx 添加用户 服务 命令 说明 chkconfig –list 列出所有系统服务 程序 命令 说明 rpm -qa 查看所有安装的软件包 yum install &lt;程序名&gt; yum安装 yum search &lt;程序名&gt; 搜索安装包 yum list 显示所有已经安装和可以安装的程序包 yum list installed 列出所有已安装的软件包 yum upgrade &lt;软件名称&gt; 更新指定软件 wget &lt;文件地址&gt; Wget主要用于下载文件，在安装软件时会经常用到， tar -xcvf &lt;包名&gt; &lt;文件&gt; 打包压缩文件 tar -xzvf &lt;包名&gt; 解压缩 find / -name nginx.conf 在根目录下查找文件nginx.conf grep ‘test’ d* 显示所有以d开头的文件中包含test的行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装maven]]></title>
    <url>%2F2019%2F02%2F26%2FCentOS7%E5%AE%89%E8%A3%85maven%2F</url>
    <content type="text"><![CDATA[下载maven-3.5.4, 可以在官网中选择不同版本1wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz 解压1tar -zxvf apache-maven-3.5.4-bin.tar.gz 配置环境变量, 编辑文件:1vim /etc/profile 加入以下内容 ( 根据自己maven实际解压路径配置 )123MAVEN_HOME=/home/software/maven-3.5.4PATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOME 使配置生效1source /etc/profile 测试是否安装成功1mvn -v]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用GitLab-Runner搭建GitLab持续集成/部署环境]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%BD%BF%E7%94%A8GitLab-Runner%E6%90%AD%E5%BB%BAGitLab%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90-%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[相关背景 GitLab 是一套基于Ruby开发的开源Git项目管理应用，其提供的功能和Github类似，不同的是GitLab提供一个GitLab CE社区版本，用户可以将其部署在自己的服务器上，这样就可以用于团队内部的项目代码托管仓库。 GitLab CI 是GitLab 提供的持续集成服务(从8.0版本之后，GitLab CI已经集成在GitLab中了)，只要在你的仓库根目录下创建一个.gitlab-ci.yml 文件， 并为该项目指派一个Runner，当有合并请求或者Push操作时，你写在.gitlab-ci.yml中的构建脚本就会开始执行。 GitLab Runner 是配合GitLab CI进行构建任务的应用程序，GitLab CI负责yml文件中各种阶段流程的执行，而GitLab Runner就是具体的负责执行每个阶段的脚本执行，一般来说GitLab Runner需要安装在单独的机器上通过其提供的注册操作跟GitLab CI进行绑定，当然，你也可以让其和GitLab安装在一起，只是有的情况下，你代码的构建过程对资源消耗十分严重的时候，会拖累GitLab给其他用户提供政策的Git服务。 持续集成/部署环境 持续集成是程序开发人员在频繁的提交代码之后，能有相应的环境能对其提交的代码自动执行构建(Build)、测试(Test),然后根据测试结果判断新提交的代码能否合并加入主分支当中,而持续部署也就是在持续集成之后自动将代码部署(Deploy)到生成环境上 开启GitLab可持续集成功能, 你需要通过如下两步启用GitLab CI功能 为你的项目配置一个GitLab Runner 新建一个.gitlab-ci.yml文件在你项目的根目录 创建GitLab Runner以及配置拉取官方镜像, alpine版镜像体积比较小, 也可以使用latest版1docker pull gitlab/gitlab-runner:alpine 启动gitlab-runner容器1234docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:alpine 执行下面命令注册一个runner :1docker exec -it gitlab-runner gitlab-ci-multi-runner register 接下来出现以下内容, 根据提示输入123456789101112131415161718192021Please enter the gitlab-ci coordinator URL:# 示例：http://10.12.2.22Please enter the gitlab-ci token for this runner:# xxxxxxPlease enter the gitlab-ci description for this runner:# 示例：testPlease enter the gitlab-ci tags for this runner (comma separated):# 示例：testPlease enter the executor: docker, parallels, shell, kubernetes, docker-ssh, ssh, virtualbox, docker+machine, docker-ssh+machine:# sshPlease enter the SSH server address (e.g. my.server.com):# 10.12.2.22Please enter the SSH server port (e.g. 22):# 22 Please enter the SSH user (e.g. root):# rootPlease enter the SSH password (e.g. docker.io):# 123456Please enter path to SSH identity file (e.g. /home/user/.ssh/id_rsa):Runner registered successfully. Feel free to start it, but if it&apos;s running already the config should be automatically reloaded! 说明： gitlab ci 的地址以及token，从你要配置该runner到哪个项目，就去gitlab下该项目首页右侧设置—》CI/CD Pipelines—》Specific Runners下可以找到。 gitlab-ci tags这个很重要，在项目构建流程yaml文件里面指定tag，就是匹配使用哪个tag的runner，这里我定义了test，回头再配置文件里面就指定这个tag。 executor：执行者可以有很多种，这里我们使用ssh, 登录进入后再构建。 如果想修改注册信息, 可以编辑文件 vim /srv/gitlab-runner/config/config.toml, 内容如下:12345678910111213141516171819202122concurrent = 1check_interval = 0[session_server] session_timeout = 1800[[runners]] name = &quot;wta-admin&quot; url = &quot;http://10.12.2.22/&quot; token = &quot;JKLASJDFIAOSKJ&quot; executor = &quot;ssh&quot; [runners.ssh] user = &quot;root&quot; password = &quot;123456&quot; host = &quot;10.12.2.22&quot; port = &quot;22&quot; builds_dir = &quot;/home/runner/builds&quot; # 设置构建路径 cache_dir = &quot;/home/runner/caches&quot; # 设置构建缓存路径 [runners.cache] [runners.cache.s3] [runners.cache.gcs] 修改完记得重启docker1docker restart gitlab-runner gitlab-runner已经配置完成。 在gitlab项目的根目录新建.gitlab-ci.yml文件gitlab-ci.yml文件是用来配置GitLab CI进行构建流程的配置文件，其采用YAML语法,所以你需要额外注意要用空格来代替缩进，而不是Tabs。.gitlab-ci.yml文件如下。查看详细配置或官方配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 利用caches字段来指定下面将要进行的job任务中需要共享的文件目录,如果没有，# 每个Job开始的时候，GitLab Runner都会删掉.gitignore里面的文件cache: key: $&#123;CI_BUILD_REF_NAME&#125; paths: - target# 利用stages关键字来定义持续构建过程中的三个阶段: package、build_docker、deploy_docker# 1. 所有 Stages 会按照顺序运行，即当一个 Stage 完成后，下一个 Stage 才会开始# 2. 只有当所有 Stages 完成后，该构建任务 (Pipeline) 才会成功# 3. 如果任何一个 Stage 失败，那么后面的 Stages 不会执行，该构建任务 (Pipeline) 失败stages: - package - build_docker - deploy_docker############################### maven打包 ################################ 定义一个叫package的Job任务, package为job名, 可随意命名。下同# stage字段声明属于package阶段，这个job会第一个执行，执行一些环境的初始化工作。# script字段指定该任务执行的内容, 由于是CentOS, 此处执行shell语句。下同package: stage: package tags: #这里的tags一定要属于注册时填的tags中，下面同理 - test script: - echo &quot;begining to execute package project&quot; - docker stop test &amp;&amp; docker rm test &amp;&amp; docker rmi test:1.0 - mvn clean install -Dmaven.test.skip=true - cp -f target/*.jar /data/ artifacts: paths: - target/*.jar # 将maven构建成功的jar包作为构建产出导出，可在下一个stage的任务中使用 目前没卵用############################### 构建镜像 ############################### build_docker: stage: build_docker script: - echo &quot;begining to execute build project&quot; - docker build -t test:1.0 /data/ tags: - test############################### 部署运行 ############################### # only字段指定需要执行的所在分支或者标签deploy_docker: stage: deploy_docker script: - echo &quot;begining to execute deploy project&quot; - docker run -d -p 80:80 --restart always --name=test test:1.0 - echo &quot;dev部署成功, 嘻嘻嘻......&quot; only: - dev tags: - testdeploy_docker: stage: deploy_docker script: - echo &quot;begining to execute deploy project&quot; - docker run -d -p 8080:80 --restart always --name=test test:1.0 - echo &quot;master部署成功, 嘻嘻嘻......&quot; only: - master tags: - test 创建完成后push到gitlab, 此时打开项目首页的Piplines标签页，会发现一个状态标识为pending的构建任务, gitlab-CI搭建完成]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
        <tag>GitLab-CI</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F02%2F25%2Fcentos7%E5%AE%89%E8%A3%85Nginx%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[title: centos7安装Nginx及配置详解categories: Nginxtags: - Nginx - centos7 date: 2019-02-25 14:41:56—f Nginx是一款轻量级的网页服务器、反向代理服务器。相较于Apache、lighttpd具有占有内存少，稳定性高等优势。它主要的用途是提供反向代理服务。下面有两种安装方式 方法一: yum在线安装 添加 yum 源 (可省, 最近yum中有nginx了)Nginx 不在默认的 yum 源中，可以使用 epel 或者官网的 yum 源，本例使用官网的 yum 源。 1234567891011121314$ sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm# 查看一下$ sudo yum repolistLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comrepo id repo name statusbase/7/x86_64 CentOS-7 - Base 9,911extras/7/x86_64 CentOS-7 - Extras 368nginx/x86_64 nginx repo 108updates/7/x86_64 CentOS-7 - Updates 1,041repolist: 11,428 可以发现 nginx repo 已经安装到本机了。 安装yum 安装 Nginx，非常简单，一条命令。 1234567891011121314# 安装$ sudo yum install -y nginx# 设置开机启动$ sudo systemctl enable nginx# 启动服务$ sudo systemctl start nginx# 停止服务$ sudo systemctl restart nginx# 重新加载，因为一般重新配置之后，不希望重启服务，这时可以使用重新加载。$ sudo systemctl reload nginx 方法二: 压缩包安装 安装所需环境 gcc 安装 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装：1yum install gcc-c++ PCRE pcre-devel 安装 PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令：1yum install -y pcre pcre-devel zlib 安装 zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。1yum install -y zlib zlib-devel OpenSSL 安装 OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。1yum install -y openssl openssl-devel 安装Nginx 直接下载.tar.gz安装包，地址：https://nginx.org/en/download.html 使用wget命令下载（推荐）: 1wget -c https://nginx.org/download/nginx-1.14.2.tar.gz 解压 1tar -zxvf nginx-1.14.2.tar.gz 执行以下命令配置安装 123cd nginx-1.14.2 # 进入Nginx目录./configure # 使用默认配置make &amp;&amp; make install # 编辑安装 Nginx默认配置 12345678910111213nginx path prefix: &quot;/usr/local/nginx&quot;nginx binary file: &quot;/usr/local/nginx/sbin/nginx&quot;nginx modules path: &quot;/usr/local/nginx/modules&quot;nginx configuration prefix: &quot;/usr/local/nginx/conf&quot;nginx configuration file: &quot;/usr/local/nginx/conf/nginx.conf&quot;nginx pid file: &quot;/usr/local/nginx/logs/nginx.pid&quot;nginx error log file: &quot;/usr/local/nginx/logs/error.log&quot;nginx http access log file: &quot;/usr/local/nginx/logs/access.log&quot;nginx http client request body temporary files: &quot;client_body_temp&quot;nginx http proxy temporary files: &quot;proxy_temp&quot;nginx http fastcgi temporary files: &quot;fastcgi_temp&quot;nginx http uwsgi temporary files: &quot;uwsgi_temp&quot;nginx http scgi temporary files: &quot;scgi_temp&quot; 查找安装路径： 1whereis nginx 安装完成, 以下是Nginx常用命令:1234/usr/local/nginx/sbin/nginx –t # 测试配置文件是否正常/usr/local/nginx/sbin/nginx # 启动Nginx/usr/local/nginx/sbin/nginx -s stop # 停止Nginx/usr/local/nginx/sbin/nginx -s reload # 重新加载配置文件 开机自启动 编辑文件 rc.local1vim /etc/rc.local 在最下面增加一行:1/usr/local/nginx/sbin/nginx 设置执行权限：1chmod 755 /etc/rc.local Nginx安装完毕, 打开浏览器访问 http://localhost查看是否安装成功 配置Nginx Nginx配置文件nginx.conf大致分为以下几块:1234567891011121314151617181920212223mainevents &#123; ....&#125;http &#123; .... upstream myproject &#123; ..... &#125; server &#123; .... location &#123; .... &#125; &#125; server &#123; .... location &#123; .... &#125; &#125; ....&#125; nginx配置文件主要分为六个区域：main(全局设置)、events(nginx工作模式)、http(http设置)、 sever(主机设置)、location(URL匹配)、upstream(负载均衡服务器设置)。 main模块 main模块是一个全局的设置： 12345user nobody nobody;worker_processes 2;error_log /usr/local/var/log/nginx/error.log notice;pid /usr/local/var/run/nginx/nginx.pid;worker_rlimit_nofile 1024; user 指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。 worker_processes 指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。 error_log 用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。 pid 用来指定进程id的存储文件位置。 worker_rlimit_nofile 用于指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。 events 模块 events模块来用指定nginx的工作模式和连接数上限1234events &#123; use epoll; #linux平台 worker_connections 1024;&#125; use 用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在Mac中。 worker_connections 用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients=worker_processes*worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4 (注: 可能有出入) 。进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。 http 模块http模块是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块至关重要，等到反向代理和负载均衡以及虚拟目录等会仔细说。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374http&#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 charset utf-8; #默认编码 #设置日志的格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址 #第二个参数：zone=one:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息 #第三个参数：rate=1r/s表示允许相同标识的客户端的访问频次，这里限制的是每秒1次，还可以有比如30r/m的 limit_zone crawler $binary_remote_addr 10m;](limit_req_zone binary_remote_addr zone=one:10m rate=1r/s; # 第一个参数：zone=one 设置使用哪个配置区域来做限制，与上面limit_req_zone 里的name对应 # 第二个参数：burst=5，这个配置的意思是设置一个大小为5的缓冲区当有大量请求过来时，超过了访问频次限制的请求可以先放到这个缓冲区内 # 第三个参数：nodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队 server &#123; location /search/ &#123; limit_req zone=one burst=5 nodelay; &#125; &#125;&#125; include 用来设定文件的mime类型, 类型在配置文件目录下的mime.type文件定义，来告诉nginx识别文件类型。 default_type 设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置asp 的locate 环境时，Nginx是不予解析的，此时，用浏览器访问asp文件就会出现下载了。 log_format 用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来记录这种类型。 main的类型日志如下：也可以增删部分参数。1127.0.0.1 - - [21/Apr/2015:18:09:54 +0800] &quot;GET /index.php HTTP/1.1&quot; 200 87151 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36&quot; access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。 sendfile 参数用于开启高效文件传输模式。将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。 keepalive_timeout 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。 其他参数后面介绍 server 模块 sever 模块是http的子模块，它用来定一个虚拟主机，基本的配置:123456789101112131415161718192021222324252627server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.w3cschool.cn w3cschool.cn; index index.html index.htm index.php; root /data/www/w3cschool; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;&#125; server 标志定义虚拟主机开始。 listen 用于指定虚拟主机的服务端口。 server_name 用来指定IP地址或者域名，多个域名之间用空格分开。 root 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。 index 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。 access_log 用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。 location 模块 location 用来定位/解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#对 &quot;/&quot; 启用反向代理location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k;&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080;&#125; #所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d;&#125; location ~ 开启正则匹配。 后面详细介绍location的匹配规则 upstream 模块 upstream 模块用来作负载均衡1234567upstream backend&#123; ip_hash; server 192.168.12.1:80; server 192.168.12.2:80 down; server 192.168.12.3:8080 max_fails=3 fail_timeout=20s; server 192.168.12.4:8080;&#125; upstream 指令指定了一个负载均衡器的名称backend。这个名称可以任意指定，在后面需要的地方直接调用即可。 ip_hash 是其中的一种负载均衡调度算法。紧接着就是各种服务器了。用server关键字表识，后面接ip。 Nginx的负载均衡模块目前支持以下几种调度算法: weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。 ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。 fair。依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。 url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。 least_conn 下一个请求将被分派到活动连接数量最少的服务器 在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有： down，表示当前的server暂时不参与负载均衡。 backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。 max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。 fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。 注意 当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。 location匹配规则语法:1location [=|~|~*|^~] /uri/ &#123;...&#125; 符号 含义 = 表示精确匹配 ^~ 表示 URI 以某个常规字符串开头。Nginx 不对 URL 做编码，因此请求为 /static/20%/aa，可以被 ^~ /static/ /aa 匹配到 ~ 表示区分大小写的正则匹配 ~* 表示不区分大小写的正则匹配 / 通用匹配，任何请求都会匹配 多个 location 配置的情况下匹配顺序为： 首先匹配 = 其次匹配 ^~ 其次是按文件中顺序的正则匹配 最后是交给 / 当有匹配成功时候，停止匹配，按当前匹配规则处理请求 若规则如下:1234567891011121314151617181920212223location = / &#123; #规则A&#125;location = /login &#123; #规则B&#125;location ^~ /static/ &#123; #规则C&#125;location ~ \.(gif|jpg|png|js|css)$ &#123; #规则D&#125;location ~* \.png$ &#123; #规则E&#125;location / &#123; #规则F&#125; 访问根目录 /， 比如 http://localhost/ 将匹配规则 A 访问 http://localhost/login 将匹配规则 B，http://localhost/register 则匹配规则 F 访问 http://localhost/static/a.html 将匹配规则 C 访问 http://localhost/a.png 符合规则 D 和规则 E，但是只匹配较前的D， 访问 http://localhost/static/c.png 则优先匹配到规则 C 访问 http://localhost/a.PNG 则匹配规则 E，而不会匹配规则 D，因为规则 E 不区分大小写。 访问 http://localhost/category/id/1111 则最终匹配到规则 F，这个时候 nginx 可以作为反向代理服务器。 server_name参数的配置nginx中的server_name指令主要用于配置基于名称虚拟主机. 如果server_name配置了多个参数, 在接到请求后的匹配顺序如下： 确切的server_name匹配： 12345server &#123; listen 80; server_name www.google.com google.com; ...&#125; 以*通配符开始的最长字符串： 12345server &#123; listen 80; server_name *.google.com; ...&#125; 以*通配符结束的最长字符串： 12345server &#123; listen 80; server_name www.*; ...&#125; 注意: 通配符名字只可以在名字的起始处或结尾处包含一个星号，并且星号与其他字符之间用点分隔。所以，www.*.example.org 和 w*.example.org 都是非法的。 有一种形 如“.example.org”的特殊通配符，它可以既匹配确切的名字“example.org”，又可以匹配一般的通配符名字“*.example.org”。 匹配正则表达式： 12345server &#123; listen 80; server_name ~^(?&lt;www&gt;.+)\.google\.com$; ...&#125; nginx将按照1,2,3,4顺序对server name进行匹配, 而与配置的排版先后顺序无关, 只要有一项匹配后就会停止搜索。 return用法该指令将结束执行直接返回http状态码到客户端. 屏蔽某个服务端口, 直接返回404 12345server &#123; listen 80; server_name mydomain.com; return 404;&#125; 重定向所有请求到特定网址 12345server &#123; listen 80; server_name mydomain.com; return 302 $scheme://anotherdomain.com$request_uri;&#125; Nginx安装https-ssl证书添加配置: 12345678910111213141516server &#123; listen 443; server_name www.domain.com; #填写绑定证书的域名 ssl on; ssl_certificate www.domain.com.pem; #指定服务器证书路径 ssl_certificate_key www.domain.com.key; #指定私钥证书路径 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置 ssl_prefer_server_ciphers on; location / &#123; root html; #站点目录 index index.html index.htm; &#125;&#125; 配置文件参数 说明 listen 443 SSL访问端口号为443 ssl on 启用ssl功能 ssl_certificate 证书文件 ssl_certificate_key 私钥文件 ssl_protocols 使用的协议 ssl_ciphers 配置加密套件，写法遵循openssl标准 然后 nginx -t 检测配置文件 nginx -s reload 重启nginx就OK了 如有报错 unknown directive &quot;ssl&quot;, 说明没有将ssl模块编译进nginx，在configure的时候加上 –with-http_ssl_module 即可 12345678910# 下载你当前版本的nginx包，并且解压 进到解压目录执行配置./configure --with-http_ssl_module# 开始编译, 切记千万不要make install 那样就覆盖安装了make# 将原来的nginx备份 备份之前先kill当前正在启动的nginxcp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak# make之后会在当前目录生成 objs 目录cp objs/nginx /usr/local/nginx/sbin/nginx# 然后重新启动nginx/usr/local/nginx/sbin/nginx http 自动转到 https123456789101112server &#123; listen 80; server_name www.opqnext.com; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443 ssl; server_name www.opqnext.com; [....]&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos7安装redis及开机自启动]]></title>
    <url>%2F2019%2F02%2F25%2Fcentos7%E5%AE%89%E8%A3%85redis%E5%8F%8A%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[安装首先确认是否具有root权限，因为vim、设定redis开机启动需要root权限1su 新建软件安装目录和配置文件存放目录(已有可以不用新建)12mkdir -p /home/software # 存放redismkdir -p /usr/local/redis # 存放配置文件 下载redis, 可以在官网获取指定版本12cd /home/software # 进入安装目录wget http://download.redis.io/releases/redis-5.0.3.tar.gz #下载 依次执行以下命令1234tar xzf redis-5.0.3.tar.gz # 解压缩cd redis-5.0.3 # 进入解压后的文件目录yum -y install gcc-c++ # 新安装的centos系统没有C++编译器, 需要安装, 有的就跳过make # 编译安装 目前已经安装完毕 配置复制配置文件( 相当于备份 )123cp /home/software/redis-5.0.3/src/redis-server /usr/local/redis/cp /home/software/redis-5.0.3/src/redis-cli /usr/local/redis/cp /home/software/redis-5.0.3/redis.conf /usr/local/redis/ 编辑配置文件 redis.conf1vim /usr/local/redis/redis.conf daemonize 改为yes 后台运行123# By default Redis does not run as a daemon. Use &apos;yes&apos; if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes 把 bind 127.0.0.1注释掉, 放开ip限制 ( 可选 )1# bind 127.0.0.1 把# requirepass foobared注释放开并修改密码为123456( 可选 )1requirepass 123456 添加开机自启动服务文件1vim /etc/systemd/system/redis.service 加入以下内容, 在vim中一定要检查是否一致12345678910111213[Unit]Description=The redis-server Process ManagerAfter=syslog.target network.target[Service]Type=simplePIDFile=/var/run/redis_6379.pidExecStart=/usr/local/redis/redis-server /usr/local/redis/redis.conf ExecReload=/bin/kill -USR2 $MAINPIDExecStop=/bin/kill -SIGINT $MAINPID[Install]WantedBy=multi-user.target 设置开机自启动123systemctl daemon-reload systemctl start redis.service systemctl enable redis.service 测试redis, 启动redis客户端, 依次执行以下命令1234567/usr/local/redis/redis-cli127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; set name HoleskiOK127.0.0.1:6379&gt; get name&quot;holeski&quot; redis安装配置成功]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装mariaDB最新版]]></title>
    <url>%2F2019%2F02%2F24%2FCentOS7%E5%AE%89%E8%A3%85mariaDB%E6%9C%80%E6%96%B0%E7%89%88%2F</url>
    <content type="text"><![CDATA[安装Maria DB来自官网的包源 编辑新增文件: vim /etc/yum.repos.d/MariaDB.repo 保存以下内容 12345[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.3/centos7-amd64/gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 加入上述内容，然后:wq!保存退出，如果在后面安装的时候很慢可以换镜像地址, 接着要注意重新生成yum源缓存包：12yum clean allyum makecache 移除已安装的mariaDB/MySQL:12yum remove $(rpm -qa | grep -i mysql)yum remove $(rpm -qa | grep -i mari) 安装1yum install -y MariaDB-server MariaDB-client 配置数据库运行以下命令：123systemctl start mariadb # 启动mariaDBsystemctl enable mariadb # 设置开机自启动mysql_secure_installation # 开始初始化数据库 首先是设置密码，会提示先输入密码，后面是一些其他配置123456789101112131415Enter current password for root (enter for none): &lt;–初次运行直接回车Set root password? [Y/n] &lt;– 是否设置root用户密码，输入y并回车或直接回车New password: &lt;– 设置root用户的密码Re-enter new password: &lt;– 再输入一次你设置的密码Remove anonymous users? [Y/n] &lt;– 是否删除匿名用户，回车Disallow root login remotely? [Y/n] &lt;–是否禁止root远程登录,回车,Remove test database and access to it? [Y/n] &lt;– 是否删除test数据库，回车Reload privilege tables now? [Y/n] &lt;– 是否重新加载权限表，回车 初始化MariaDB完成，接下来测试登录1mysql&gt; mysql -uroot -ppassword 登录成功，查看数据库版本：1mysql&gt; select version(); 配置MariaDB的字符集 编辑文件：vi /etc/my.cnf ，在[mysqld]标签下添加12345init_connect=&apos;SET collation_connection = utf8mb4_unicode_ci&apos; init_connect=&apos;SET NAMES utf8mb4&apos; character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci skip-character-set-client-handshake 编辑文件：vi /etc/my.cnf.d/client.cnf ，在[client]下添加 ( 如果没有可以不加 )1default-character-set=utf8mb4 编辑文件： vi /etc/my.cnf.d/mysql-clients.cnf ，在[mysql]下添加1default-character-set=utf8mb4 全部配置完成，重启mariadb1systemctl restart mariadb 之后进入MariaDB查看字符集1mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;; 显示为：12345678910111213141516171819202122+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8mb4 || character_set_connection | utf8mb4 || character_set_database | utf8mb4 || character_set_filesystem | binary || character_set_results | utf8mb4 || character_set_server | utf8mb4 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)+----------------------+--------------------+| Variable_name | Value |+----------------------+--------------------+| collation_connection | utf8mb4_unicode_ci || collation_database | utf8mb4_unicode_ci || collation_server | utf8mb4_unicode_ci |+----------------------+--------------------+3 rows in set (0.00 sec) 字符集配置完成。 添加用户，设置权限 创建用户命令 1create user username@&apos;%&apos; identified by &apos;password&apos;; 授予当前登录用户所有权限给该用户 1grant all privileges on *.* to username@&apos;%&apos;; 授予权限并且可以授权 1grant all privileges on *.* to username@&apos;%&apos; with grant option; 授予dbname只读权限 1GRANT SELECT ON dbname.* TO 'username'@'%'; 授予table_name表的修改权限 1GRANT UPDATE ON dbname.table_name TO 'username'@'%'; 刷新权限 1flush privileges; 安装成功。]]></content>
      <categories>
        <category>mariaDB</category>
      </categories>
      <tags>
        <tag>CentOS7</tag>
        <tag>mariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot入门教程]]></title>
    <url>%2F2019%2F01%2F31%2Fspringboot%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[构建微服务：Spring boot 入门篇什么是spring bootSpring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。用我的话来理解，就是spring boot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架（有点夸张）。 使用spring boot有什么好处其实就是简单、快速、方便！平时如果我们需要搭建一个spring web项目的时候需要怎么做呢？ 配置web.xml，加载spring和spring mvc 配置数据库连接、配置spring事务 配置加载配置文件的读取，开启注解 配置日志文件 快速入门说了那么多，手痒痒的很，马上来一发试试! maven构建项目 访问http://start.spring.io/ 选择构建工具Maven Project、Spring Boot版本1.3.6以及一些工程基本信息，点击“Switch to the full version.”java版本选择1.7。 点击Generate Project下载项目压缩包 解压后，使用IDEA Import 项目结构介绍Spring Boot的基础结构共三个文件： 123l src/main/java 程序开发以及主程序入口l src/main/resources 配置文件l src/test/java 测试程序 另外，spingboot建议的目录结果如下：root package结构：com.example.myproject 123456789101112131415com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- controller | +- CustomerController.java | Application.java 建议放到跟目录下面,主要用于做一些框架配置 domain目录主要用于实体（Entity）与数据访问层（Repository） service 层主要是业务类代码 controller 负责页面访问控制 采用默认配置可以省去很多配置，当然也可以根据自己的喜欢来进行更改。最后，启动Application main方法，至此一个java项目搭建好了！ 引入web模块 pom.xml中添加支持web的模块： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; pom.xml文件中默认有两个模块： spring-boot-starter：核心模块，包括自动配置支持、日志和YAML；spring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito。 编写controller内容1234567@RestControllerpublic class HelloWorldController &#123; @RequestMapping(&quot;/hello&quot;) public String index() &#123; return &quot;Hello World&quot;; &#125;&#125; @RestController的意思就是controller里面的方法都以json格式输出，不用再写什么jackjson配置的了！ 启动主程序，打开浏览器访问http://localhost:8080/hello，就可以看到效果了，有木有很简单！ 如何做单元测试打开的src/test/下的测试入口，编写简单的http请求来测试；使用mockmvc进行，利用MockMvcResultHandlers.print()打印出执行结果。1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = MockServletContext.class)@WebAppConfigurationpublic class HelloWorldControlerTests &#123; private MockMvc mvc; @Before public void setUp() throws Exception &#123; mvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build(); &#125; @Test public void getHello() throws Exception &#123; mvc.perform(MockMvcRequestBuilders.get(&quot;/hello&quot;).accept(MediaType.APPLICATION_JSON)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125;&#125; 开发环境的调试热启动在正常开发项目中已经很常见了吧，虽然平时开发web项目过程中，改动项目启重启总是报错；修改之后可以实时生效，需要添加以下的配置：123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
</search>
